
%Range = type { i64, i64, i64 }
%Tuple = type opaque
%Array = type opaque
%Qubit = type opaque
%Result = type opaque
%String = type opaque
%Callable = type opaque

@PauliI = constant i2 0
@PauliX = constant i2 1
@PauliY = constant i2 -1
@PauliZ = constant i2 -2
@EmptyRange = internal constant %Range { i64 0, i64 1, i64 -1 }
@0 = internal constant [19 x i8] c"Evaluating P(x) = \00"
@1 = internal constant [3 x i8] c"*x\00"
@2 = internal constant [72 x i8] c" + {polynomialCoefficients[d]}*x^{d + (odd ? d+1 | 0) + (even ? d | 0)}\00"
@3 = internal constant [2 x i8] c".\00"
@4 = internal constant [3 x i8] c"P(\00"
@5 = internal constant [5 x i8] c") = \00"
@6 = internal constant [13 x i8] c". [sin(x) = \00"
@7 = internal constant [2 x i8] c"]\00"
@8 = internal constant [36 x i8] c"Qubit in invalid state. Expecting: \00"
@9 = internal constant [36 x i8] c"Qubit in invalid state. Expecting: \00"
@10 = internal constant [36 x i8] c"Qubit in invalid state. Expecting: \00"
@11 = internal constant [36 x i8] c"Qubit in invalid state. Expecting: \00"
@12 = internal constant [13 x i8] c"\0A\09Expected:\09\00"
@13 = internal constant [11 x i8] c"\0A\09Actual:\09\00"
@14 = internal constant [13 x i8] c"\0A\09Expected:\09\00"
@15 = internal constant [11 x i8] c"\0A\09Actual:\09\00"
@16 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@17 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@18 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@19 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@20 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@Microsoft__Quantum__Intrinsic__CNOT = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Intrinsic__CNOT__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Intrinsic__CNOT__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Intrinsic__CNOT__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Intrinsic__CNOT__ctladj__wrapper]
@21 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@22 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@23 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@PartialApplication__1 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__1__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__1__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__1__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__1__ctladj__wrapper]
@Microsoft__Quantum__Arithmetic__PrepareFxP = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__PrepareFxP__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__PrepareFxP__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__PrepareFxP__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__PrepareFxP__ctladj__wrapper]
@MemoryManagement__1 = constant [2 x void (%Tuple*, i32)*] [void (%Tuple*, i32)* @MemoryManagement__1__RefCount, void (%Tuple*, i32)* @MemoryManagement__1__AliasCount]
@PartialApplication__2 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__2__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__2__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__2__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__2__ctladj__wrapper]
@Microsoft__Quantum__Arithmetic__AddFxP = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__AddFxP__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__AddFxP__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__AddFxP__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__AddFxP__ctladj__wrapper]
@MemoryManagement__2 = constant [2 x void (%Tuple*, i32)*] [void (%Tuple*, i32)* @MemoryManagement__2__RefCount, void (%Tuple*, i32)* @MemoryManagement__2__AliasCount]
@PartialApplication__3 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__3__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__3__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__3__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__3__ctladj__wrapper]
@PartialApplication__4 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__4__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__4__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__4__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__4__ctladj__wrapper]
@PartialApplication__5 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__5__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__5__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__5__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__5__ctladj__wrapper]
@PartialApplication__6 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__6__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__6__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__6__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__6__ctladj__wrapper]
@PartialApplication__7 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__7__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__7__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__7__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__7__ctladj__wrapper]
@PartialApplication__8 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__8__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__8__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__8__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__8__ctladj__wrapper]
@24 = internal constant [41 x i8] c"xs must not contain more qubits than ys!\00"
@25 = internal constant [41 x i8] c"xs must not contain more qubits than ys!\00"
@26 = internal constant [41 x i8] c"xs must not contain more qubits than ys!\00"
@27 = internal constant [41 x i8] c"xs must not contain more qubits than ys!\00"
@PartialApplication__9 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__9__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__9__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__9__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__9__ctladj__wrapper]
@Microsoft__Quantum__Arithmetic__SquareFxP = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__SquareFxP__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__SquareFxP__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__SquareFxP__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__SquareFxP__ctladj__wrapper]
@PartialApplication__10 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__10__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__10__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__10__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__10__ctladj__wrapper]
@Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__ctladj__wrapper]
@MemoryManagement__3 = constant [2 x void (%Tuple*, i32)*] [void (%Tuple*, i32)* @MemoryManagement__3__RefCount, void (%Tuple*, i32)* @MemoryManagement__3__AliasCount]
@PartialApplication__11 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__11__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__11__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__11__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__11__ctladj__wrapper]
@PartialApplication__12 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__12__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__12__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__12__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__12__ctladj__wrapper]
@PartialApplication__13 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__13__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__13__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__13__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__13__ctladj__wrapper]
@Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__ctladj__wrapper]
@MemoryManagement__4 = constant [2 x void (%Tuple*, i32)*] [void (%Tuple*, i32)* @MemoryManagement__4__RefCount, void (%Tuple*, i32)* @MemoryManagement__4__AliasCount]
@PartialApplication__14 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__14__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__14__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__14__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__14__ctladj__wrapper]
@Microsoft__Quantum__Arithmetic__MultiplyFxP = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__MultiplyFxP__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__MultiplyFxP__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctladj__wrapper]
@MemoryManagement__5 = constant [2 x void (%Tuple*, i32)*] [void (%Tuple*, i32)* @MemoryManagement__5__RefCount, void (%Tuple*, i32)* @MemoryManagement__5__AliasCount]
@PartialApplication__15 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__15__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__15__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__15__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__15__ctladj__wrapper]
@PartialApplication__16 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__16__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__16__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__16__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__16__ctladj__wrapper]
@28 = internal constant [42 x i8] c"Point position must be greater than zero.\00"
@29 = internal constant [62 x i8] c"FixedPoint numbers must have identical binary point position.\00"
@30 = internal constant [57 x i8] c"FixedPoint numbers must have identical number of qubits.\00"
@31 = internal constant [42 x i8] c"Point position must be greater than zero.\00"
@32 = internal constant [56 x i8] c"FixedPoint numbers must have identical point alignment.\00"
@PartialApplication__17 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__17__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__17__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__17__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__17__ctladj__wrapper]
@Microsoft__Quantum__Intrinsic__X = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Intrinsic__X__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Intrinsic__X__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Intrinsic__X__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Intrinsic__X__ctladj__wrapper]
@MemoryManagement__6 = constant [2 x void (%Tuple*, i32)*] [void (%Tuple*, i32)* @MemoryManagement__6__RefCount, void (%Tuple*, i32)* @MemoryManagement__6__AliasCount]
@PartialApplication__18 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__18__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__18__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__18__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__18__ctladj__wrapper]
@33 = internal constant [94 x i8] c"Integer multiplication requires\0A                           equally-sized registers xs and ys.\00"
@34 = internal constant [87 x i8] c"Integer multiplication\0A                            requires a 2n-bit result registers.\00"
@35 = internal constant [94 x i8] c"Integer multiplication requires\0A                           equally-sized registers xs and ys.\00"
@36 = internal constant [87 x i8] c"Integer multiplication\0A                            requires a 2n-bit result registers.\00"
@37 = internal constant [94 x i8] c"Integer multiplication requires\0A                           equally-sized registers xs and ys.\00"
@38 = internal constant [87 x i8] c"Integer multiplication\0A                            requires a 2n-bit result registers.\00"
@39 = internal constant [94 x i8] c"Integer multiplication requires\0A                           equally-sized registers xs and ys.\00"
@40 = internal constant [87 x i8] c"Integer multiplication\0A                            requires a 2n-bit result registers.\00"
@41 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder__ = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____ctladj__wrapper]
@Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry__ = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____ctladj__wrapper]
@42 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@43 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@44 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@45 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@PartialApplication__19 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__19__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__19__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__19__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__19__ctladj__wrapper]
@Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder__ = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____ctladj__wrapper]
@MemoryManagement__7 = constant [2 x void (%Tuple*, i32)*] [void (%Tuple*, i32)* @MemoryManagement__7__RefCount, void (%Tuple*, i32)* @MemoryManagement__7__AliasCount]
@46 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@PartialApplication__20 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__20__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__20__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__20__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__20__ctladj__wrapper]
@47 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@PartialApplication__21 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__21__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__21__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__21__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__21__ctladj__wrapper]
@48 = internal constant [53 x i8] c"Input registers must have the same number of qubits.\00"
@PartialApplication__22 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__22__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__22__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__22__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__22__ctladj__wrapper]
@49 = internal constant [87 x i8] c"Integer multiplication\0A                            requires a 2n-bit result registers.\00"
@50 = internal constant [87 x i8] c"Integer multiplication\0A                            requires a 2n-bit result registers.\00"
@51 = internal constant [39 x i8] c"Array must be of the length at least 1\00"
@52 = internal constant [28 x i8] c"reached unreachable code...\00"
@PartialApplication__23 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__23__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* null, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__23__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* null]
@MemoryManagement__8 = constant [2 x void (%Tuple*, i32)*] [void (%Tuple*, i32)* @MemoryManagement__8__RefCount, void (%Tuple*, i32)* @MemoryManagement__8__AliasCount]
@PartialApplication__24 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__24__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* null, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__24__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* null]
@PartialApplication__25 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__25__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__25__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__25__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__25__ctladj__wrapper]
@MemoryManagement__9 = constant [2 x void (%Tuple*, i32)*] [void (%Tuple*, i32)* @MemoryManagement__9__RefCount, void (%Tuple*, i32)* @MemoryManagement__9__AliasCount]
@PartialApplication__26 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__26__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__26__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__26__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__26__ctladj__wrapper]
@PartialApplication__27 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__27__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__27__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__27__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__27__ctladj__wrapper]
@PartialApplication__28 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__28__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__28__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__28__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__28__ctladj__wrapper]
@PartialApplication__29 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__29__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* null, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__29__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* null]
@PartialApplication__30 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__30__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* null, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__30__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* null]
@PartialApplication__31 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__31__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__31__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__31__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__31__ctladj__wrapper]
@PartialApplication__32 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__32__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__32__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__32__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__32__ctladj__wrapper]
@PartialApplication__33 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__33__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__33__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__33__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__33__ctladj__wrapper]
@PartialApplication__34 = constant [4 x void (%Tuple*, %Tuple*, %Tuple*)*] [void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__34__body__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__34__adj__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__34__ctl__wrapper, void (%Tuple*, %Tuple*, %Tuple*)* @Lifted__PartialApplication__34__ctladj__wrapper]

@Microsoft__Quantum__Numerics__Samples__RunProgram__Interop = alias void (), void ()* @Microsoft__Quantum__Numerics__Samples__RunProgram__body

define %Array* @Microsoft__Quantum__Numerics__Samples__EvaluatePolynomial__body(%Array* %coefficients, %Array* %evaluationPoints, i64 %numBits, i64 %pointPos, i1 %odd, i1 %even) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %evaluationPoints, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %evaluationPoints)
  %1 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 %0)
  %2 = sub i64 %0, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %3 = phi i64 [ 0, %entry ], [ %7, %exiting__1 ]
  %4 = icmp sle i64 %3, %2
  br i1 %4, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %5 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %1, i64 %3)
  %6 = bitcast i8* %5 to double*
  store double 0.000000e+00, double* %6, align 8
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %7 = add i64 %3, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  %results = alloca %Array*, align 8
  store %Array* %1, %Array** %results, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  %8 = call %Range @Microsoft__Quantum__Arrays___37c1790f6b42464bbf53eafc490018f1_IndexRange__body(%Array* %evaluationPoints)
  %9 = extractvalue %Range %8, 0
  %10 = extractvalue %Range %8, 1
  %11 = extractvalue %Range %8, 2
  br label %preheader__1

preheader__1:                                     ; preds = %exit__1
  %12 = icmp sgt i64 %10, 0
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__1
  %i = phi i64 [ %9, %preheader__1 ], [ %31, %exiting__2 ]
  %13 = icmp sle i64 %i, %11
  %14 = icmp sge i64 %i, %11
  %15 = select i1 %12, i1 %13, i1 %14
  br i1 %15, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %16 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %evaluationPoints, i64 %i)
  %17 = bitcast i8* %16 to double*
  %point = load double, double* %17, align 8
  %xQubits = call %Array* @__quantum__rt__qubit_allocate_array(i64 %numBits)
  call void @__quantum__rt__array_update_alias_count(%Array* %xQubits, i32 1)
  %yQubits = call %Array* @__quantum__rt__qubit_allocate_array(i64 %numBits)
  call void @__quantum__rt__array_update_alias_count(%Array* %yQubits, i32 1)
  %x = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %pointPos, %Array* %xQubits)
  %18 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %x, i32 0, i32 1
  %19 = load %Array*, %Array** %18, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %19, i32 1)
  %20 = bitcast { i64, %Array* }* %x to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 1)
  %y = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %pointPos, %Array* %yQubits)
  %21 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %y, i32 0, i32 1
  %22 = load %Array*, %Array** %21, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %22, i32 1)
  %23 = bitcast { i64, %Array* }* %y to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %23, i32 1)
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__body(double %point, { i64, %Array* }* %x)
  br i1 %odd, label %then0__1, label %test1__1

then0__1:                                         ; preds = %body__2
  call void @Microsoft__Quantum__Arithmetic__EvaluateOddPolynomialFxP__body(%Array* %coefficients, { i64, %Array* }* %x, { i64, %Array* }* %y)
  br label %continue__1

test1__1:                                         ; preds = %body__2
  br i1 %even, label %then1__1, label %else__1

then1__1:                                         ; preds = %test1__1
  call void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__body(%Array* %coefficients, { i64, %Array* }* %x, { i64, %Array* }* %y)
  br label %continue__1

else__1:                                          ; preds = %test1__1
  call void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__body(%Array* %coefficients, { i64, %Array* }* %x, { i64, %Array* }* %y)
  br label %continue__1

continue__1:                                      ; preds = %else__1, %then1__1, %then0__1
  %24 = load %Array*, %Array** %results, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %24, i32 -1)
  %25 = call %Array* @__quantum__rt__array_copy(%Array* %24, i1 false)
  %26 = icmp ne %Array* %24, %25
  %27 = call double @Microsoft__Quantum__Arithmetic__MeasureFxP__body({ i64, %Array* }* %y)
  %28 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %25, i64 %i)
  %29 = bitcast i8* %28 to double*
  store double %27, double* %29, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %25, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %25, i32 1)
  store %Array* %25, %Array** %results, align 8
  %30 = call %Array* @__quantum__rt__array_concatenate(%Array* %xQubits, %Array* %yQubits)
  call void @Microsoft__Quantum__Intrinsic__ResetAll__body(%Array* %30)
  call void @__quantum__rt__array_update_alias_count(%Array* %yQubits, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %22, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %23, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %22, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %23, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %24, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %25, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %30, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %yQubits)
  call void @__quantum__rt__array_update_alias_count(%Array* %xQubits, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %xQubits)
  br label %exiting__2

exiting__2:                                       ; preds = %continue__1
  %31 = add i64 %i, %10
  br label %header__2

exit__2:                                          ; preds = %header__2
  %32 = load %Array*, %Array** %results, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %evaluationPoints, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %32, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  ret %Array* %32
}

declare void @__quantum__rt__array_update_alias_count(%Array*, i32)

declare i64 @__quantum__rt__array_get_size_1d(%Array*)

declare %Array* @__quantum__rt__array_create_1d(i32, i64)

declare i8* @__quantum__rt__array_get_element_ptr_1d(%Array*, i64)

declare void @__quantum__rt__array_update_reference_count(%Array*, i32)

define %Range @Microsoft__Quantum__Arrays___37c1790f6b42464bbf53eafc490018f1_IndexRange__body(%Array* %array) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %array)
  %1 = sub i64 %0, 1
  %2 = load %Range, %Range* @EmptyRange, align 4
  %3 = insertvalue %Range %2, i64 0, 0
  %4 = insertvalue %Range %3, i64 1, 1
  %5 = insertvalue %Range %4, i64 %1, 2
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 -1)
  ret %Range %5
}

declare %Qubit* @__quantum__rt__qubit_allocate()

declare %Array* @__quantum__rt__qubit_allocate_array(i64)

declare void @__quantum__rt__qubit_release_array(%Array*)

define { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__Item1__, %Array* %__Item2__) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__Item2__, i32 1)
  %0 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ i64, %Array* }* getelementptr ({ i64, %Array* }, { i64, %Array* }* null, i32 1) to i64))
  %1 = bitcast %Tuple* %0 to { i64, %Array* }*
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %1, i32 0, i32 0
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %1, i32 0, i32 1
  store i64 %__Item1__, i64* %2, align 4
  store %Array* %__Item2__, %Array** %3, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %__Item2__, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__Item2__, i32 -1)
  ret { i64, %Array* }* %1
}

declare void @__quantum__rt__tuple_update_alias_count(%Tuple*, i32)

define void @Microsoft__Quantum__Arithmetic__PrepareFxP__body(double %constant, { i64, %Array* }* %fp) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %q = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 1)
  %1 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 1)
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %p = load i64, i64* %2, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %q)
  %sign = fcmp olt double %constant, 0.000000e+00
  %3 = sub i64 %n, %p
  %4 = sitofp i64 %3 to double
  %5 = call double @Microsoft__Quantum__Math__PowD__body(double 2.000000e+00, double %4)
  %6 = call double @Microsoft__Quantum__Math__AbsD__body(double %constant)
  %7 = fmul double %5, %6
  %8 = fadd double %7, 5.000000e-01
  %rescaledConstant = alloca double, align 8
  store double %8, double* %rescaledConstant, align 8
  %keepAdding = alloca i1, align 1
  store i1 %sign, i1* %keepAdding, align 1
  %9 = sub i64 %n, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %i = phi i64 [ 0, %entry ], [ %21, %exiting__1 ]
  %10 = icmp sle i64 %i, %9
  br i1 %10, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %11 = load double, double* %rescaledConstant, align 8
  %intConstant = call i64 @Microsoft__Quantum__Math__Floor__body(double %11)
  %12 = fmul double 5.000000e-01, %11
  store double %12, double* %rescaledConstant, align 8
  %13 = and i64 %intConstant, 1
  %14 = select i1 %sign, i64 0, i64 1
  %15 = icmp eq i64 %13, %14
  %currentBit = alloca i1, align 1
  store i1 %15, i1* %currentBit, align 1
  %16 = load i1, i1* %keepAdding, align 1
  br i1 %16, label %then0__1, label %continue__1

then0__1:                                         ; preds = %body__1
  store i1 %15, i1* %keepAdding, align 1
  %17 = xor i1 %15, true
  store i1 %17, i1* %currentBit, align 1
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %body__1
  %18 = load i1, i1* %currentBit, align 1
  br i1 %18, label %then0__2, label %continue__2

then0__2:                                         ; preds = %continue__1
  %19 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %q, i64 %i)
  %20 = bitcast i8* %19 to %Qubit**
  %qubit = load %Qubit*, %Qubit** %20, align 8
  call void @__quantum__qis__x__body(%Qubit* %qubit)
  br label %continue__2

continue__2:                                      ; preds = %then0__2, %continue__1
  br label %exiting__1

exiting__1:                                       ; preds = %continue__2
  %21 = add i64 %i, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateOddPolynomialFxP__body(%Array* %coefficients, { i64, %Array* }* %fpx, { i64, %Array* }* %result) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store %Array* %coefficients, %Array** %9, align 8
  store { i64, %Array* }* %fpx, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %11, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluateOddPolynomialFxP__ctl(%Array* %6, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__body(%Array* %coefficients, { i64, %Array* }* %fpx, { i64, %Array* }* %result) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store %Array* %coefficients, %Array** %9, align 8
  store { i64, %Array* }* %fpx, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %11, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__ctl(%Array* %6, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__body(%Array* %coefficients, { i64, %Array* }* %fpx, { i64, %Array* }* %result) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store %Array* %coefficients, %Array** %9, align 8
  store { i64, %Array* }* %fpx, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %11, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__ctl(%Array* %6, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

declare %Array* @__quantum__rt__array_copy(%Array*, i1)

define double @Microsoft__Quantum__Arithmetic__MeasureFxP__body({ i64, %Array* }* %fp) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %xs = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %1 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 1)
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %p = load i64, i64* %2, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %xs)
  %3 = sub i64 %n, 1
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %xs, i64 %3)
  %5 = bitcast i8* %4 to %Qubit**
  %6 = load %Qubit*, %Qubit** %5, align 8
  %7 = call %Result* @Microsoft__Quantum__Measurement__MResetZ__body(%Qubit* %6)
  %8 = call %Result* @__quantum__rt__result_get_one()
  %sign = call i1 @__quantum__rt__result_equal(%Result* %7, %Result* %8)
  %keepAdding = alloca i1, align 1
  store i1 %sign, i1* %keepAdding, align 1
  %fpAsDouble = alloca double, align 8
  store double 0.000000e+00, double* %fpAsDouble, align 8
  %9 = sub i64 %n, 2
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %i = phi i64 [ 0, %entry ], [ %27, %exiting__1 ]
  %10 = icmp sle i64 %i, %9
  br i1 %10, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %11 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %xs, i64 %i)
  %12 = bitcast i8* %11 to %Qubit**
  %13 = load %Qubit*, %Qubit** %12, align 8
  %14 = call %Result* @Microsoft__Quantum__Measurement__MResetZ__body(%Qubit* %13)
  %15 = call %Result* @__quantum__rt__result_get_zero()
  %16 = call %Result* @__quantum__rt__result_get_one()
  %17 = select i1 %sign, %Result* %15, %Result* %16
  %18 = call i1 @__quantum__rt__result_equal(%Result* %14, %Result* %17)
  %currentRes = alloca i1, align 1
  store i1 %18, i1* %currentRes, align 1
  %19 = load i1, i1* %keepAdding, align 1
  br i1 %19, label %then0__1, label %continue__1

then0__1:                                         ; preds = %body__1
  store i1 %18, i1* %keepAdding, align 1
  %20 = xor i1 %18, true
  store i1 %20, i1* %currentRes, align 1
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %body__1
  %21 = load double, double* %fpAsDouble, align 8
  %22 = fmul double %21, 5.000000e-01
  %23 = load i1, i1* %currentRes, align 1
  %24 = icmp eq i1 %23, true
  %25 = select i1 %24, double 1.000000e+00, double 0.000000e+00
  %26 = fadd double %22, %25
  store double %26, double* %fpAsDouble, align 8
  call void @__quantum__rt__result_update_reference_count(%Result* %14, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %continue__1
  %27 = add i64 %i, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  br i1 %sign, label %condTrue__1, label %condFalse__1

condTrue__1:                                      ; preds = %exit__1
  br label %condContinue__1

condFalse__1:                                     ; preds = %exit__1
  br label %condContinue__1

condContinue__1:                                  ; preds = %condFalse__1, %condTrue__1
  %28 = phi double [ -1.000000e+00, %condTrue__1 ], [ 1.000000e+00, %condFalse__1 ]
  %29 = load double, double* %fpAsDouble, align 8
  %30 = fmul double %28, %29
  %31 = sub i64 %p, 2
  %32 = sitofp i64 %31 to double
  %33 = call double @Microsoft__Quantum__Math__PowD__body(double 2.000000e+00, double %32)
  %34 = fmul double %30, %33
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__result_update_reference_count(%Result* %7, i32 -1)
  ret double %34
}

define void @Microsoft__Quantum__Intrinsic__ResetAll__body(%Array* %qubits) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %qubits)
  %1 = sub i64 %0, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %2 = phi i64 [ 0, %entry ], [ %6, %exiting__1 ]
  %3 = icmp sle i64 %2, %1
  br i1 %3, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %qubits, i64 %2)
  %5 = bitcast i8* %4 to %Qubit**
  %qubit = load %Qubit*, %Qubit** %5, align 8
  call void @Microsoft__Quantum__Intrinsic__Reset__body(%Qubit* %qubit)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %6 = add i64 %2, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  ret void
}

declare %Array* @__quantum__rt__array_concatenate(%Array*, %Array*)

declare void @__quantum__rt__tuple_update_reference_count(%Tuple*, i32)

define void @Microsoft__Quantum__Numerics__Samples__RunProgram__body() #0 {
entry:
  %evaluationPoints = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 7)
  %0 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %evaluationPoints, i64 0)
  %1 = bitcast i8* %0 to double*
  %2 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %evaluationPoints, i64 1)
  %3 = bitcast i8* %2 to double*
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %evaluationPoints, i64 2)
  %5 = bitcast i8* %4 to double*
  %6 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %evaluationPoints, i64 3)
  %7 = bitcast i8* %6 to double*
  %8 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %evaluationPoints, i64 4)
  %9 = bitcast i8* %8 to double*
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %evaluationPoints, i64 5)
  %11 = bitcast i8* %10 to double*
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %evaluationPoints, i64 6)
  %13 = bitcast i8* %12 to double*
  store double 0.000000e+00, double* %1, align 8
  store double 1.000000e-01, double* %3, align 8
  store double 2.000000e-01, double* %5, align 8
  store double 3.000000e-01, double* %7, align 8
  store double 4.000000e-01, double* %9, align 8
  store double 5.000000e-01, double* %11, align 8
  store double 6.000000e-01, double* %13, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %evaluationPoints, i32 1)
  %polynomialCoefficients = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 4)
  %14 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %polynomialCoefficients, i64 0)
  %15 = bitcast i8* %14 to double*
  %16 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %polynomialCoefficients, i64 1)
  %17 = bitcast i8* %16 to double*
  %18 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %polynomialCoefficients, i64 2)
  %19 = bitcast i8* %18 to double*
  %20 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %polynomialCoefficients, i64 3)
  %21 = bitcast i8* %20 to double*
  store double 0x3FEFFA119AB46747, double* %15, align 8
  store double 0xBFC534941C3393E9, double* %17, align 8
  store double 0x3F804C5353BFB282, double* %19, align 8
  store double 0xBF230402D18174B8, double* %21, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %polynomialCoefficients, i32 1)
  %22 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %polynomialCoefficients, i64 0)
  %23 = bitcast i8* %22 to double*
  %24 = load double, double* %23, align 8
  %25 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([19 x i8], [19 x i8]* @0, i32 0, i32 0))
  %26 = call %String* @__quantum__rt__double_to_string(double %24)
  %27 = call %String* @__quantum__rt__string_concatenate(%String* %25, %String* %26)
  call void @__quantum__rt__string_update_reference_count(%String* %25, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %26, i32 -1)
  %msg = alloca %String*, align 8
  store %String* %27, %String** %msg, align 8
  call void @__quantum__rt__string_update_reference_count(%String* %27, i32 1)
  br i1 true, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  %28 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([3 x i8], [3 x i8]* @1, i32 0, i32 0))
  %29 = call %String* @__quantum__rt__string_concatenate(%String* %27, %String* %28)
  call void @__quantum__rt__string_update_reference_count(%String* %29, i32 1)
  store %String* %29, %String** %msg, align 8
  call void @__quantum__rt__string_update_reference_count(%String* %28, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %29, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %27, i32 -1)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  br label %header__1

header__1:                                        ; preds = %exiting__1, %continue__1
  %d = phi i64 [ 1, %continue__1 ], [ %34, %exiting__1 ]
  %30 = icmp sle i64 %d, 3
  br i1 %30, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %31 = load %String*, %String** %msg, align 8
  %32 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([72 x i8], [72 x i8]* @2, i32 0, i32 0))
  %33 = call %String* @__quantum__rt__string_concatenate(%String* %31, %String* %32)
  call void @__quantum__rt__string_update_reference_count(%String* %33, i32 1)
  store %String* %33, %String** %msg, align 8
  call void @__quantum__rt__string_update_reference_count(%String* %32, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %33, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %31, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %34 = add i64 %d, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  %35 = load %String*, %String** %msg, align 8
  %36 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @3, i32 0, i32 0))
  %37 = call %String* @__quantum__rt__string_concatenate(%String* %35, %String* %36)
  call void @__quantum__rt__message(%String* %37)
  %res = call %Array* @Microsoft__Quantum__Numerics__Samples__EvaluatePolynomial__body(%Array* %polynomialCoefficients, %Array* %evaluationPoints, i64 64, i64 3, i1 true, i1 false)
  call void @__quantum__rt__array_update_alias_count(%Array* %res, i32 1)
  %38 = call %Range @Microsoft__Quantum__Arrays___37c1790f6b42464bbf53eafc490018f1_IndexRange__body(%Array* %res)
  %39 = extractvalue %Range %38, 0
  %40 = extractvalue %Range %38, 1
  %41 = extractvalue %Range %38, 2
  br label %preheader__1

preheader__1:                                     ; preds = %exit__1
  %42 = icmp sgt i64 %40, 0
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__1
  %i = phi i64 [ %39, %preheader__1 ], [ %68, %exiting__2 ]
  %43 = icmp sle i64 %i, %41
  %44 = icmp sge i64 %i, %41
  %45 = select i1 %42, i1 %43, i1 %44
  br i1 %45, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %46 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %evaluationPoints, i64 %i)
  %47 = bitcast i8* %46 to double*
  %48 = load double, double* %47, align 8
  %49 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %res, i64 %i)
  %50 = bitcast i8* %49 to double*
  %51 = load double, double* %50, align 8
  %52 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %evaluationPoints, i64 %i)
  %53 = bitcast i8* %52 to double*
  %theta = load double, double* %53, align 8
  %54 = call double @__quantum__qis__sin__body(double %theta)
  %55 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([3 x i8], [3 x i8]* @4, i32 0, i32 0))
  %56 = call %String* @__quantum__rt__double_to_string(double %48)
  %57 = call %String* @__quantum__rt__string_concatenate(%String* %55, %String* %56)
  call void @__quantum__rt__string_update_reference_count(%String* %55, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %56, i32 -1)
  %58 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @5, i32 0, i32 0))
  %59 = call %String* @__quantum__rt__string_concatenate(%String* %57, %String* %58)
  call void @__quantum__rt__string_update_reference_count(%String* %57, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %58, i32 -1)
  %60 = call %String* @__quantum__rt__double_to_string(double %51)
  %61 = call %String* @__quantum__rt__string_concatenate(%String* %59, %String* %60)
  call void @__quantum__rt__string_update_reference_count(%String* %59, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %60, i32 -1)
  %62 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([13 x i8], [13 x i8]* @6, i32 0, i32 0))
  %63 = call %String* @__quantum__rt__string_concatenate(%String* %61, %String* %62)
  call void @__quantum__rt__string_update_reference_count(%String* %61, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %62, i32 -1)
  %64 = call %String* @__quantum__rt__double_to_string(double %54)
  %65 = call %String* @__quantum__rt__string_concatenate(%String* %63, %String* %64)
  call void @__quantum__rt__string_update_reference_count(%String* %63, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %64, i32 -1)
  %66 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([2 x i8], [2 x i8]* @7, i32 0, i32 0))
  %67 = call %String* @__quantum__rt__string_concatenate(%String* %65, %String* %66)
  call void @__quantum__rt__string_update_reference_count(%String* %65, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %66, i32 -1)
  call void @__quantum__rt__message(%String* %67)
  call void @__quantum__rt__string_update_reference_count(%String* %67, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %68 = add i64 %i, %40
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %evaluationPoints, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %polynomialCoefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %res, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %evaluationPoints, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %polynomialCoefficients, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %27, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %36, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %37, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %res, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %35, i32 -1)
  ret void
}

declare %String* @__quantum__rt__string_create(i8*)

declare void @__quantum__rt__string_update_reference_count(%String*, i32)

declare %String* @__quantum__rt__double_to_string(double)

declare %String* @__quantum__rt__string_concatenate(%String*, %String*)

declare void @__quantum__rt__message(%String*)

declare double @__quantum__qis__sin__body(double)

define void @Microsoft__Quantum__Intrinsic__CCNOT__body(%Qubit* %control1, %Qubit* %control2, %Qubit* %target) {
entry:
  %__controlQubits__ = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %0 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %__controlQubits__, i64 0)
  %1 = bitcast i8* %0 to %Qubit**
  %2 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %__controlQubits__, i64 1)
  %3 = bitcast i8* %2 to %Qubit**
  store %Qubit* %control1, %Qubit** %1, align 8
  store %Qubit* %control2, %Qubit** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  call void @__quantum__qis__x__ctl(%Array* %__controlQubits__, %Qubit* %target)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__, i32 -1)
  ret void
}

declare void @__quantum__qis__x__ctl(%Array*, %Qubit*)

define void @Microsoft__Quantum__Intrinsic__CCNOT__adj(%Qubit* %control1, %Qubit* %control2, %Qubit* %target) {
entry:
  call void @Microsoft__Quantum__Intrinsic__CCNOT__body(%Qubit* %control1, %Qubit* %control2, %Qubit* %target)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__CCNOT__ctl(%Array* %__controlQubits__, { %Qubit*, %Qubit*, %Qubit* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %0, i32 0, i32 0
  %control1 = load %Qubit*, %Qubit** %1, align 8
  %2 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %0, i32 0, i32 1
  %control2 = load %Qubit*, %Qubit** %2, align 8
  %3 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %0, i32 0, i32 2
  %target = load %Qubit*, %Qubit** %3, align 8
  %4 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %5 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %4, i64 0)
  %6 = bitcast i8* %5 to %Qubit**
  %7 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %4, i64 1)
  %8 = bitcast i8* %7 to %Qubit**
  store %Qubit* %control1, %Qubit** %6, align 8
  store %Qubit* %control2, %Qubit** %8, align 8
  %__controlQubits__1 = call %Array* @__quantum__rt__array_concatenate(%Array* %__controlQubits__, %Array* %4)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__1, i32 1)
  call void @__quantum__qis__x__ctl(%Array* %__controlQubits__1, %Qubit* %target)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__1, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__CCNOT__ctladj(%Array* %__controlQubits__, { %Qubit*, %Qubit*, %Qubit* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %0, i32 0, i32 0
  %control1 = load %Qubit*, %Qubit** %1, align 8
  %2 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %0, i32 0, i32 1
  %control2 = load %Qubit*, %Qubit** %2, align 8
  %3 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %0, i32 0, i32 2
  %target = load %Qubit*, %Qubit** %3, align 8
  %4 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %5 = bitcast %Tuple* %4 to { %Qubit*, %Qubit*, %Qubit* }*
  %6 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %5, i32 0, i32 0
  %7 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %5, i32 0, i32 1
  %8 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %5, i32 0, i32 2
  store %Qubit* %control1, %Qubit** %6, align 8
  store %Qubit* %control2, %Qubit** %7, align 8
  store %Qubit* %target, %Qubit** %8, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__ctl(%Array* %__controlQubits__, { %Qubit*, %Qubit*, %Qubit* }* %5)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  ret void
}

declare %Tuple* @__quantum__rt__tuple_create(i64)

define void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %control, %Qubit* %target) {
entry:
  %__controlQubits__ = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %0 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %__controlQubits__, i64 0)
  %1 = bitcast i8* %0 to %Qubit**
  store %Qubit* %control, %Qubit** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  call void @__quantum__qis__x__ctl(%Array* %__controlQubits__, %Qubit* %target)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %control, %Qubit* %target) {
entry:
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %control, %Qubit* %target)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %__controlQubits__, { %Qubit*, %Qubit* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %0, i32 0, i32 0
  %control = load %Qubit*, %Qubit** %1, align 8
  %2 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %0, i32 0, i32 1
  %target = load %Qubit*, %Qubit** %2, align 8
  %3 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 0)
  %5 = bitcast i8* %4 to %Qubit**
  store %Qubit* %control, %Qubit** %5, align 8
  %__controlQubits__1 = call %Array* @__quantum__rt__array_concatenate(%Array* %__controlQubits__, %Array* %3)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__1, i32 1)
  call void @__quantum__qis__x__ctl(%Array* %__controlQubits__1, %Qubit* %target)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__1, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %__controlQubits__, { %Qubit*, %Qubit* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %0, i32 0, i32 0
  %control = load %Qubit*, %Qubit** %1, align 8
  %2 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %0, i32 0, i32 1
  %target = load %Qubit*, %Qubit** %2, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { %Qubit*, %Qubit* }*
  %5 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %4, i32 0, i32 1
  store %Qubit* %control, %Qubit** %5, align 8
  store %Qubit* %target, %Qubit** %6, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %__controlQubits__, { %Qubit*, %Qubit* }* %4)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define %Result* @Microsoft__Quantum__Intrinsic__M__body(%Qubit* %qubit) {
entry:
  %bases = call %Array* @__quantum__rt__array_create_1d(i32 1, i64 1)
  %0 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %bases, i64 0)
  %1 = bitcast i8* %0 to i2*
  %2 = load i2, i2* @PauliZ, align 1
  store i2 %2, i2* %1, align 1
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 1)
  %qubits = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %3 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %qubits, i64 0)
  %4 = bitcast i8* %3 to %Qubit**
  store %Qubit* %qubit, %Qubit** %4, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %5 = call %Result* @__quantum__qis__measure__body(%Array* %bases, %Array* %qubits)
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 -1)
  ret %Result* %5
}

declare %Result* @__quantum__qis__measure__body(%Array*, %Array*)

define %Result* @Microsoft__Quantum__Intrinsic__Measure__body(%Array* %bases, %Array* %qubits) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %0 = call %Result* @__quantum__qis__measure__body(%Array* %bases, %Array* %qubits)
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  ret %Result* %0
}

define void @Microsoft__Quantum__Intrinsic__Reset__body(%Qubit* %qubit) {
entry:
  %0 = call %Result* @Microsoft__Quantum__Intrinsic__M__body(%Qubit* %qubit)
  %1 = call %Result* @__quantum__rt__result_get_one()
  %2 = call i1 @__quantum__rt__result_equal(%Result* %0, %Result* %1)
  br i1 %2, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  call void @__quantum__qis__x__body(%Qubit* %qubit)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  call void @__quantum__rt__result_update_reference_count(%Result* %0, i32 -1)
  ret void
}

declare %Result* @__quantum__rt__result_get_one()

declare i1 @__quantum__rt__result_equal(%Result*, %Result*)

declare void @__quantum__qis__x__body(%Qubit*)

declare void @__quantum__rt__result_update_reference_count(%Result*, i32)

define void @Microsoft__Quantum__Intrinsic__X__body(%Qubit* %qubit) {
entry:
  call void @__quantum__qis__x__body(%Qubit* %qubit)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__X__adj(%Qubit* %qubit) {
entry:
  call void @__quantum__qis__x__body(%Qubit* %qubit)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__X__ctl(%Array* %__controlQubits__, %Qubit* %qubit) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  call void @__quantum__qis__x__ctl(%Array* %__controlQubits__, %Qubit* %qubit)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__X__ctladj(%Array* %__controlQubits__, %Qubit* %qubit) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  call void @__quantum__qis__x__ctl(%Array* %__controlQubits__, %Qubit* %qubit)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  ret void
}

define %Result* @Microsoft__Quantum__Measurement__MResetZ__body(%Qubit* %target) {
entry:
  %result = call %Result* @Microsoft__Quantum__Intrinsic__M__body(%Qubit* %target)
  %0 = call %Result* @__quantum__rt__result_get_one()
  %1 = call i1 @__quantum__rt__result_equal(%Result* %result, %Result* %0)
  br i1 %1, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  call void @__quantum__qis__x__body(%Qubit* %target)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  ret %Result* %result
}

define void @Microsoft__Quantum__Diagnostics__AssertAllZero__body(%Array* %qubits) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %qubits)
  %1 = sub i64 %0, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %2 = phi i64 [ 0, %entry ], [ %7, %exiting__1 ]
  %3 = icmp sle i64 %2, %1
  br i1 %3, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %qubits, i64 %2)
  %5 = bitcast i8* %4 to %Qubit**
  %qubit = load %Qubit*, %Qubit** %5, align 8
  %6 = call %Result* @__quantum__rt__result_get_zero()
  call void @Microsoft__Quantum__Diagnostics__AssertQubit__body(%Result* %6, %Qubit* %qubit)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %7 = add i64 %2, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Diagnostics__AssertQubit__body(%Result* %expected, %Qubit* %q) {
entry:
  %bases = call %Array* @__quantum__rt__array_create_1d(i32 1, i64 1)
  %0 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %bases, i64 0)
  %1 = bitcast i8* %0 to i2*
  %2 = load i2, i2* @PauliZ, align 1
  store i2 %2, i2* %1, align 1
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 1)
  %qubits = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %3 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %qubits, i64 0)
  %4 = bitcast i8* %3 to %Qubit**
  store %Qubit* %q, %Qubit** %4, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %5 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([36 x i8], [36 x i8]* @8, i32 0, i32 0))
  %6 = call %String* @__quantum__rt__result_to_string(%Result* %expected)
  %msg = call %String* @__quantum__rt__string_concatenate(%String* %5, %String* %6)
  call void @__quantum__rt__string_update_reference_count(%String* %5, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %6, i32 -1)
  call void @__quantum__qis__assertmeasurement__body(%Array* %bases, %Array* %qubits, %Result* %expected, %String* %msg)
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 -1)
  ret void
}

declare %Result* @__quantum__rt__result_get_zero()

define void @Microsoft__Quantum__Diagnostics__AssertAllZero__adj(%Array* %qubits) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__body(%Array* %qubits)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Diagnostics__AssertAllZero__ctl(%Array* %ctrls, %Array* %qubits) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %ctrls, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__body(%Array* %qubits)
  call void @__quantum__rt__array_update_alias_count(%Array* %ctrls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Diagnostics__AssertAllZero__ctladj(%Array* %__controlQubits__, %Array* %qubits) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__ctl(%Array* %__controlQubits__, %Array* %qubits)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Diagnostics__AssertMeasurement__body(%Array* %bases, %Array* %qubits, %Result* %result, %String* %msg) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  call void @__quantum__qis__assertmeasurement__body(%Array* %bases, %Array* %qubits, %Result* %result, %String* %msg)
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  ret void
}

declare void @__quantum__qis__assertmeasurement__body(%Array*, %Array*, %Result*, %String*)

define void @Microsoft__Quantum__Diagnostics__AssertMeasurement__adj(%Array* %bases, %Array* %qubits, %Result* %result, %String* %msg) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  call void @__quantum__qis__assertmeasurement__adj(%Array* %bases, %Array* %qubits, %Result* %result, %String* %msg)
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  ret void
}

declare void @__quantum__qis__assertmeasurement__adj(%Array*, %Array*, %Result*, %String*)

define void @Microsoft__Quantum__Diagnostics__AssertMeasurement__ctl(%Array* %__controlQubits__, { %Array*, %Array*, %Result*, %String* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %0, i32 0, i32 0
  %bases = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 1)
  %2 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %0, i32 0, i32 1
  %qubits = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %3 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %0, i32 0, i32 2
  %result = load %Result*, %Result** %3, align 8
  %4 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %0, i32 0, i32 3
  %msg = load %String*, %String** %4, align 8
  %5 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 4))
  %6 = bitcast %Tuple* %5 to { %Array*, %Array*, %Result*, %String* }*
  %7 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %6, i32 0, i32 0
  %8 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %6, i32 0, i32 1
  %9 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %6, i32 0, i32 2
  %10 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %6, i32 0, i32 3
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 1)
  call void @__quantum__rt__result_update_reference_count(%Result* %result, i32 1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 1)
  store %Array* %bases, %Array** %7, align 8
  store %Array* %qubits, %Array** %8, align 8
  store %Result* %result, %Result** %9, align 8
  store %String* %msg, %String** %10, align 8
  call void @__quantum__qis__assertmeasurement__ctl(%Array* %__controlQubits__, { %Array*, %Array*, %Result*, %String* }* %6)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__result_update_reference_count(%Result* %result, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  ret void
}

declare void @__quantum__qis__assertmeasurement__ctl(%Array*, { %Array*, %Array*, %Result*, %String* }*)

define void @Microsoft__Quantum__Diagnostics__AssertMeasurement__ctladj(%Array* %__controlQubits__, { %Array*, %Array*, %Result*, %String* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %0, i32 0, i32 0
  %bases = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 1)
  %2 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %0, i32 0, i32 1
  %qubits = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %3 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %0, i32 0, i32 2
  %result = load %Result*, %Result** %3, align 8
  %4 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %0, i32 0, i32 3
  %msg = load %String*, %String** %4, align 8
  %5 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 4))
  %6 = bitcast %Tuple* %5 to { %Array*, %Array*, %Result*, %String* }*
  %7 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %6, i32 0, i32 0
  %8 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %6, i32 0, i32 1
  %9 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %6, i32 0, i32 2
  %10 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %6, i32 0, i32 3
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 1)
  call void @__quantum__rt__result_update_reference_count(%Result* %result, i32 1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 1)
  store %Array* %bases, %Array** %7, align 8
  store %Array* %qubits, %Array** %8, align 8
  store %Result* %result, %Result** %9, align 8
  store %String* %msg, %String** %10, align 8
  call void @__quantum__qis__assertmeasurement__ctladj(%Array* %__controlQubits__, { %Array*, %Array*, %Result*, %String* }* %6)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__result_update_reference_count(%Result* %result, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  ret void
}

declare void @__quantum__qis__assertmeasurement__ctladj(%Array*, { %Array*, %Array*, %Result*, %String* }*)

declare %String* @__quantum__rt__result_to_string(%Result*)

define void @Microsoft__Quantum__Diagnostics__AssertQubit__adj(%Result* %expected, %Qubit* %q) {
entry:
  %bases = call %Array* @__quantum__rt__array_create_1d(i32 1, i64 1)
  %0 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %bases, i64 0)
  %1 = bitcast i8* %0 to i2*
  %2 = load i2, i2* @PauliZ, align 1
  store i2 %2, i2* %1, align 1
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 1)
  %qubits = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %3 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %qubits, i64 0)
  %4 = bitcast i8* %3 to %Qubit**
  store %Qubit* %q, %Qubit** %4, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %5 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([36 x i8], [36 x i8]* @9, i32 0, i32 0))
  %6 = call %String* @__quantum__rt__result_to_string(%Result* %expected)
  %msg = call %String* @__quantum__rt__string_concatenate(%String* %5, %String* %6)
  call void @__quantum__rt__string_update_reference_count(%String* %5, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %6, i32 -1)
  call void @__quantum__qis__assertmeasurement__adj(%Array* %bases, %Array* %qubits, %Result* %expected, %String* %msg)
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Diagnostics__AssertQubit__ctl(%Array* %__controlQubits__, { %Result*, %Qubit* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Result*, %Qubit* }, { %Result*, %Qubit* }* %0, i32 0, i32 0
  %expected = load %Result*, %Result** %1, align 8
  %2 = getelementptr inbounds { %Result*, %Qubit* }, { %Result*, %Qubit* }* %0, i32 0, i32 1
  %q = load %Qubit*, %Qubit** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %bases = call %Array* @__quantum__rt__array_create_1d(i32 1, i64 1)
  %3 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %bases, i64 0)
  %4 = bitcast i8* %3 to i2*
  %5 = load i2, i2* @PauliZ, align 1
  store i2 %5, i2* %4, align 1
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 1)
  %qubits = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %6 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %qubits, i64 0)
  %7 = bitcast i8* %6 to %Qubit**
  store %Qubit* %q, %Qubit** %7, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %8 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([36 x i8], [36 x i8]* @10, i32 0, i32 0))
  %9 = call %String* @__quantum__rt__result_to_string(%Result* %expected)
  %msg = call %String* @__quantum__rt__string_concatenate(%String* %8, %String* %9)
  call void @__quantum__rt__string_update_reference_count(%String* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %9, i32 -1)
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 4))
  %11 = bitcast %Tuple* %10 to { %Array*, %Array*, %Result*, %String* }*
  %12 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %11, i32 0, i32 1
  %14 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %11, i32 0, i32 2
  %15 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %11, i32 0, i32 3
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 1)
  call void @__quantum__rt__result_update_reference_count(%Result* %expected, i32 1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 1)
  store %Array* %bases, %Array** %12, align 8
  store %Array* %qubits, %Array** %13, align 8
  store %Result* %expected, %Result** %14, align 8
  store %String* %msg, %String** %15, align 8
  call void @__quantum__qis__assertmeasurement__ctl(%Array* %__controlQubits__, { %Array*, %Array*, %Result*, %String* }* %11)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__result_update_reference_count(%Result* %expected, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Diagnostics__AssertQubit__ctladj(%Array* %__controlQubits__, { %Result*, %Qubit* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Result*, %Qubit* }, { %Result*, %Qubit* }* %0, i32 0, i32 0
  %expected = load %Result*, %Result** %1, align 8
  %2 = getelementptr inbounds { %Result*, %Qubit* }, { %Result*, %Qubit* }* %0, i32 0, i32 1
  %q = load %Qubit*, %Qubit** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %bases = call %Array* @__quantum__rt__array_create_1d(i32 1, i64 1)
  %3 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %bases, i64 0)
  %4 = bitcast i8* %3 to i2*
  %5 = load i2, i2* @PauliZ, align 1
  store i2 %5, i2* %4, align 1
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 1)
  %qubits = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %6 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %qubits, i64 0)
  %7 = bitcast i8* %6 to %Qubit**
  store %Qubit* %q, %Qubit** %7, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %8 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([36 x i8], [36 x i8]* @11, i32 0, i32 0))
  %9 = call %String* @__quantum__rt__result_to_string(%Result* %expected)
  %msg = call %String* @__quantum__rt__string_concatenate(%String* %8, %String* %9)
  call void @__quantum__rt__string_update_reference_count(%String* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %9, i32 -1)
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 4))
  %11 = bitcast %Tuple* %10 to { %Array*, %Array*, %Result*, %String* }*
  %12 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %11, i32 0, i32 1
  %14 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %11, i32 0, i32 2
  %15 = getelementptr inbounds { %Array*, %Array*, %Result*, %String* }, { %Array*, %Array*, %Result*, %String* }* %11, i32 0, i32 3
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 1)
  call void @__quantum__rt__result_update_reference_count(%Result* %expected, i32 1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 1)
  store %Array* %bases, %Array** %12, align 8
  store %Array* %qubits, %Array** %13, align 8
  store %Result* %expected, %Result** %14, align 8
  store %String* %msg, %String** %15, align 8
  call void @__quantum__qis__assertmeasurement__ctladj(%Array* %__controlQubits__, { %Array*, %Array*, %Result*, %String* }* %11)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %bases, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__result_update_reference_count(%Result* %expected, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %msg, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Diagnostics__EqualityFactB__body(i1 %actual, i1 %expected, %String* %message) {
entry:
  %0 = icmp ne i1 %actual, %expected
  br i1 %0, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  call void @Microsoft__Quantum__Diagnostics___bc9b023136c745c38ae242d338824de2___QsRef3__FormattedFailure____body(i1 %actual, i1 %expected, %String* %message)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  ret void
}

define void @Microsoft__Quantum__Diagnostics___bc9b023136c745c38ae242d338824de2___QsRef3__FormattedFailure____body(i1 %actual, i1 %expected, %String* %message) {
entry:
  call void @__quantum__rt__string_update_reference_count(%String* %message, i32 1)
  %0 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([13 x i8], [13 x i8]* @12, i32 0, i32 0))
  %1 = call %String* @__quantum__rt__string_concatenate(%String* %message, %String* %0)
  call void @__quantum__rt__string_update_reference_count(%String* %message, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %0, i32 -1)
  %2 = call %String* @__quantum__rt__bool_to_string(i1 %expected)
  %3 = call %String* @__quantum__rt__string_concatenate(%String* %1, %String* %2)
  call void @__quantum__rt__string_update_reference_count(%String* %1, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %2, i32 -1)
  %4 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([11 x i8], [11 x i8]* @13, i32 0, i32 0))
  %5 = call %String* @__quantum__rt__string_concatenate(%String* %3, %String* %4)
  call void @__quantum__rt__string_update_reference_count(%String* %3, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %4, i32 -1)
  %6 = call %String* @__quantum__rt__bool_to_string(i1 %actual)
  %7 = call %String* @__quantum__rt__string_concatenate(%String* %5, %String* %6)
  call void @__quantum__rt__string_update_reference_count(%String* %5, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %6, i32 -1)
  call void @__quantum__rt__fail(%String* %7)
  unreachable
}

define void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %actual, i64 %expected, %String* %message) {
entry:
  %0 = icmp ne i64 %actual, %expected
  br i1 %0, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  call void @Microsoft__Quantum__Diagnostics___1f0df3d705a64f76b79f7d551e2aad9b___QsRef3__FormattedFailure____body(i64 %actual, i64 %expected, %String* %message)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  ret void
}

define void @Microsoft__Quantum__Diagnostics___1f0df3d705a64f76b79f7d551e2aad9b___QsRef3__FormattedFailure____body(i64 %actual, i64 %expected, %String* %message) {
entry:
  call void @__quantum__rt__string_update_reference_count(%String* %message, i32 1)
  %0 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([13 x i8], [13 x i8]* @14, i32 0, i32 0))
  %1 = call %String* @__quantum__rt__string_concatenate(%String* %message, %String* %0)
  call void @__quantum__rt__string_update_reference_count(%String* %message, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %0, i32 -1)
  %2 = call %String* @__quantum__rt__int_to_string(i64 %expected)
  %3 = call %String* @__quantum__rt__string_concatenate(%String* %1, %String* %2)
  call void @__quantum__rt__string_update_reference_count(%String* %1, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %2, i32 -1)
  %4 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([11 x i8], [11 x i8]* @15, i32 0, i32 0))
  %5 = call %String* @__quantum__rt__string_concatenate(%String* %3, %String* %4)
  call void @__quantum__rt__string_update_reference_count(%String* %3, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %4, i32 -1)
  %6 = call %String* @__quantum__rt__int_to_string(i64 %actual)
  %7 = call %String* @__quantum__rt__string_concatenate(%String* %5, %String* %6)
  call void @__quantum__rt__string_update_reference_count(%String* %5, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %6, i32 -1)
  call void @__quantum__rt__fail(%String* %7)
  unreachable
}

define void @Microsoft__Quantum__Diagnostics__Fact__body(i1 %actual, %String* %message) {
entry:
  %0 = xor i1 %actual, true
  br i1 %0, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  call void @__quantum__rt__string_update_reference_count(%String* %message, i32 1)
  call void @__quantum__rt__fail(%String* %message)
  unreachable

continue__1:                                      ; preds = %entry
  ret void
}

declare void @__quantum__rt__fail(%String*)

declare %String* @__quantum__rt__bool_to_string(i1)

declare %String* @__quantum__rt__int_to_string(i64)

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____body({ %Array* }* %xs, { %Array* }* %ys, %Qubit* %carry) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %8, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { %Array* }* %xs, { %Array* }** %9, align 8
  store { %Array* }* %ys, { %Array* }** %10, align 8
  store %Qubit* %carry, %Qubit** %11, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____ctl(%Array* %6, { { %Array* }*, { %Array* }*, %Qubit* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____ctl(%Array* %controls, { { %Array* }*, { %Array* }*, %Qubit* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 2
  %carry = load %Qubit*, %Qubit** %9, align 8
  %nQubits = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %10 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %11 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @16, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %nQubits, i64 %10, %String* %11)
  %12 = sub i64 %nQubits, 2
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %idx = phi i64 [ 0, %entry ], [ %26, %exiting__1 ]
  %13 = icmp sle i64 %idx, %12
  br i1 %13, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %14 = load %Array*, %Array** %2, align 8
  %15 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %14, i64 %idx)
  %16 = bitcast i8* %15 to %Qubit**
  %17 = load %Qubit*, %Qubit** %16, align 8
  %18 = load %Array*, %Array** %6, align 8
  %19 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %18, i64 %idx)
  %20 = bitcast i8* %19 to %Qubit**
  %21 = load %Qubit*, %Qubit** %20, align 8
  %22 = add i64 %idx, 1
  %23 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %14, i64 %22)
  %24 = bitcast i8* %23 to %Qubit**
  %25 = load %Qubit*, %Qubit** %24, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__body(%Qubit* %17, %Qubit* %21, %Qubit* %25)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %26 = add i64 %idx, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  %27 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %28 = bitcast %Tuple* %27 to { %Qubit*, %Qubit*, %Qubit* }*
  %29 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %28, i32 0, i32 0
  %30 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %28, i32 0, i32 1
  %31 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %28, i32 0, i32 2
  %32 = load %Array*, %Array** %2, align 8
  %33 = sub i64 %nQubits, 1
  %34 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %32, i64 %33)
  %35 = bitcast i8* %34 to %Qubit**
  %36 = load %Qubit*, %Qubit** %35, align 8
  %37 = load %Array*, %Array** %6, align 8
  %38 = sub i64 %nQubits, 1
  %39 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %37, i64 %38)
  %40 = bitcast i8* %39 to %Qubit**
  %41 = load %Qubit*, %Qubit** %40, align 8
  store %Qubit* %36, %Qubit** %29, align 8
  store %Qubit* %41, %Qubit** %30, align 8
  store %Qubit* %carry, %Qubit** %31, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__ctl(%Array* %controls, { %Qubit*, %Qubit*, %Qubit* }* %28)
  %42 = sub i64 %nQubits, 1
  br label %preheader__1

preheader__1:                                     ; preds = %exit__1
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__1
  %idx__1 = phi i64 [ %42, %preheader__1 ], [ %69, %exiting__2 ]
  %43 = icmp sle i64 %idx__1, 1
  %44 = icmp sge i64 %idx__1, 1
  %45 = select i1 false, i1 %43, i1 %44
  br i1 %45, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %46 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %47 = bitcast %Tuple* %46 to { %Qubit*, %Qubit* }*
  %48 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %47, i32 0, i32 0
  %49 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %47, i32 0, i32 1
  %50 = load %Array*, %Array** %2, align 8
  %51 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %50, i64 %idx__1)
  %52 = bitcast i8* %51 to %Qubit**
  %53 = load %Qubit*, %Qubit** %52, align 8
  %54 = load %Array*, %Array** %6, align 8
  %55 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %54, i64 %idx__1)
  %56 = bitcast i8* %55 to %Qubit**
  %57 = load %Qubit*, %Qubit** %56, align 8
  store %Qubit* %53, %Qubit** %48, align 8
  store %Qubit* %57, %Qubit** %49, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %controls, { %Qubit*, %Qubit* }* %47)
  %58 = sub i64 %idx__1, 1
  %59 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %50, i64 %58)
  %60 = bitcast i8* %59 to %Qubit**
  %61 = load %Qubit*, %Qubit** %60, align 8
  %62 = sub i64 %idx__1, 1
  %63 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %54, i64 %62)
  %64 = bitcast i8* %63 to %Qubit**
  %65 = load %Qubit*, %Qubit** %64, align 8
  %66 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %50, i64 %idx__1)
  %67 = bitcast i8* %66 to %Qubit**
  %68 = load %Qubit*, %Qubit** %67, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__body(%Qubit* %61, %Qubit* %65, %Qubit* %68)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %46, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %69 = add i64 %idx__1, -1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %70 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %70, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  %71 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %71, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %11, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____adj({ %Array* }* %xs, { %Array* }* %ys, %Qubit* %carry) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %8, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { %Array* }* %xs, { %Array* }** %9, align 8
  store { %Array* }* %ys, { %Array* }** %10, align 8
  store %Qubit* %carry, %Qubit** %11, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____ctladj(%Array* %6, { { %Array* }*, { %Array* }*, %Qubit* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____ctladj(%Array* %controls, { { %Array* }*, { %Array* }*, %Qubit* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 2
  %carry = load %Qubit*, %Qubit** %9, align 8
  %__qsVar0__nQubits__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %10 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %11 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @17, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %__qsVar0__nQubits__, i64 %10, %String* %11)
  %12 = sub i64 %__qsVar0__nQubits__, 1
  %13 = sub i64 1, %12
  %14 = udiv i64 %13, -1
  %15 = mul i64 -1, %14
  %16 = add i64 %12, %15
  %17 = load %Range, %Range* @EmptyRange, align 4
  %18 = insertvalue %Range %17, i64 %16, 0
  %19 = insertvalue %Range %18, i64 1, 1
  %20 = insertvalue %Range %19, i64 %12, 2
  %21 = extractvalue %Range %20, 0
  %22 = extractvalue %Range %20, 1
  %23 = extractvalue %Range %20, 2
  br label %preheader__1

preheader__1:                                     ; preds = %entry
  %24 = icmp sgt i64 %22, 0
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %__qsVar2__idx__ = phi i64 [ %21, %preheader__1 ], [ %51, %exiting__1 ]
  %25 = icmp sle i64 %__qsVar2__idx__, %23
  %26 = icmp sge i64 %__qsVar2__idx__, %23
  %27 = select i1 %24, i1 %25, i1 %26
  br i1 %27, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %28 = load %Array*, %Array** %2, align 8
  %29 = sub i64 %__qsVar2__idx__, 1
  %30 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %28, i64 %29)
  %31 = bitcast i8* %30 to %Qubit**
  %32 = load %Qubit*, %Qubit** %31, align 8
  %33 = load %Array*, %Array** %6, align 8
  %34 = sub i64 %__qsVar2__idx__, 1
  %35 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %33, i64 %34)
  %36 = bitcast i8* %35 to %Qubit**
  %37 = load %Qubit*, %Qubit** %36, align 8
  %38 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %28, i64 %__qsVar2__idx__)
  %39 = bitcast i8* %38 to %Qubit**
  %40 = load %Qubit*, %Qubit** %39, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__adj(%Qubit* %32, %Qubit* %37, %Qubit* %40)
  %41 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %42 = bitcast %Tuple* %41 to { %Qubit*, %Qubit* }*
  %43 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %42, i32 0, i32 0
  %44 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %42, i32 0, i32 1
  %45 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %28, i64 %__qsVar2__idx__)
  %46 = bitcast i8* %45 to %Qubit**
  %47 = load %Qubit*, %Qubit** %46, align 8
  %48 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %33, i64 %__qsVar2__idx__)
  %49 = bitcast i8* %48 to %Qubit**
  %50 = load %Qubit*, %Qubit** %49, align 8
  store %Qubit* %47, %Qubit** %43, align 8
  store %Qubit* %50, %Qubit** %44, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %controls, { %Qubit*, %Qubit* }* %42)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %41, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %51 = add i64 %__qsVar2__idx__, %22
  br label %header__1

exit__1:                                          ; preds = %header__1
  %52 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %53 = bitcast %Tuple* %52 to { %Qubit*, %Qubit*, %Qubit* }*
  %54 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %53, i32 0, i32 0
  %55 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %53, i32 0, i32 1
  %56 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %53, i32 0, i32 2
  %57 = load %Array*, %Array** %2, align 8
  %58 = sub i64 %__qsVar0__nQubits__, 1
  %59 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %57, i64 %58)
  %60 = bitcast i8* %59 to %Qubit**
  %61 = load %Qubit*, %Qubit** %60, align 8
  %62 = load %Array*, %Array** %6, align 8
  %63 = sub i64 %__qsVar0__nQubits__, 1
  %64 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %62, i64 %63)
  %65 = bitcast i8* %64 to %Qubit**
  %66 = load %Qubit*, %Qubit** %65, align 8
  store %Qubit* %61, %Qubit** %54, align 8
  store %Qubit* %66, %Qubit** %55, align 8
  store %Qubit* %carry, %Qubit** %56, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__ctladj(%Array* %controls, { %Qubit*, %Qubit*, %Qubit* }* %53)
  %67 = sub i64 %__qsVar0__nQubits__, 2
  %68 = sub i64 %67, 0
  %69 = udiv i64 %68, 1
  %70 = mul i64 1, %69
  %71 = add i64 0, %70
  %72 = load %Range, %Range* @EmptyRange, align 4
  %73 = insertvalue %Range %72, i64 %71, 0
  %74 = insertvalue %Range %73, i64 -1, 1
  %75 = insertvalue %Range %74, i64 0, 2
  %76 = extractvalue %Range %75, 0
  %77 = extractvalue %Range %75, 1
  %78 = extractvalue %Range %75, 2
  br label %preheader__2

preheader__2:                                     ; preds = %exit__1
  %79 = icmp sgt i64 %77, 0
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__2
  %__qsVar1__idx__ = phi i64 [ %76, %preheader__2 ], [ %95, %exiting__2 ]
  %80 = icmp sle i64 %__qsVar1__idx__, %78
  %81 = icmp sge i64 %__qsVar1__idx__, %78
  %82 = select i1 %79, i1 %80, i1 %81
  br i1 %82, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %83 = load %Array*, %Array** %2, align 8
  %84 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %83, i64 %__qsVar1__idx__)
  %85 = bitcast i8* %84 to %Qubit**
  %86 = load %Qubit*, %Qubit** %85, align 8
  %87 = load %Array*, %Array** %6, align 8
  %88 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %87, i64 %__qsVar1__idx__)
  %89 = bitcast i8* %88 to %Qubit**
  %90 = load %Qubit*, %Qubit** %89, align 8
  %91 = add i64 %__qsVar1__idx__, 1
  %92 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %83, i64 %91)
  %93 = bitcast i8* %92 to %Qubit**
  %94 = load %Qubit*, %Qubit** %93, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__adj(%Qubit* %86, %Qubit* %90, %Qubit* %94)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %95 = add i64 %__qsVar1__idx__, %77
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %96 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %96, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  %97 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %97, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %11, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %52, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____body({ %Array* }* %xs, { %Array* }* %ys) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %8 = bitcast %Tuple* %7 to { { %Array* }*, { %Array* }* }*
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %8, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { %Array* }* %xs, { %Array* }** %9, align 8
  store { %Array* }* %ys, { %Array* }** %10, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____ctl(%Array* %6, { { %Array* }*, { %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____ctl(%Array* %controls, { { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %nQubits = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %9 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %10 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @18, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %nQubits, i64 %9, %String* %10)
  %11 = sub i64 %nQubits, 2
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %idx = phi i64 [ 0, %entry ], [ %25, %exiting__1 ]
  %12 = icmp sle i64 %idx, %11
  br i1 %12, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %13 = load %Array*, %Array** %2, align 8
  %14 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %13, i64 %idx)
  %15 = bitcast i8* %14 to %Qubit**
  %16 = load %Qubit*, %Qubit** %15, align 8
  %17 = load %Array*, %Array** %6, align 8
  %18 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %17, i64 %idx)
  %19 = bitcast i8* %18 to %Qubit**
  %20 = load %Qubit*, %Qubit** %19, align 8
  %21 = add i64 %idx, 1
  %22 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %13, i64 %21)
  %23 = bitcast i8* %22 to %Qubit**
  %24 = load %Qubit*, %Qubit** %23, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__body(%Qubit* %16, %Qubit* %20, %Qubit* %24)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %25 = add i64 %idx, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  %26 = sub i64 %nQubits, 1
  br label %preheader__1

preheader__1:                                     ; preds = %exit__1
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__1
  %idx__1 = phi i64 [ %26, %preheader__1 ], [ %53, %exiting__2 ]
  %27 = icmp sle i64 %idx__1, 1
  %28 = icmp sge i64 %idx__1, 1
  %29 = select i1 false, i1 %27, i1 %28
  br i1 %29, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %30 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %31 = bitcast %Tuple* %30 to { %Qubit*, %Qubit* }*
  %32 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %31, i32 0, i32 0
  %33 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %31, i32 0, i32 1
  %34 = load %Array*, %Array** %2, align 8
  %35 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %34, i64 %idx__1)
  %36 = bitcast i8* %35 to %Qubit**
  %37 = load %Qubit*, %Qubit** %36, align 8
  %38 = load %Array*, %Array** %6, align 8
  %39 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %38, i64 %idx__1)
  %40 = bitcast i8* %39 to %Qubit**
  %41 = load %Qubit*, %Qubit** %40, align 8
  store %Qubit* %37, %Qubit** %32, align 8
  store %Qubit* %41, %Qubit** %33, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %controls, { %Qubit*, %Qubit* }* %31)
  %42 = sub i64 %idx__1, 1
  %43 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %34, i64 %42)
  %44 = bitcast i8* %43 to %Qubit**
  %45 = load %Qubit*, %Qubit** %44, align 8
  %46 = sub i64 %idx__1, 1
  %47 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %38, i64 %46)
  %48 = bitcast i8* %47 to %Qubit**
  %49 = load %Qubit*, %Qubit** %48, align 8
  %50 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %34, i64 %idx__1)
  %51 = bitcast i8* %50 to %Qubit**
  %52 = load %Qubit*, %Qubit** %51, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__body(%Qubit* %45, %Qubit* %49, %Qubit* %52)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %30, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %53 = add i64 %idx__1, -1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %54 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %54, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  %55 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %55, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %10, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____adj({ %Array* }* %xs, { %Array* }* %ys) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %8 = bitcast %Tuple* %7 to { { %Array* }*, { %Array* }* }*
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %8, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { %Array* }* %xs, { %Array* }** %9, align 8
  store { %Array* }* %ys, { %Array* }** %10, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____ctladj(%Array* %6, { { %Array* }*, { %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____ctladj(%Array* %controls, { { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %__qsVar0__nQubits__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %9 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %10 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @19, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %__qsVar0__nQubits__, i64 %9, %String* %10)
  %11 = sub i64 %__qsVar0__nQubits__, 1
  %12 = sub i64 1, %11
  %13 = udiv i64 %12, -1
  %14 = mul i64 -1, %13
  %15 = add i64 %11, %14
  %16 = load %Range, %Range* @EmptyRange, align 4
  %17 = insertvalue %Range %16, i64 %15, 0
  %18 = insertvalue %Range %17, i64 1, 1
  %19 = insertvalue %Range %18, i64 %11, 2
  %20 = extractvalue %Range %19, 0
  %21 = extractvalue %Range %19, 1
  %22 = extractvalue %Range %19, 2
  br label %preheader__1

preheader__1:                                     ; preds = %entry
  %23 = icmp sgt i64 %21, 0
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %__qsVar2__idx__ = phi i64 [ %20, %preheader__1 ], [ %50, %exiting__1 ]
  %24 = icmp sle i64 %__qsVar2__idx__, %22
  %25 = icmp sge i64 %__qsVar2__idx__, %22
  %26 = select i1 %23, i1 %24, i1 %25
  br i1 %26, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %27 = load %Array*, %Array** %2, align 8
  %28 = sub i64 %__qsVar2__idx__, 1
  %29 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %27, i64 %28)
  %30 = bitcast i8* %29 to %Qubit**
  %31 = load %Qubit*, %Qubit** %30, align 8
  %32 = load %Array*, %Array** %6, align 8
  %33 = sub i64 %__qsVar2__idx__, 1
  %34 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %32, i64 %33)
  %35 = bitcast i8* %34 to %Qubit**
  %36 = load %Qubit*, %Qubit** %35, align 8
  %37 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %27, i64 %__qsVar2__idx__)
  %38 = bitcast i8* %37 to %Qubit**
  %39 = load %Qubit*, %Qubit** %38, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__adj(%Qubit* %31, %Qubit* %36, %Qubit* %39)
  %40 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %41 = bitcast %Tuple* %40 to { %Qubit*, %Qubit* }*
  %42 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %41, i32 0, i32 0
  %43 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %41, i32 0, i32 1
  %44 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %27, i64 %__qsVar2__idx__)
  %45 = bitcast i8* %44 to %Qubit**
  %46 = load %Qubit*, %Qubit** %45, align 8
  %47 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %32, i64 %__qsVar2__idx__)
  %48 = bitcast i8* %47 to %Qubit**
  %49 = load %Qubit*, %Qubit** %48, align 8
  store %Qubit* %46, %Qubit** %42, align 8
  store %Qubit* %49, %Qubit** %43, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %controls, { %Qubit*, %Qubit* }* %41)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %40, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %50 = add i64 %__qsVar2__idx__, %21
  br label %header__1

exit__1:                                          ; preds = %header__1
  %51 = sub i64 %__qsVar0__nQubits__, 2
  %52 = sub i64 %51, 0
  %53 = udiv i64 %52, 1
  %54 = mul i64 1, %53
  %55 = add i64 0, %54
  %56 = load %Range, %Range* @EmptyRange, align 4
  %57 = insertvalue %Range %56, i64 %55, 0
  %58 = insertvalue %Range %57, i64 -1, 1
  %59 = insertvalue %Range %58, i64 0, 2
  %60 = extractvalue %Range %59, 0
  %61 = extractvalue %Range %59, 1
  %62 = extractvalue %Range %59, 2
  br label %preheader__2

preheader__2:                                     ; preds = %exit__1
  %63 = icmp sgt i64 %61, 0
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__2
  %__qsVar1__idx__ = phi i64 [ %60, %preheader__2 ], [ %79, %exiting__2 ]
  %64 = icmp sle i64 %__qsVar1__idx__, %62
  %65 = icmp sge i64 %__qsVar1__idx__, %62
  %66 = select i1 %63, i1 %64, i1 %65
  br i1 %66, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %67 = load %Array*, %Array** %2, align 8
  %68 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %67, i64 %__qsVar1__idx__)
  %69 = bitcast i8* %68 to %Qubit**
  %70 = load %Qubit*, %Qubit** %69, align 8
  %71 = load %Array*, %Array** %6, align 8
  %72 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %71, i64 %__qsVar1__idx__)
  %73 = bitcast i8* %72 to %Qubit**
  %74 = load %Qubit*, %Qubit** %73, align 8
  %75 = add i64 %__qsVar1__idx__, 1
  %76 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %67, i64 %75)
  %77 = bitcast i8* %76 to %Qubit**
  %78 = load %Qubit*, %Qubit** %77, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__adj(%Qubit* %70, %Qubit* %74, %Qubit* %78)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %79 = add i64 %__qsVar1__idx__, %61
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %80 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %80, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  %81 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %81, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %10, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____body({ %Array* }* %xs, { %Array* }* %ys) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %nQubits = call i64 @__quantum__rt__array_get_size_1d(%Array* %1)
  %6 = call i64 @__quantum__rt__array_get_size_1d(%Array* %4)
  %7 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @20, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %nQubits, i64 %6, %String* %7)
  %8 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %9 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %1)
  %10 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %4)
  %11 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %9, %Array* %10)
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__body(%Callable* %8, %Array* %11)
  %12 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %1)
  call void @Microsoft__Quantum__Canon__ApplyCNOTChain__adj(%Array* %12)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %7, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %8, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %10, i32 -1)
  %13 = call i64 @__quantum__rt__array_get_size_1d(%Array* %11)
  %14 = sub i64 %13, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %15 = phi i64 [ 0, %entry ], [ %21, %exiting__1 ]
  %16 = icmp sle i64 %15, %14
  br i1 %16, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %17 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %11, i64 %15)
  %18 = bitcast i8* %17 to { %Qubit*, %Qubit* }**
  %19 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %18, align 8
  %20 = bitcast { %Qubit*, %Qubit* }* %19 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %21 = add i64 %15, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %11, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__body(%Callable* %singleElementOperation, %Array* %register) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %register)
  %1 = sub i64 %0, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %2 = phi i64 [ 0, %entry ], [ %8, %exiting__1 ]
  %3 = icmp sle i64 %2, %1
  br i1 %3, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %2)
  %5 = bitcast i8* %4 to { %Qubit*, %Qubit* }**
  %6 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %5, align 8
  %7 = bitcast { %Qubit*, %Qubit* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %8 = add i64 %2, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 1)
  %9 = call %Range @Microsoft__Quantum__Arrays___fa96fdec02544eef8fc1589d871c3b90_IndexRange__body(%Array* %register)
  %10 = extractvalue %Range %9, 0
  %11 = extractvalue %Range %9, 1
  %12 = extractvalue %Range %9, 2
  br label %preheader__1

preheader__1:                                     ; preds = %exit__1
  %13 = icmp sgt i64 %11, 0
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__1
  %idxQubit = phi i64 [ %10, %preheader__1 ], [ %21, %exiting__2 ]
  %14 = icmp sle i64 %idxQubit, %12
  %15 = icmp sge i64 %idxQubit, %12
  %16 = select i1 %13, i1 %14, i1 %15
  br i1 %16, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %17 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %idxQubit)
  %18 = bitcast i8* %17 to { %Qubit*, %Qubit* }**
  %19 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %18, align 8
  %20 = bitcast { %Qubit*, %Qubit* }* %19 to %Tuple*
  call void @__quantum__rt__callable_invoke(%Callable* %singleElementOperation, %Tuple* %20, %Tuple* null)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %21 = add i64 %idxQubit, %11
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  %22 = sub i64 %0, 1
  br label %header__3

header__3:                                        ; preds = %exiting__3, %exit__2
  %23 = phi i64 [ 0, %exit__2 ], [ %29, %exiting__3 ]
  %24 = icmp sle i64 %23, %22
  br i1 %24, label %body__3, label %exit__3

body__3:                                          ; preds = %header__3
  %25 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %23)
  %26 = bitcast i8* %25 to { %Qubit*, %Qubit* }**
  %27 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %26, align 8
  %28 = bitcast { %Qubit*, %Qubit* }* %27 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %28, i32 -1)
  br label %exiting__3

exiting__3:                                       ; preds = %body__3
  %29 = add i64 %23, 1
  br label %header__3

exit__3:                                          ; preds = %header__3
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__CNOT__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Qubit*, %Qubit* }*
  %1 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %0, i32 0, i32 1
  %3 = load %Qubit*, %Qubit** %1, align 8
  %4 = load %Qubit*, %Qubit** %2, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %3, %Qubit* %4)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__CNOT__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Qubit*, %Qubit* }*
  %1 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %0, i32 0, i32 1
  %3 = load %Qubit*, %Qubit** %1, align 8
  %4 = load %Qubit*, %Qubit** %2, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %3, %Qubit* %4)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__CNOT__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { %Qubit*, %Qubit* }* }*
  %1 = getelementptr inbounds { %Array*, { %Qubit*, %Qubit* }* }, { %Array*, { %Qubit*, %Qubit* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { %Qubit*, %Qubit* }* }, { %Array*, { %Qubit*, %Qubit* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %2, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %3, { %Qubit*, %Qubit* }* %4)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__CNOT__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { %Qubit*, %Qubit* }* }*
  %1 = getelementptr inbounds { %Array*, { %Qubit*, %Qubit* }* }, { %Array*, { %Qubit*, %Qubit* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { %Qubit*, %Qubit* }* }, { %Array*, { %Qubit*, %Qubit* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %2, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %3, { %Qubit*, %Qubit* }* %4)
  ret void
}

declare %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]*, [2 x void (%Tuple*, i32)*]*, %Tuple*)

define %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %left, %Array* %right) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %left, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %right, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %left)
  %1 = call i64 @__quantum__rt__array_get_size_1d(%Array* %right)
  %2 = icmp slt i64 %0, %1
  br i1 %2, label %condTrue__1, label %condFalse__1

condTrue__1:                                      ; preds = %entry
  br label %condContinue__1

condFalse__1:                                     ; preds = %entry
  br label %condContinue__1

condContinue__1:                                  ; preds = %condFalse__1, %condTrue__1
  %nElements = phi i64 [ %0, %condTrue__1 ], [ %1, %condFalse__1 ]
  %3 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 %nElements)
  %4 = sub i64 %nElements, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %condContinue__1
  %5 = phi i64 [ 0, %condContinue__1 ], [ %13, %exiting__1 ]
  %6 = icmp sle i64 %5, %4
  br i1 %6, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %8 = bitcast %Tuple* %7 to { %Qubit*, %Qubit* }*
  %9 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %8, i32 0, i32 1
  store %Qubit* null, %Qubit** %9, align 8
  store %Qubit* null, %Qubit** %10, align 8
  %11 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 %5)
  %12 = bitcast i8* %11 to { %Qubit*, %Qubit* }**
  store { %Qubit*, %Qubit* }* %8, { %Qubit*, %Qubit* }** %12, align 8
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %13 = add i64 %5, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  %output = alloca %Array*, align 8
  store %Array* %3, %Array** %output, align 8
  %14 = sub i64 %nElements, 1
  br label %header__2

header__2:                                        ; preds = %exiting__2, %exit__1
  %15 = phi i64 [ 0, %exit__1 ], [ %21, %exiting__2 ]
  %16 = icmp sle i64 %15, %14
  br i1 %16, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %17 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 %15)
  %18 = bitcast i8* %17 to { %Qubit*, %Qubit* }**
  %19 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %18, align 8
  %20 = bitcast { %Qubit*, %Qubit* }* %19 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %21 = add i64 %15, 1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %22 = sub i64 %nElements, 1
  br label %header__3

header__3:                                        ; preds = %exiting__3, %exit__2
  %23 = phi i64 [ 0, %exit__2 ], [ %29, %exiting__3 ]
  %24 = icmp sle i64 %23, %22
  br i1 %24, label %body__3, label %exit__3

body__3:                                          ; preds = %header__3
  %25 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 %23)
  %26 = bitcast i8* %25 to { %Qubit*, %Qubit* }**
  %27 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %26, align 8
  %28 = bitcast { %Qubit*, %Qubit* }* %27 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %28, i32 1)
  br label %exiting__3

exiting__3:                                       ; preds = %body__3
  %29 = add i64 %23, 1
  br label %header__3

exit__3:                                          ; preds = %header__3
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  %30 = sub i64 %nElements, 1
  br label %header__4

header__4:                                        ; preds = %exiting__4, %exit__3
  %idxElement = phi i64 [ 0, %exit__3 ], [ %49, %exiting__4 ]
  %31 = icmp sle i64 %idxElement, %30
  br i1 %31, label %body__4, label %exit__4

body__4:                                          ; preds = %header__4
  %32 = load %Array*, %Array** %output, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %32, i32 -1)
  %33 = call %Array* @__quantum__rt__array_copy(%Array* %32, i1 false)
  %34 = icmp ne %Array* %32, %33
  %35 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %36 = bitcast %Tuple* %35 to { %Qubit*, %Qubit* }*
  %37 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %36, i32 0, i32 0
  %38 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %36, i32 0, i32 1
  %39 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %left, i64 %idxElement)
  %40 = bitcast i8* %39 to %Qubit**
  %41 = load %Qubit*, %Qubit** %40, align 8
  %42 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %right, i64 %idxElement)
  %43 = bitcast i8* %42 to %Qubit**
  %44 = load %Qubit*, %Qubit** %43, align 8
  store %Qubit* %41, %Qubit** %37, align 8
  store %Qubit* %44, %Qubit** %38, align 8
  %45 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %33, i64 %idxElement)
  %46 = bitcast i8* %45 to { %Qubit*, %Qubit* }**
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %35, i32 1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %35, i32 1)
  %47 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %46, align 8
  %48 = bitcast { %Qubit*, %Qubit* }* %47 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %48, i32 -1)
  br i1 %34, label %condContinue__2, label %condFalse__2

condFalse__2:                                     ; preds = %body__4
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %35, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %48, i32 -1)
  br label %condContinue__2

condContinue__2:                                  ; preds = %condFalse__2, %body__4
  store { %Qubit*, %Qubit* }* %36, { %Qubit*, %Qubit* }** %46, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %33, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %33, i32 1)
  store %Array* %33, %Array** %output, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %32, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %35, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %48, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %33, i32 -1)
  br label %exiting__4

exiting__4:                                       ; preds = %condContinue__2
  %49 = add i64 %idxElement, 1
  br label %header__4

exit__4:                                          ; preds = %header__4
  %50 = load %Array*, %Array** %output, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %left, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %right, i32 -1)
  %51 = call i64 @__quantum__rt__array_get_size_1d(%Array* %50)
  %52 = sub i64 %51, 1
  br label %header__5

header__5:                                        ; preds = %exiting__5, %exit__4
  %53 = phi i64 [ 0, %exit__4 ], [ %59, %exiting__5 ]
  %54 = icmp sle i64 %53, %52
  br i1 %54, label %body__5, label %exit__5

body__5:                                          ; preds = %header__5
  %55 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %50, i64 %53)
  %56 = bitcast i8* %55 to { %Qubit*, %Qubit* }**
  %57 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %56, align 8
  %58 = bitcast { %Qubit*, %Qubit* }* %57 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %58, i32 -1)
  br label %exiting__5

exiting__5:                                       ; preds = %body__5
  %59 = add i64 %53, 1
  br label %header__5

exit__5:                                          ; preds = %header__5
  call void @__quantum__rt__array_update_alias_count(%Array* %50, i32 -1)
  %60 = sub i64 %nElements, 1
  br label %header__6

header__6:                                        ; preds = %exiting__6, %exit__5
  %61 = phi i64 [ 0, %exit__5 ], [ %67, %exiting__6 ]
  %62 = icmp sle i64 %61, %60
  br i1 %62, label %body__6, label %exit__6

body__6:                                          ; preds = %header__6
  %63 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 %61)
  %64 = bitcast i8* %63 to { %Qubit*, %Qubit* }**
  %65 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %64, align 8
  %66 = bitcast { %Qubit*, %Qubit* }* %65 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %66, i32 -1)
  br label %exiting__6

exiting__6:                                       ; preds = %body__6
  %67 = add i64 %61, 1
  br label %header__6

exit__6:                                          ; preds = %header__6
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  ret %Array* %50
}

define %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %array) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %array)
  %1 = sub i64 %0, 1
  %2 = load %Range, %Range* @EmptyRange, align 4
  %3 = insertvalue %Range %2, i64 1, 0
  %4 = insertvalue %Range %3, i64 1, 1
  %5 = insertvalue %Range %4, i64 %1, 2
  %6 = call %Array* @__quantum__rt__array_slice_1d(%Array* %array, %Range %5, i1 true)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  ret %Array* %6
}

define void @Microsoft__Quantum__Canon__ApplyCNOTChain__adj(%Array* %qubits) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %0 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %1 = call %Array* @Microsoft__Quantum__Arrays___283fa6e23b0f4b32a19af5a6a52c5177_Most__body(%Array* %qubits)
  %2 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %qubits)
  %3 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %1, %Array* %2)
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__adj(%Callable* %0, %Array* %3)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %0, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %0, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %2, i32 -1)
  %4 = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %5 = sub i64 %4, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %6 = phi i64 [ 0, %entry ], [ %12, %exiting__1 ]
  %7 = icmp sle i64 %6, %5
  br i1 %7, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %8 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 %6)
  %9 = bitcast i8* %8 to { %Qubit*, %Qubit* }**
  %10 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %9, align 8
  %11 = bitcast { %Qubit*, %Qubit* }* %10 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %12 = add i64 %6, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  ret void
}

declare void @__quantum__rt__capture_update_reference_count(%Callable*, i32)

declare void @__quantum__rt__callable_update_reference_count(%Callable*, i32)

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____adj({ %Array* }* %xs, { %Array* }* %ys) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %__qsVar0__nQubits__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %1)
  %6 = call i64 @__quantum__rt__array_get_size_1d(%Array* %4)
  %7 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @21, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %__qsVar0__nQubits__, i64 %6, %String* %7)
  %8 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %1)
  call void @Microsoft__Quantum__Canon__ApplyCNOTChain__body(%Array* %8)
  %9 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %10 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %1)
  %11 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %4)
  %12 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %10, %Array* %11)
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__adj(%Callable* %9, %Array* %12)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %7, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %8, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %9, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %9, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %10, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %11, i32 -1)
  %13 = call i64 @__quantum__rt__array_get_size_1d(%Array* %12)
  %14 = sub i64 %13, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %15 = phi i64 [ 0, %entry ], [ %21, %exiting__1 ]
  %16 = icmp sle i64 %15, %14
  br i1 %16, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %17 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %12, i64 %15)
  %18 = bitcast i8* %17 to { %Qubit*, %Qubit* }**
  %19 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %18, align 8
  %20 = bitcast { %Qubit*, %Qubit* }* %19 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %21 = add i64 %15, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon__ApplyCNOTChain__body(%Array* %qubits) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %0 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %1 = call %Array* @Microsoft__Quantum__Arrays___283fa6e23b0f4b32a19af5a6a52c5177_Most__body(%Array* %qubits)
  %2 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %qubits)
  %3 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %1, %Array* %2)
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__body(%Callable* %0, %Array* %3)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %0, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %0, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %2, i32 -1)
  %4 = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %5 = sub i64 %4, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %6 = phi i64 [ 0, %entry ], [ %12, %exiting__1 ]
  %7 = icmp sle i64 %6, %5
  br i1 %7, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %8 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 %6)
  %9 = bitcast i8* %8 to { %Qubit*, %Qubit* }**
  %10 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %9, align 8
  %11 = bitcast { %Qubit*, %Qubit* }* %10 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %12 = add i64 %6, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__adj(%Callable* %singleElementOperation, %Array* %register) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %register)
  %1 = sub i64 %0, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %2 = phi i64 [ 0, %entry ], [ %8, %exiting__1 ]
  %3 = icmp sle i64 %2, %1
  br i1 %3, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %2)
  %5 = bitcast i8* %4 to { %Qubit*, %Qubit* }**
  %6 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %5, align 8
  %7 = bitcast { %Qubit*, %Qubit* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %8 = add i64 %2, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 1)
  %9 = call %Range @Microsoft__Quantum__Arrays___fa96fdec02544eef8fc1589d871c3b90_IndexRange__body(%Array* %register)
  %10 = extractvalue %Range %9, 0
  %11 = extractvalue %Range %9, 1
  %12 = extractvalue %Range %9, 2
  %13 = sub i64 %12, %10
  %14 = udiv i64 %13, %11
  %15 = mul i64 %11, %14
  %16 = add i64 %10, %15
  %17 = sub i64 0, %11
  %18 = load %Range, %Range* @EmptyRange, align 4
  %19 = insertvalue %Range %18, i64 %16, 0
  %20 = insertvalue %Range %19, i64 %17, 1
  %21 = insertvalue %Range %20, i64 %10, 2
  %22 = extractvalue %Range %21, 0
  %23 = extractvalue %Range %21, 1
  %24 = extractvalue %Range %21, 2
  br label %preheader__1

preheader__1:                                     ; preds = %exit__1
  %25 = icmp sgt i64 %23, 0
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__1
  %__qsVar0__idxQubit__ = phi i64 [ %22, %preheader__1 ], [ %34, %exiting__2 ]
  %26 = icmp sle i64 %__qsVar0__idxQubit__, %24
  %27 = icmp sge i64 %__qsVar0__idxQubit__, %24
  %28 = select i1 %25, i1 %26, i1 %27
  br i1 %28, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %29 = call %Callable* @__quantum__rt__callable_copy(%Callable* %singleElementOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %29)
  %30 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %__qsVar0__idxQubit__)
  %31 = bitcast i8* %30 to { %Qubit*, %Qubit* }**
  %32 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %31, align 8
  %33 = bitcast { %Qubit*, %Qubit* }* %32 to %Tuple*
  call void @__quantum__rt__callable_invoke(%Callable* %29, %Tuple* %33, %Tuple* null)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %29, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %34 = add i64 %__qsVar0__idxQubit__, %23
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  %35 = sub i64 %0, 1
  br label %header__3

header__3:                                        ; preds = %exiting__3, %exit__2
  %36 = phi i64 [ 0, %exit__2 ], [ %42, %exiting__3 ]
  %37 = icmp sle i64 %36, %35
  br i1 %37, label %body__3, label %exit__3

body__3:                                          ; preds = %header__3
  %38 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %36)
  %39 = bitcast i8* %38 to { %Qubit*, %Qubit* }**
  %40 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %39, align 8
  %41 = bitcast { %Qubit*, %Qubit* }* %40 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %41, i32 -1)
  br label %exiting__3

exiting__3:                                       ; preds = %body__3
  %42 = add i64 %36, 1
  br label %header__3

exit__3:                                          ; preds = %header__3
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____ctl(%Array* %__controlQubits__, { { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %nQubits = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %9 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %10 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @22, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %nQubits, i64 %9, %String* %10)
  %11 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %12 = bitcast %Tuple* %11 to { %Callable*, %Array* }*
  %13 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %12, i32 0, i32 0
  %14 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %12, i32 0, i32 1
  %15 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %16 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %3)
  %17 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %7)
  %18 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %16, %Array* %17)
  call void @__quantum__rt__array_update_reference_count(%Array* %16, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %17, i32 -1)
  store %Callable* %15, %Callable** %13, align 8
  store %Array* %18, %Array** %14, align 8
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__ctl(%Array* %__controlQubits__, { %Callable*, %Array* }* %12)
  %19 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %3)
  call void @Microsoft__Quantum__Canon__ApplyCNOTChain__ctladj(%Array* %__controlQubits__, %Array* %19)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %10, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  %20 = call i64 @__quantum__rt__array_get_size_1d(%Array* %18)
  %21 = sub i64 %20, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %22 = phi i64 [ 0, %entry ], [ %28, %exiting__1 ]
  %23 = icmp sle i64 %22, %21
  br i1 %23, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %24 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %18, i64 %22)
  %25 = bitcast i8* %24 to { %Qubit*, %Qubit* }**
  %26 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %25, align 8
  %27 = bitcast { %Qubit*, %Qubit* }* %26 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %28 = add i64 %22, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %19, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__ctl(%Array* %__controlQubits__, { %Callable*, %Array* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %singleElementOperation = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 1)
  %2 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %register = load %Array*, %Array** %2, align 8
  %3 = call i64 @__quantum__rt__array_get_size_1d(%Array* %register)
  %4 = sub i64 %3, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %5 = phi i64 [ 0, %entry ], [ %11, %exiting__1 ]
  %6 = icmp sle i64 %5, %4
  br i1 %6, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %7 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %5)
  %8 = bitcast i8* %7 to { %Qubit*, %Qubit* }**
  %9 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %8, align 8
  %10 = bitcast { %Qubit*, %Qubit* }* %9 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %11 = add i64 %5, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 1)
  %12 = call %Range @Microsoft__Quantum__Arrays___fa96fdec02544eef8fc1589d871c3b90_IndexRange__body(%Array* %register)
  %13 = extractvalue %Range %12, 0
  %14 = extractvalue %Range %12, 1
  %15 = extractvalue %Range %12, 2
  br label %preheader__1

preheader__1:                                     ; preds = %exit__1
  %16 = icmp sgt i64 %14, 0
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__1
  %idxQubit = phi i64 [ %13, %preheader__1 ], [ %29, %exiting__2 ]
  %17 = icmp sle i64 %idxQubit, %15
  %18 = icmp sge i64 %idxQubit, %15
  %19 = select i1 %16, i1 %17, i1 %18
  br i1 %19, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %20 = call %Callable* @__quantum__rt__callable_copy(%Callable* %singleElementOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %20, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %20)
  %21 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %22 = bitcast %Tuple* %21 to { %Array*, { %Qubit*, %Qubit* }* }*
  %23 = getelementptr inbounds { %Array*, { %Qubit*, %Qubit* }* }, { %Array*, { %Qubit*, %Qubit* }* }* %22, i32 0, i32 0
  %24 = getelementptr inbounds { %Array*, { %Qubit*, %Qubit* }* }, { %Array*, { %Qubit*, %Qubit* }* }* %22, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__, i32 1)
  %25 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %idxQubit)
  %26 = bitcast i8* %25 to { %Qubit*, %Qubit* }**
  %27 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %26, align 8
  %28 = bitcast { %Qubit*, %Qubit* }* %27 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %28, i32 1)
  store %Array* %__controlQubits__, %Array** %23, align 8
  store { %Qubit*, %Qubit* }* %27, { %Qubit*, %Qubit* }** %24, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %20, %Tuple* %21, %Tuple* null)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %20, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %20, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %28, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %21, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %29 = add i64 %idxQubit, %14
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  %30 = sub i64 %3, 1
  br label %header__3

header__3:                                        ; preds = %exiting__3, %exit__2
  %31 = phi i64 [ 0, %exit__2 ], [ %37, %exiting__3 ]
  %32 = icmp sle i64 %31, %30
  br i1 %32, label %body__3, label %exit__3

body__3:                                          ; preds = %header__3
  %33 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %31)
  %34 = bitcast i8* %33 to { %Qubit*, %Qubit* }**
  %35 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %34, align 8
  %36 = bitcast { %Qubit*, %Qubit* }* %35 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %36, i32 -1)
  br label %exiting__3

exiting__3:                                       ; preds = %body__3
  %37 = add i64 %31, 1
  br label %header__3

exit__3:                                          ; preds = %header__3
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon__ApplyCNOTChain__ctladj(%Array* %__controlQubits__, %Array* %qubits) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %0 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %1 = bitcast %Tuple* %0 to { %Callable*, %Array* }*
  %2 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %1, i32 0, i32 0
  %3 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %1, i32 0, i32 1
  %4 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %5 = call %Array* @Microsoft__Quantum__Arrays___283fa6e23b0f4b32a19af5a6a52c5177_Most__body(%Array* %qubits)
  %6 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %qubits)
  %7 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %5, %Array* %6)
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  store %Callable* %4, %Callable** %2, align 8
  store %Array* %7, %Array** %3, align 8
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__ctladj(%Array* %__controlQubits__, { %Callable*, %Array* }* %1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %4, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %4, i32 -1)
  %8 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %9 = sub i64 %8, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %10 = phi i64 [ 0, %entry ], [ %16, %exiting__1 ]
  %11 = icmp sle i64 %10, %9
  br i1 %11, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 %10)
  %13 = bitcast i8* %12 to { %Qubit*, %Qubit* }**
  %14 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %13, align 8
  %15 = bitcast { %Qubit*, %Qubit* }* %14 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %15, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %16 = add i64 %10, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %0, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____ctladj(%Array* %__controlQubits__, { { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %__qsVar0__nQubits__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %9 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %10 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @23, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %__qsVar0__nQubits__, i64 %9, %String* %10)
  %11 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %3)
  call void @Microsoft__Quantum__Canon__ApplyCNOTChain__ctl(%Array* %__controlQubits__, %Array* %11)
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Callable*, %Array* }*
  %14 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %13, i32 0, i32 1
  %16 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %17 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %3)
  %18 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %7)
  %19 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %17, %Array* %18)
  call void @__quantum__rt__array_update_reference_count(%Array* %17, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  store %Callable* %16, %Callable** %14, align 8
  store %Array* %19, %Array** %15, align 8
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__ctladj(%Array* %__controlQubits__, { %Callable*, %Array* }* %13)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %10, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %11, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %16, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %16, i32 -1)
  %20 = call i64 @__quantum__rt__array_get_size_1d(%Array* %19)
  %21 = sub i64 %20, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %22 = phi i64 [ 0, %entry ], [ %28, %exiting__1 ]
  %23 = icmp sle i64 %22, %21
  br i1 %23, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %24 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %19, i64 %22)
  %25 = bitcast i8* %24 to { %Qubit*, %Qubit* }**
  %26 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %25, align 8
  %27 = bitcast { %Qubit*, %Qubit* }* %26 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %28 = add i64 %22, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon__ApplyCNOTChain__ctl(%Array* %__controlQubits__, %Array* %qubits) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %0 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %1 = bitcast %Tuple* %0 to { %Callable*, %Array* }*
  %2 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %1, i32 0, i32 0
  %3 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %1, i32 0, i32 1
  %4 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %5 = call %Array* @Microsoft__Quantum__Arrays___283fa6e23b0f4b32a19af5a6a52c5177_Most__body(%Array* %qubits)
  %6 = call %Array* @Microsoft__Quantum__Arrays___a757e20f513d4055bf21197973f4f9c9_Rest__body(%Array* %qubits)
  %7 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %5, %Array* %6)
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  store %Callable* %4, %Callable** %2, align 8
  store %Array* %7, %Array** %3, align 8
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__ctl(%Array* %__controlQubits__, { %Callable*, %Array* }* %1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %4, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %4, i32 -1)
  %8 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %9 = sub i64 %8, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %10 = phi i64 [ 0, %entry ], [ %16, %exiting__1 ]
  %11 = icmp sle i64 %10, %9
  br i1 %11, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 %10)
  %13 = bitcast i8* %12 to { %Qubit*, %Qubit* }**
  %14 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %13, align 8
  %15 = bitcast { %Qubit*, %Qubit* }* %14 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %15, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %16 = add i64 %10, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %0, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__ctladj(%Array* %__controlQubits__, { %Callable*, %Array* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %singleElementOperation = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 1)
  %2 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %register = load %Array*, %Array** %2, align 8
  %3 = call i64 @__quantum__rt__array_get_size_1d(%Array* %register)
  %4 = sub i64 %3, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %5 = phi i64 [ 0, %entry ], [ %11, %exiting__1 ]
  %6 = icmp sle i64 %5, %4
  br i1 %6, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %7 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %5)
  %8 = bitcast i8* %7 to { %Qubit*, %Qubit* }**
  %9 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %8, align 8
  %10 = bitcast { %Qubit*, %Qubit* }* %9 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %11 = add i64 %5, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 1)
  %12 = call %Range @Microsoft__Quantum__Arrays___fa96fdec02544eef8fc1589d871c3b90_IndexRange__body(%Array* %register)
  %13 = extractvalue %Range %12, 0
  %14 = extractvalue %Range %12, 1
  %15 = extractvalue %Range %12, 2
  %16 = sub i64 %15, %13
  %17 = udiv i64 %16, %14
  %18 = mul i64 %14, %17
  %19 = add i64 %13, %18
  %20 = sub i64 0, %14
  %21 = load %Range, %Range* @EmptyRange, align 4
  %22 = insertvalue %Range %21, i64 %19, 0
  %23 = insertvalue %Range %22, i64 %20, 1
  %24 = insertvalue %Range %23, i64 %13, 2
  %25 = extractvalue %Range %24, 0
  %26 = extractvalue %Range %24, 1
  %27 = extractvalue %Range %24, 2
  br label %preheader__1

preheader__1:                                     ; preds = %exit__1
  %28 = icmp sgt i64 %26, 0
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__1
  %__qsVar0__idxQubit__ = phi i64 [ %25, %preheader__1 ], [ %41, %exiting__2 ]
  %29 = icmp sle i64 %__qsVar0__idxQubit__, %27
  %30 = icmp sge i64 %__qsVar0__idxQubit__, %27
  %31 = select i1 %28, i1 %29, i1 %30
  br i1 %31, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %32 = call %Callable* @__quantum__rt__callable_copy(%Callable* %singleElementOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %32, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %32)
  call void @__quantum__rt__callable_make_controlled(%Callable* %32)
  %33 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %34 = bitcast %Tuple* %33 to { %Array*, { %Qubit*, %Qubit* }* }*
  %35 = getelementptr inbounds { %Array*, { %Qubit*, %Qubit* }* }, { %Array*, { %Qubit*, %Qubit* }* }* %34, i32 0, i32 0
  %36 = getelementptr inbounds { %Array*, { %Qubit*, %Qubit* }* }, { %Array*, { %Qubit*, %Qubit* }* }* %34, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__, i32 1)
  %37 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %__qsVar0__idxQubit__)
  %38 = bitcast i8* %37 to { %Qubit*, %Qubit* }**
  %39 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %38, align 8
  %40 = bitcast { %Qubit*, %Qubit* }* %39 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %40, i32 1)
  store %Array* %__controlQubits__, %Array** %35, align 8
  store { %Qubit*, %Qubit* }* %39, { %Qubit*, %Qubit* }** %36, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %32, %Tuple* %33, %Tuple* null)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %32, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %32, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %40, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %41 = add i64 %__qsVar0__idxQubit__, %26
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  %42 = sub i64 %3, 1
  br label %header__3

header__3:                                        ; preds = %exiting__3, %exit__2
  %43 = phi i64 [ 0, %exit__2 ], [ %49, %exiting__3 ]
  %44 = icmp sle i64 %43, %42
  br i1 %44, label %body__3, label %exit__3

body__3:                                          ; preds = %header__3
  %45 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %43)
  %46 = bitcast i8* %45 to { %Qubit*, %Qubit* }**
  %47 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %46, align 8
  %48 = bitcast { %Qubit*, %Qubit* }* %47 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %48, i32 -1)
  br label %exiting__3

exiting__3:                                       ; preds = %body__3
  %49 = add i64 %43, 1
  br label %header__3

exit__3:                                          ; preds = %header__3
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddConstantFxP__body(double %constant, { i64, %Array* }* %fp) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %xs = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %1 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 1)
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %px = load i64, i64* %2, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %xs)
  %ys = call %Array* @__quantum__rt__qubit_allocate_array(i64 %n)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 1)
  %tmpFp = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %px, %Array* %ys)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %tmpFp, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %tmpFp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ %Callable*, double }* getelementptr ({ %Callable*, double }, { %Callable*, double }* null, i32 1) to i64))
  %7 = bitcast %Tuple* %6 to { %Callable*, double }*
  %8 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %7, i32 0, i32 1
  %10 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__PrepareFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  store %Callable* %10, %Callable** %8, align 8
  store double %constant, double* %9, align 8
  %11 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__1, [2 x void (%Tuple*, i32)*]* @MemoryManagement__1, %Tuple* %6)
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Callable*, { i64, %Array* }* }*
  %14 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %13, i32 0, i32 1
  %16 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__AddFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__array_update_reference_count(%Array* %xs, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %1, i32 1)
  store %Callable* %16, %Callable** %14, align 8
  store { i64, %Array* }* %fp, { i64, %Array* }** %15, align 8
  %17 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__2, [2 x void (%Tuple*, i32)*]* @MemoryManagement__2, %Tuple* %12)
  call void @Microsoft__Quantum__Canon___9f62d661957643458f5ddbb073487adf_ApplyWithCA__body(%Callable* %11, %Callable* %17, { i64, %Array* }* %tmpFp)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %17, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %17, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %ys)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___9f62d661957643458f5ddbb073487adf_ApplyWithCA__body(%Callable* %outerOperation, %Callable* %innerOperation, { i64, %Array* }* %target) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %target, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__callable_invoke(%Callable* %outerOperation, %Tuple* %2, %Tuple* null)
  call void @__quantum__rt__callable_invoke(%Callable* %innerOperation, %Tuple* %2, %Tuple* null)
  %3 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %3, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %3)
  call void @__quantum__rt__callable_invoke(%Callable* %3, %Tuple* %2, %Tuple* null)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %3, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__1__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %1 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 1
  %2 = load double, double* %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %4 = bitcast %Tuple* %3 to { double, { i64, %Array* }* }*
  %5 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 1
  store double %2, double* %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %9, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__1__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %1 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 1
  %2 = load double, double* %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %4 = bitcast %Tuple* %3 to { double, { i64, %Array* }* }*
  %5 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 1
  store double %2, double* %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  %10 = call %Callable* @__quantum__rt__callable_copy(%Callable* %9, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %10)
  call void @__quantum__rt__callable_invoke(%Callable* %10, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__1__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %6 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 1
  %7 = load double, double* %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %9 = bitcast %Tuple* %8 to { double, { i64, %Array* }* }*
  %10 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 1
  store double %7, double* %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { double, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { double, { i64, %Array* }* }* %9, { double, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__1__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %6 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 1
  %7 = load double, double* %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %9 = bitcast %Tuple* %8 to { double, { i64, %Array* }* }*
  %10 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 1
  store double %7, double* %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { double, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { double, { i64, %Array* }* }* %9, { double, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__PrepareFxP__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { double, { i64, %Array* }* }*
  %1 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load double, double* %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__body(double %3, { i64, %Array* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__PrepareFxP__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { double, { i64, %Array* }* }*
  %1 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load double, double* %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__adj(double %3, { i64, %Array* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { double, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { double, { i64, %Array* }* }*, { double, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctl(%Array* %3, { double, { i64, %Array* }* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { double, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { double, { i64, %Array* }* }*, { double, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctladj(%Array* %3, { double, { i64, %Array* }* }* %4)
  ret void
}

define void @MemoryManagement__1__RefCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %1 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @MemoryManagement__1__AliasCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %1 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @Lifted__PartialApplication__2__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %5, align 8
  store { i64, %Array* }* %2, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %9, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__2__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %5, align 8
  store { i64, %Array* }* %2, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  %10 = call %Callable* @__quantum__rt__callable_copy(%Callable* %9, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %10)
  call void @__quantum__rt__callable_invoke(%Callable* %10, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__2__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %4, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__2__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %4, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddFxP__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__AddFxP__body({ i64, %Array* }* %3, { i64, %Array* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddFxP__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__AddFxP__adj({ i64, %Array* }* %3, { i64, %Array* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddFxP__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__AddFxP__ctl(%Array* %3, { { i64, %Array* }*, { i64, %Array* }* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddFxP__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__AddFxP__ctladj(%Array* %3, { { i64, %Array* }*, { i64, %Array* }* }* %4)
  ret void
}

define void @MemoryManagement__2__RefCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %4 = load { i64, %Array* }*, { i64, %Array* }** %3, align 8
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %4, i32 0, i32 1
  %6 = load %Array*, %Array** %5, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 %count-change)
  %7 = bitcast { i64, %Array* }* %4 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 %count-change)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @MemoryManagement__2__AliasCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %4 = load { i64, %Array* }*, { i64, %Array* }** %3, align 8
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %4, i32 0, i32 1
  %6 = load %Array*, %Array** %5, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %6, i32 %count-change)
  %7 = bitcast { i64, %Array* }* %4 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 %count-change)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__PrepareFxP__adj(double %constant, { i64, %Array* }* %fp) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__body(double %constant, { i64, %Array* }* %fp)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctl(%Array* %__controlQubits__, { double, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 0
  %constant = load double, double* %1, align 8
  %2 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 1
  %fp = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %q = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 1)
  %4 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %p = load i64, i64* %5, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %q)
  %sign = fcmp olt double %constant, 0.000000e+00
  %6 = sub i64 %n, %p
  %7 = sitofp i64 %6 to double
  %8 = call double @Microsoft__Quantum__Math__PowD__body(double 2.000000e+00, double %7)
  %9 = call double @Microsoft__Quantum__Math__AbsD__body(double %constant)
  %10 = fmul double %8, %9
  %11 = fadd double %10, 5.000000e-01
  %rescaledConstant = alloca double, align 8
  store double %11, double* %rescaledConstant, align 8
  %keepAdding = alloca i1, align 1
  store i1 %sign, i1* %keepAdding, align 1
  %12 = sub i64 %n, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %i = phi i64 [ 0, %entry ], [ %24, %exiting__1 ]
  %13 = icmp sle i64 %i, %12
  br i1 %13, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %14 = load double, double* %rescaledConstant, align 8
  %intConstant = call i64 @Microsoft__Quantum__Math__Floor__body(double %14)
  %15 = fmul double 5.000000e-01, %14
  store double %15, double* %rescaledConstant, align 8
  %16 = and i64 %intConstant, 1
  %17 = select i1 %sign, i64 0, i64 1
  %18 = icmp eq i64 %16, %17
  %currentBit = alloca i1, align 1
  store i1 %18, i1* %currentBit, align 1
  %19 = load i1, i1* %keepAdding, align 1
  br i1 %19, label %then0__1, label %continue__1

then0__1:                                         ; preds = %body__1
  store i1 %18, i1* %keepAdding, align 1
  %20 = xor i1 %18, true
  store i1 %20, i1* %currentBit, align 1
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %body__1
  %21 = load i1, i1* %currentBit, align 1
  br i1 %21, label %then0__2, label %continue__2

then0__2:                                         ; preds = %continue__1
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %22 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %q, i64 %i)
  %23 = bitcast i8* %22 to %Qubit**
  %qubit = load %Qubit*, %Qubit** %23, align 8
  call void @__quantum__qis__x__ctl(%Array* %__controlQubits__, %Qubit* %qubit)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  br label %continue__2

continue__2:                                      ; preds = %then0__2, %continue__1
  br label %exiting__1

exiting__1:                                       ; preds = %continue__2
  %24 = add i64 %i, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctladj(%Array* %__controlQubits__, { double, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 0
  %constant = load double, double* %1, align 8
  %2 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 1
  %fp = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %7 = bitcast %Tuple* %6 to { double, { i64, %Array* }* }*
  %8 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %7, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store double %constant, double* %8, align 8
  store { i64, %Array* }* %fp, { i64, %Array* }** %9, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctl(%Array* %__controlQubits__, { double, { i64, %Array* }* }* %7)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddFxP__body({ i64, %Array* }* %fp1, { i64, %Array* }* %fp2) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 1
  %xs = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %1 = bitcast { i64, %Array* }* %fp1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 1)
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 1
  %ys = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 1)
  %3 = bitcast { i64, %Array* }* %fp2 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 1)
  %4 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 0
  %px = load i64, i64* %4, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 0
  %py = load i64, i64* %5, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %7 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %6, i64 0)
  %8 = bitcast i8* %7 to { i64, %Array* }**
  %9 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %6, i64 1)
  %10 = bitcast i8* %9 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %xs, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %1, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %ys, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 1)
  store { i64, %Array* }* %fp1, { i64, %Array* }** %8, align 8
  store { i64, %Array* }* %fp2, { i64, %Array* }** %10, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalPointPosFactFxP__body(%Array* %6)
  %11 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %xs)
  %12 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %ys)
  call void @Microsoft__Quantum__Arithmetic__AddI__body({ %Array* }* %11, { %Array* }* %12)
  %13 = getelementptr inbounds { %Array* }, { %Array* }* %11, i32 0, i32 0
  %14 = load %Array*, %Array** %13, align 8
  %15 = getelementptr inbounds { %Array* }, { %Array* }* %12, i32 0, i32 0
  %16 = load %Array*, %Array** %15, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 -1)
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %17 = phi i64 [ 0, %entry ], [ %25, %exiting__1 ]
  %18 = icmp sle i64 %17, 1
  br i1 %18, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %19 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %6, i64 %17)
  %20 = bitcast i8* %19 to { i64, %Array* }**
  %21 = load { i64, %Array* }*, { i64, %Array* }** %20, align 8
  %22 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %21, i32 0, i32 1
  %23 = load %Array*, %Array** %22, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %23, i32 -1)
  %24 = bitcast { i64, %Array* }* %21 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %24, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %25 = add i64 %17, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %14, i32 -1)
  %26 = bitcast { %Array* }* %11 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %26, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %16, i32 -1)
  %27 = bitcast { %Array* }* %12 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddFxP__adj({ i64, %Array* }* %fp1, { i64, %Array* }* %fp2) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 1
  %__qsVar1__xs__ = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %1 = bitcast { i64, %Array* }* %fp1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 1)
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 1
  %__qsVar3__ys__ = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 1)
  %3 = bitcast { i64, %Array* }* %fp2 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 1)
  %4 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 0
  %__qsVar0__px__ = load i64, i64* %4, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 0
  %__qsVar2__py__ = load i64, i64* %5, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %7 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %6, i64 0)
  %8 = bitcast i8* %7 to { i64, %Array* }**
  %9 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %6, i64 1)
  %10 = bitcast i8* %9 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar1__xs__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %1, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar3__ys__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 1)
  store { i64, %Array* }* %fp1, { i64, %Array* }** %8, align 8
  store { i64, %Array* }* %fp2, { i64, %Array* }** %10, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalPointPosFactFxP__body(%Array* %6)
  %11 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__qsVar1__xs__)
  %12 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__qsVar3__ys__)
  call void @Microsoft__Quantum__Arithmetic__AddI__adj({ %Array* }* %11, { %Array* }* %12)
  %13 = getelementptr inbounds { %Array* }, { %Array* }* %11, i32 0, i32 0
  %14 = load %Array*, %Array** %13, align 8
  %15 = getelementptr inbounds { %Array* }, { %Array* }* %12, i32 0, i32 0
  %16 = load %Array*, %Array** %15, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 -1)
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %17 = phi i64 [ 0, %entry ], [ %25, %exiting__1 ]
  %18 = icmp sle i64 %17, 1
  br i1 %18, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %19 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %6, i64 %17)
  %20 = bitcast i8* %19 to { i64, %Array* }**
  %21 = load { i64, %Array* }*, { i64, %Array* }** %20, align 8
  %22 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %21, i32 0, i32 1
  %23 = load %Array*, %Array** %22, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %23, i32 -1)
  %24 = bitcast { i64, %Array* }* %21 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %24, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %25 = add i64 %17, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %14, i32 -1)
  %26 = bitcast { %Array* }* %11 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %26, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %16, i32 -1)
  %27 = bitcast { %Array* }* %12 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddFxP__ctl(%Array* %__controlQubits__, { { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %fp1 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 1
  %xs = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %3 = bitcast { i64, %Array* }* %fp1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 1)
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %fp2 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 1
  %ys = load %Array*, %Array** %5, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 1)
  %6 = bitcast { i64, %Array* }* %fp2 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 0
  %px = load i64, i64* %7, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %8 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 0
  %py = load i64, i64* %8, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 1)
  %9 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 0)
  %11 = bitcast i8* %10 to { i64, %Array* }**
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 1)
  %13 = bitcast i8* %12 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %xs, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %ys, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  store { i64, %Array* }* %fp1, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %fp2, { i64, %Array* }** %13, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalPointPosFactFxP__body(%Array* %9)
  %14 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %15 = bitcast %Tuple* %14 to { { %Array* }*, { %Array* }* }*
  %16 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %15, i32 0, i32 0
  %17 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %15, i32 0, i32 1
  %18 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %xs)
  %19 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %ys)
  store { %Array* }* %18, { %Array* }** %16, align 8
  store { %Array* }* %19, { %Array* }** %17, align 8
  call void @Microsoft__Quantum__Arithmetic__AddI__ctl(%Array* %__controlQubits__, { { %Array* }*, { %Array* }* }* %15)
  %20 = getelementptr inbounds { %Array* }, { %Array* }* %18, i32 0, i32 0
  %21 = load %Array*, %Array** %20, align 8
  %22 = getelementptr inbounds { %Array* }, { %Array* }* %19, i32 0, i32 0
  %23 = load %Array*, %Array** %22, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 -1)
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %24 = phi i64 [ 0, %entry ], [ %32, %exiting__1 ]
  %25 = icmp sle i64 %24, 1
  br i1 %25, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %26 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 %24)
  %27 = bitcast i8* %26 to { i64, %Array* }**
  %28 = load { i64, %Array* }*, { i64, %Array* }** %27, align 8
  %29 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %28, i32 0, i32 1
  %30 = load %Array*, %Array** %29, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %30, i32 -1)
  %31 = bitcast { i64, %Array* }* %28 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %31, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %32 = add i64 %24, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %21, i32 -1)
  %33 = bitcast { %Array* }* %18 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %23, i32 -1)
  %34 = bitcast { %Array* }* %19 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %34, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddFxP__ctladj(%Array* %__controlQubits__, { { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %fp1 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 1
  %__qsVar1__xs__ = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %3 = bitcast { i64, %Array* }* %fp1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 1)
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %fp2 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 1
  %__qsVar3__ys__ = load %Array*, %Array** %5, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 1)
  %6 = bitcast { i64, %Array* }* %fp2 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 0
  %__qsVar0__px__ = load i64, i64* %7, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %8 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 0
  %__qsVar2__py__ = load i64, i64* %8, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 1)
  %9 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 0)
  %11 = bitcast i8* %10 to { i64, %Array* }**
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 1)
  %13 = bitcast i8* %12 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar1__xs__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar3__ys__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  store { i64, %Array* }* %fp1, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %fp2, { i64, %Array* }** %13, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalPointPosFactFxP__body(%Array* %9)
  %14 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %15 = bitcast %Tuple* %14 to { { %Array* }*, { %Array* }* }*
  %16 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %15, i32 0, i32 0
  %17 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %15, i32 0, i32 1
  %18 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__qsVar1__xs__)
  %19 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__qsVar3__ys__)
  store { %Array* }* %18, { %Array* }** %16, align 8
  store { %Array* }* %19, { %Array* }** %17, align 8
  call void @Microsoft__Quantum__Arithmetic__AddI__ctladj(%Array* %__controlQubits__, { { %Array* }*, { %Array* }* }* %15)
  %20 = getelementptr inbounds { %Array* }, { %Array* }* %18, i32 0, i32 0
  %21 = load %Array*, %Array** %20, align 8
  %22 = getelementptr inbounds { %Array* }, { %Array* }* %19, i32 0, i32 0
  %23 = load %Array*, %Array** %22, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 -1)
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %24 = phi i64 [ 0, %entry ], [ %32, %exiting__1 ]
  %25 = icmp sle i64 %24, 1
  br i1 %25, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %26 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 %24)
  %27 = bitcast i8* %26 to { i64, %Array* }**
  %28 = load { i64, %Array* }*, { i64, %Array* }** %27, align 8
  %29 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %28, i32 0, i32 1
  %30 = load %Array*, %Array** %29, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %30, i32 -1)
  %31 = bitcast { i64, %Array* }* %28 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %31, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %32 = add i64 %24, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %21, i32 -1)
  %33 = bitcast { %Array* }* %18 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %23, i32 -1)
  %34 = bitcast { %Array* }* %19 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %34, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  ret void
}

declare void @__quantum__rt__callable_invoke(%Callable*, %Tuple*, %Tuple*)

declare %Callable* @__quantum__rt__callable_copy(%Callable*, i1)

declare void @__quantum__rt__callable_make_adjoint(%Callable*)

declare void @__quantum__rt__callable_make_controlled(%Callable*)

declare void @__quantum__rt__capture_update_alias_count(%Callable*, i32)

declare void @__quantum__rt__callable_update_alias_count(%Callable*, i32)

define void @Microsoft__Quantum__Arithmetic__AddConstantFxP__adj(double %constant, { i64, %Array* }* %fp) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %__qsVar1__xs__ = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %1 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 1)
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %__qsVar0__px__ = load i64, i64* %2, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %__qsVar2__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %__qsVar1__xs__)
  %__qsVar3__ys__ = call %Array* @__quantum__rt__qubit_allocate_array(i64 %__qsVar2__n__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 1)
  %__qsVar4__tmpFp__ = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__qsVar0__px__, %Array* %__qsVar3__ys__)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %__qsVar4__tmpFp__, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %__qsVar4__tmpFp__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ %Callable*, double }* getelementptr ({ %Callable*, double }, { %Callable*, double }* null, i32 1) to i64))
  %7 = bitcast %Tuple* %6 to { %Callable*, double }*
  %8 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %7, i32 0, i32 1
  %10 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__PrepareFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  store %Callable* %10, %Callable** %8, align 8
  store double %constant, double* %9, align 8
  %11 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__3, [2 x void (%Tuple*, i32)*]* @MemoryManagement__1, %Tuple* %6)
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Callable*, { i64, %Array* }* }*
  %14 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %13, i32 0, i32 1
  %16 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__AddFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar1__xs__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %1, i32 1)
  store %Callable* %16, %Callable** %14, align 8
  store { i64, %Array* }* %fp, { i64, %Array* }** %15, align 8
  %17 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__4, [2 x void (%Tuple*, i32)*]* @MemoryManagement__2, %Tuple* %12)
  call void @Microsoft__Quantum__Canon___9f62d661957643458f5ddbb073487adf_ApplyWithCA__adj(%Callable* %11, %Callable* %17, { i64, %Array* }* %__qsVar4__tmpFp__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %17, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %17, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %__qsVar3__ys__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___9f62d661957643458f5ddbb073487adf_ApplyWithCA__adj(%Callable* %outerOperation, %Callable* %innerOperation, { i64, %Array* }* %target) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %target, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %3, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %3)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %3)
  call void @__quantum__rt__callable_invoke(%Callable* %3, %Tuple* %2, %Tuple* null)
  %4 = call %Callable* @__quantum__rt__callable_copy(%Callable* %innerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %4, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %4)
  call void @__quantum__rt__callable_invoke(%Callable* %4, %Tuple* %2, %Tuple* null)
  %5 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %5, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %5)
  call void @__quantum__rt__callable_invoke(%Callable* %5, %Tuple* %2, %Tuple* null)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %3, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %4, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %4, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %5, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %5, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__3__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %1 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 1
  %2 = load double, double* %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %4 = bitcast %Tuple* %3 to { double, { i64, %Array* }* }*
  %5 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 1
  store double %2, double* %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %9, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__3__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %1 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 1
  %2 = load double, double* %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %4 = bitcast %Tuple* %3 to { double, { i64, %Array* }* }*
  %5 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 1
  store double %2, double* %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  %10 = call %Callable* @__quantum__rt__callable_copy(%Callable* %9, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %10)
  call void @__quantum__rt__callable_invoke(%Callable* %10, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__3__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %6 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 1
  %7 = load double, double* %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %9 = bitcast %Tuple* %8 to { double, { i64, %Array* }* }*
  %10 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 1
  store double %7, double* %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { double, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { double, { i64, %Array* }* }* %9, { double, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__3__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %6 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 1
  %7 = load double, double* %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %9 = bitcast %Tuple* %8 to { double, { i64, %Array* }* }*
  %10 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 1
  store double %7, double* %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { double, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { double, { i64, %Array* }* }* %9, { double, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__4__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %5, align 8
  store { i64, %Array* }* %2, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %9, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__4__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %5, align 8
  store { i64, %Array* }* %2, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  %10 = call %Callable* @__quantum__rt__callable_copy(%Callable* %9, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %10)
  call void @__quantum__rt__callable_invoke(%Callable* %10, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__4__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %4, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__4__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %4, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddConstantFxP__ctl(%Array* %__controlQubits__, { double, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 0
  %constant = load double, double* %1, align 8
  %2 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 1
  %fp = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %xs = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %4 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %px = load i64, i64* %5, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %xs)
  %ys = call %Array* @__quantum__rt__qubit_allocate_array(i64 %n)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 1)
  %tmpFp = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %px, %Array* %ys)
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %tmpFp, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %tmpFp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %10 = bitcast %Tuple* %9 to { %Callable*, %Callable*, { i64, %Array* }* }*
  %11 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %10, i32 0, i32 0
  %12 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %10, i32 0, i32 1
  %13 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %10, i32 0, i32 2
  %14 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ %Callable*, double }* getelementptr ({ %Callable*, double }, { %Callable*, double }* null, i32 1) to i64))
  %15 = bitcast %Tuple* %14 to { %Callable*, double }*
  %16 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %15, i32 0, i32 0
  %17 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %15, i32 0, i32 1
  %18 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__PrepareFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  store %Callable* %18, %Callable** %16, align 8
  store double %constant, double* %17, align 8
  %19 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__5, [2 x void (%Tuple*, i32)*]* @MemoryManagement__1, %Tuple* %14)
  %20 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %21 = bitcast %Tuple* %20 to { %Callable*, { i64, %Array* }* }*
  %22 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %21, i32 0, i32 0
  %23 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %21, i32 0, i32 1
  %24 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__AddFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__array_update_reference_count(%Array* %xs, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  store %Callable* %24, %Callable** %22, align 8
  store { i64, %Array* }* %fp, { i64, %Array* }** %23, align 8
  %25 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__6, [2 x void (%Tuple*, i32)*]* @MemoryManagement__2, %Tuple* %20)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store %Callable* %19, %Callable** %11, align 8
  store %Callable* %25, %Callable** %12, align 8
  store { i64, %Array* }* %tmpFp, { i64, %Array* }** %13, align 8
  call void @Microsoft__Quantum__Canon___9f62d661957643458f5ddbb073487adf_ApplyWithCA__ctl(%Array* %__controlQubits__, { %Callable*, %Callable*, { i64, %Array* }* }* %10)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %19, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %19, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %25, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %25, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %9, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %ys)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___9f62d661957643458f5ddbb073487adf_ApplyWithCA__ctl(%Array* %controlRegister, { %Callable*, %Callable*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 1)
  %1 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %outerOperation = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  %2 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %innerOperation = load %Callable*, %Callable** %2, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %3 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %0, i32 0, i32 2
  %target = load { i64, %Array* }*, { i64, %Array* }** %3, align 8
  %4 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %target, i32 0, i32 1
  %5 = load %Array*, %Array** %4, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 1)
  %6 = bitcast { i64, %Array* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  call void @__quantum__rt__callable_invoke(%Callable* %outerOperation, %Tuple* %6, %Tuple* null)
  %7 = call %Callable* @__quantum__rt__callable_copy(%Callable* %innerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %7, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %7)
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %9, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  store %Array* %controlRegister, %Array** %10, align 8
  store { i64, %Array* }* %target, { i64, %Array* }** %11, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %7, %Tuple* %8, %Tuple* null)
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* null)
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %7, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %7, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__5__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %1 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 1
  %2 = load double, double* %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %4 = bitcast %Tuple* %3 to { double, { i64, %Array* }* }*
  %5 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 1
  store double %2, double* %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %9, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__5__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %1 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 1
  %2 = load double, double* %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %4 = bitcast %Tuple* %3 to { double, { i64, %Array* }* }*
  %5 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 1
  store double %2, double* %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  %10 = call %Callable* @__quantum__rt__callable_copy(%Callable* %9, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %10)
  call void @__quantum__rt__callable_invoke(%Callable* %10, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__5__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %6 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 1
  %7 = load double, double* %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %9 = bitcast %Tuple* %8 to { double, { i64, %Array* }* }*
  %10 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 1
  store double %7, double* %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { double, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { double, { i64, %Array* }* }* %9, { double, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__5__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %6 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 1
  %7 = load double, double* %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %9 = bitcast %Tuple* %8 to { double, { i64, %Array* }* }*
  %10 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 1
  store double %7, double* %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { double, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { double, { i64, %Array* }* }* %9, { double, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__6__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %5, align 8
  store { i64, %Array* }* %2, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %9, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__6__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %5, align 8
  store { i64, %Array* }* %2, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  %10 = call %Callable* @__quantum__rt__callable_copy(%Callable* %9, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %10)
  call void @__quantum__rt__callable_invoke(%Callable* %10, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__6__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %4, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__6__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %4, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddConstantFxP__ctladj(%Array* %__controlQubits__, { double, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 0
  %constant = load double, double* %1, align 8
  %2 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %0, i32 0, i32 1
  %fp = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %__qsVar1__xs__ = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %4 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %__qsVar0__px__ = load i64, i64* %5, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %__qsVar2__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %__qsVar1__xs__)
  %__qsVar3__ys__ = call %Array* @__quantum__rt__qubit_allocate_array(i64 %__qsVar2__n__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 1)
  %__qsVar4__tmpFp__ = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__qsVar0__px__, %Array* %__qsVar3__ys__)
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %__qsVar4__tmpFp__, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %__qsVar4__tmpFp__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %10 = bitcast %Tuple* %9 to { %Callable*, %Callable*, { i64, %Array* }* }*
  %11 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %10, i32 0, i32 0
  %12 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %10, i32 0, i32 1
  %13 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %10, i32 0, i32 2
  %14 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ %Callable*, double }* getelementptr ({ %Callable*, double }, { %Callable*, double }* null, i32 1) to i64))
  %15 = bitcast %Tuple* %14 to { %Callable*, double }*
  %16 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %15, i32 0, i32 0
  %17 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %15, i32 0, i32 1
  %18 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__PrepareFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  store %Callable* %18, %Callable** %16, align 8
  store double %constant, double* %17, align 8
  %19 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__7, [2 x void (%Tuple*, i32)*]* @MemoryManagement__1, %Tuple* %14)
  %20 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %21 = bitcast %Tuple* %20 to { %Callable*, { i64, %Array* }* }*
  %22 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %21, i32 0, i32 0
  %23 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %21, i32 0, i32 1
  %24 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__AddFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar1__xs__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  store %Callable* %24, %Callable** %22, align 8
  store { i64, %Array* }* %fp, { i64, %Array* }** %23, align 8
  %25 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__8, [2 x void (%Tuple*, i32)*]* @MemoryManagement__2, %Tuple* %20)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store %Callable* %19, %Callable** %11, align 8
  store %Callable* %25, %Callable** %12, align 8
  store { i64, %Array* }* %__qsVar4__tmpFp__, { i64, %Array* }** %13, align 8
  call void @Microsoft__Quantum__Canon___9f62d661957643458f5ddbb073487adf_ApplyWithCA__ctladj(%Array* %__controlQubits__, { %Callable*, %Callable*, { i64, %Array* }* }* %10)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %19, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %19, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %25, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %25, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %9, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %__qsVar3__ys__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___9f62d661957643458f5ddbb073487adf_ApplyWithCA__ctladj(%Array* %controlRegister, { %Callable*, %Callable*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 1)
  %1 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %outerOperation = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  %2 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %innerOperation = load %Callable*, %Callable** %2, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %3 = getelementptr inbounds { %Callable*, %Callable*, { i64, %Array* }* }, { %Callable*, %Callable*, { i64, %Array* }* }* %0, i32 0, i32 2
  %target = load { i64, %Array* }*, { i64, %Array* }** %3, align 8
  %4 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %target, i32 0, i32 1
  %5 = load %Array*, %Array** %4, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 1)
  %6 = bitcast { i64, %Array* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %7, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %7)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %7)
  call void @__quantum__rt__callable_invoke(%Callable* %7, %Tuple* %6, %Tuple* null)
  %8 = call %Callable* @__quantum__rt__callable_copy(%Callable* %innerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %8, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %8)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %8)
  %9 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %10 = bitcast %Tuple* %9 to { %Array*, { i64, %Array* }* }*
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %10, i32 0, i32 0
  %12 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %10, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  store %Array* %controlRegister, %Array** %11, align 8
  store { i64, %Array* }* %target, { i64, %Array* }** %12, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %8, %Tuple* %9, %Tuple* null)
  %13 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %13, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %13)
  call void @__quantum__rt__callable_invoke(%Callable* %13, %Tuple* %6, %Tuple* null)
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %7, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %7, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %8, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %9, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %13, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %13, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__7__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %1 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 1
  %2 = load double, double* %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %4 = bitcast %Tuple* %3 to { double, { i64, %Array* }* }*
  %5 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 1
  store double %2, double* %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %9, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__7__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %1 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 1
  %2 = load double, double* %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %4 = bitcast %Tuple* %3 to { double, { i64, %Array* }* }*
  %5 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %4, i32 0, i32 1
  store double %2, double* %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  %10 = call %Callable* @__quantum__rt__callable_copy(%Callable* %9, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %10)
  call void @__quantum__rt__callable_invoke(%Callable* %10, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__7__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %6 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 1
  %7 = load double, double* %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %9 = bitcast %Tuple* %8 to { double, { i64, %Array* }* }*
  %10 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 1
  store double %7, double* %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { double, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { double, { i64, %Array* }* }* %9, { double, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__7__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, double }*
  %6 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 1
  %7 = load double, double* %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %9 = bitcast %Tuple* %8 to { double, { i64, %Array* }* }*
  %10 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %9, i32 0, i32 1
  store double %7, double* %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { double, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { double, { i64, %Array* }* }* }, { %Array*, { double, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { double, { i64, %Array* }* }* %9, { double, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, double }, { %Callable*, double }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__8__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %5, align 8
  store { i64, %Array* }* %2, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %9, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__8__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %5, align 8
  store { i64, %Array* }* %2, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  %10 = call %Callable* @__quantum__rt__callable_copy(%Callable* %9, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %10)
  call void @__quantum__rt__callable_invoke(%Callable* %10, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__8__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %4, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__8__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %4, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__IdenticalPointPosFactFxP__body(%Array* %fixedPoints) {
entry:
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %fixedPoints)
  %1 = sub i64 %0, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %2 = phi i64 [ 0, %entry ], [ %10, %exiting__1 ]
  %3 = icmp sle i64 %2, %1
  br i1 %3, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %fixedPoints, i64 %2)
  %5 = bitcast i8* %4 to { i64, %Array* }**
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %6, i32 0, i32 1
  %8 = load %Array*, %Array** %7, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 1)
  %9 = bitcast { i64, %Array* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %10 = add i64 %2, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %fixedPoints, i32 1)
  %11 = icmp eq i64 %0, 0
  br i1 %11, label %then0__1, label %continue__1

then0__1:                                         ; preds = %exit__1
  %12 = sub i64 %0, 1
  br label %header__2

continue__1:                                      ; preds = %exit__1
  %13 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %fixedPoints, i64 0)
  %14 = bitcast i8* %13 to { i64, %Array* }**
  %15 = load { i64, %Array* }*, { i64, %Array* }** %14, align 8
  %16 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %15, i32 0, i32 0
  %position = load i64, i64* %16, align 4
  %17 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %15, i32 0, i32 1
  %register = load %Array*, %Array** %17, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 1)
  %18 = icmp sgt i64 %position, 0
  %19 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @31, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__Fact__body(i1 %18, %String* %19)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %register)
  %20 = call %Array* @Microsoft__Quantum__Arrays___a5a25c88e98b4395a077e1efe49da681_Most__body(%Array* %fixedPoints)
  %21 = call i64 @__quantum__rt__array_get_size_1d(%Array* %20)
  %22 = sub i64 %21, 1
  br label %header__3

header__2:                                        ; preds = %exiting__2, %then0__1
  %23 = phi i64 [ 0, %then0__1 ], [ %31, %exiting__2 ]
  %24 = icmp sle i64 %23, %12
  br i1 %24, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %25 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %fixedPoints, i64 %23)
  %26 = bitcast i8* %25 to { i64, %Array* }**
  %27 = load { i64, %Array* }*, { i64, %Array* }** %26, align 8
  %28 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %27, i32 0, i32 1
  %29 = load %Array*, %Array** %28, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %29, i32 -1)
  %30 = bitcast { i64, %Array* }* %27 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %30, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %31 = add i64 %23, 1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %fixedPoints, i32 -1)
  ret void

header__3:                                        ; preds = %exiting__3, %continue__1
  %32 = phi i64 [ 0, %continue__1 ], [ %43, %exiting__3 ]
  %33 = icmp sle i64 %32, %22
  br i1 %33, label %body__3, label %exit__3

body__3:                                          ; preds = %header__3
  %34 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %20, i64 %32)
  %35 = bitcast i8* %34 to { i64, %Array* }**
  %fp = load { i64, %Array* }*, { i64, %Array* }** %35, align 8
  %36 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %reg = load %Array*, %Array** %36, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %reg, i32 1)
  %37 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %37, i32 1)
  %38 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %pos = load i64, i64* %38, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %reg, i32 1)
  %39 = call i64 @__quantum__rt__array_get_size_1d(%Array* %reg)
  %40 = sub i64 %39, %pos
  %41 = sub i64 %n, %position
  %42 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([56 x i8], [56 x i8]* @32, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %40, i64 %41, %String* %42)
  call void @__quantum__rt__array_update_alias_count(%Array* %reg, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %37, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %reg, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %42, i32 -1)
  br label %exiting__3

exiting__3:                                       ; preds = %body__3
  %43 = add i64 %32, 1
  br label %header__3

exit__3:                                          ; preds = %header__3
  %44 = sub i64 %0, 1
  br label %header__4

header__4:                                        ; preds = %exiting__4, %exit__3
  %45 = phi i64 [ 0, %exit__3 ], [ %53, %exiting__4 ]
  %46 = icmp sle i64 %45, %44
  br i1 %46, label %body__4, label %exit__4

body__4:                                          ; preds = %header__4
  %47 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %fixedPoints, i64 %45)
  %48 = bitcast i8* %47 to { i64, %Array* }**
  %49 = load { i64, %Array* }*, { i64, %Array* }** %48, align 8
  %50 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %49, i32 0, i32 1
  %51 = load %Array*, %Array** %50, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %51, i32 -1)
  %52 = bitcast { i64, %Array* }* %49 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %52, i32 -1)
  br label %exiting__4

exiting__4:                                       ; preds = %body__4
  %53 = add i64 %45, 1
  br label %header__4

exit__4:                                          ; preds = %header__4
  call void @__quantum__rt__array_update_alias_count(%Array* %fixedPoints, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %19, i32 -1)
  %54 = sub i64 %21, 1
  br label %header__5

header__5:                                        ; preds = %exiting__5, %exit__4
  %55 = phi i64 [ 0, %exit__4 ], [ %63, %exiting__5 ]
  %56 = icmp sle i64 %55, %54
  br i1 %56, label %body__5, label %exit__5

body__5:                                          ; preds = %header__5
  %57 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %20, i64 %55)
  %58 = bitcast i8* %57 to { i64, %Array* }**
  %59 = load { i64, %Array* }*, { i64, %Array* }** %58, align 8
  %60 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %59, i32 0, i32 1
  %61 = load %Array*, %Array** %60, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %61, i32 -1)
  %62 = bitcast { i64, %Array* }* %59 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %62, i32 -1)
  br label %exiting__5

exiting__5:                                       ; preds = %body__5
  %63 = add i64 %55, 1
  br label %header__5

exit__5:                                          ; preds = %header__5
  call void @__quantum__rt__array_update_reference_count(%Array* %20, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddI__body({ %Array* }* %xs, { %Array* }* %ys) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call i64 @__quantum__rt__array_get_size_1d(%Array* %1)
  %7 = call i64 @__quantum__rt__array_get_size_1d(%Array* %4)
  %8 = icmp eq i64 %6, %7
  br i1 %8, label %then0__1, label %test1__1

then0__1:                                         ; preds = %entry
  call void @Microsoft__Quantum__Arithmetic__RippleCarryAdderNoCarryTTK__body({ %Array* }* %xs, { %Array* }* %ys)
  br label %continue__1

test1__1:                                         ; preds = %entry
  %9 = icmp sgt i64 %7, %6
  br i1 %9, label %then1__1, label %else__1

then1__1:                                         ; preds = %test1__1
  %10 = sub i64 %7, %6
  %11 = sub i64 %10, 1
  %qs = call %Array* @__quantum__rt__qubit_allocate_array(i64 %11)
  call void @__quantum__rt__array_update_alias_count(%Array* %qs, i32 1)
  %12 = call %Array* @__quantum__rt__array_concatenate(%Array* %1, %Array* %qs)
  %13 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %12)
  %14 = call %Array* @Microsoft__Quantum__Arrays___283fa6e23b0f4b32a19af5a6a52c5177_Most__body(%Array* %4)
  %15 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %14)
  %16 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %4)
  call void @Microsoft__Quantum__Arithmetic__RippleCarryAdderTTK__body({ %Array* }* %13, { %Array* }* %15, %Qubit* %16)
  %17 = getelementptr inbounds { %Array* }, { %Array* }* %13, i32 0, i32 0
  %18 = load %Array*, %Array** %17, align 8
  %19 = getelementptr inbounds { %Array* }, { %Array* }* %15, i32 0, i32 0
  %20 = load %Array*, %Array** %19, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %qs, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  %21 = bitcast { %Array* }* %13 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %21, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %14, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %20, i32 -1)
  %22 = bitcast { %Array* }* %15 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %22, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %qs)
  br label %continue__1

else__1:                                          ; preds = %test1__1
  %23 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([41 x i8], [41 x i8]* @24, i32 0, i32 0))
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__fail(%String* %23)
  unreachable

continue__1:                                      ; preds = %then1__1, %then0__1
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  ret void
}

define { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__Item1__) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__Item1__, i32 1)
  %0 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64))
  %1 = bitcast %Tuple* %0 to { %Array* }*
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  store %Array* %__Item1__, %Array** %2, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %__Item1__, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__Item1__, i32 -1)
  ret { %Array* }* %1
}

define void @Microsoft__Quantum__Arithmetic__AddI__adj({ %Array* }* %xs, { %Array* }* %ys) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call i64 @__quantum__rt__array_get_size_1d(%Array* %1)
  %7 = call i64 @__quantum__rt__array_get_size_1d(%Array* %4)
  %8 = icmp eq i64 %6, %7
  br i1 %8, label %then0__1, label %test1__1

then0__1:                                         ; preds = %entry
  call void @Microsoft__Quantum__Arithmetic__RippleCarryAdderNoCarryTTK__adj({ %Array* }* %xs, { %Array* }* %ys)
  br label %continue__1

test1__1:                                         ; preds = %entry
  %9 = icmp sgt i64 %7, %6
  br i1 %9, label %then1__1, label %else__1

then1__1:                                         ; preds = %test1__1
  %10 = sub i64 %7, %6
  %11 = sub i64 %10, 1
  %__qsVar0__qs__ = call %Array* @__quantum__rt__qubit_allocate_array(i64 %11)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar0__qs__, i32 1)
  %12 = call %Array* @__quantum__rt__array_concatenate(%Array* %1, %Array* %__qsVar0__qs__)
  %13 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %12)
  %14 = call %Array* @Microsoft__Quantum__Arrays___283fa6e23b0f4b32a19af5a6a52c5177_Most__body(%Array* %4)
  %15 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %14)
  %16 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %4)
  call void @Microsoft__Quantum__Arithmetic__RippleCarryAdderTTK__adj({ %Array* }* %13, { %Array* }* %15, %Qubit* %16)
  %17 = getelementptr inbounds { %Array* }, { %Array* }* %13, i32 0, i32 0
  %18 = load %Array*, %Array** %17, align 8
  %19 = getelementptr inbounds { %Array* }, { %Array* }* %15, i32 0, i32 0
  %20 = load %Array*, %Array** %19, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar0__qs__, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  %21 = bitcast { %Array* }* %13 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %21, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %14, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %20, i32 -1)
  %22 = bitcast { %Array* }* %15 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %22, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %__qsVar0__qs__)
  br label %continue__1

else__1:                                          ; preds = %test1__1
  %23 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([41 x i8], [41 x i8]* @25, i32 0, i32 0))
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__fail(%String* %23)
  unreachable

continue__1:                                      ; preds = %then1__1, %then0__1
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddI__ctl(%Array* %__controlQubits__, { { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %10 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %11 = icmp eq i64 %9, %10
  br i1 %11, label %then0__1, label %test1__1

then0__1:                                         ; preds = %entry
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %13, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { %Array* }* %xs, { %Array* }** %14, align 8
  store { %Array* }* %ys, { %Array* }** %15, align 8
  call void @Microsoft__Quantum__Arithmetic__RippleCarryAdderNoCarryTTK__ctl(%Array* %__controlQubits__, { { %Array* }*, { %Array* }* }* %13)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  br label %continue__1

test1__1:                                         ; preds = %entry
  %16 = icmp sgt i64 %10, %9
  br i1 %16, label %then1__1, label %else__1

then1__1:                                         ; preds = %test1__1
  %17 = sub i64 %10, %9
  %18 = sub i64 %17, 1
  %qs = call %Array* @__quantum__rt__qubit_allocate_array(i64 %18)
  call void @__quantum__rt__array_update_alias_count(%Array* %qs, i32 1)
  %19 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %20 = bitcast %Tuple* %19 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %21 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %20, i32 0, i32 0
  %22 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %20, i32 0, i32 1
  %23 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %20, i32 0, i32 2
  %24 = call %Array* @__quantum__rt__array_concatenate(%Array* %3, %Array* %qs)
  %25 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %24)
  call void @__quantum__rt__array_update_reference_count(%Array* %24, i32 -1)
  %26 = call %Array* @Microsoft__Quantum__Arrays___283fa6e23b0f4b32a19af5a6a52c5177_Most__body(%Array* %7)
  %27 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %26)
  call void @__quantum__rt__array_update_reference_count(%Array* %26, i32 -1)
  %28 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %7)
  store { %Array* }* %25, { %Array* }** %21, align 8
  store { %Array* }* %27, { %Array* }** %22, align 8
  store %Qubit* %28, %Qubit** %23, align 8
  call void @Microsoft__Quantum__Arithmetic__RippleCarryAdderTTK__ctl(%Array* %__controlQubits__, { { %Array* }*, { %Array* }*, %Qubit* }* %20)
  %29 = getelementptr inbounds { %Array* }, { %Array* }* %25, i32 0, i32 0
  %30 = load %Array*, %Array** %29, align 8
  %31 = getelementptr inbounds { %Array* }, { %Array* }* %27, i32 0, i32 0
  %32 = load %Array*, %Array** %31, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %qs, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %30, i32 -1)
  %33 = bitcast { %Array* }* %25 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %32, i32 -1)
  %34 = bitcast { %Array* }* %27 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %34, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %qs)
  br label %continue__1

else__1:                                          ; preds = %test1__1
  %35 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([41 x i8], [41 x i8]* @26, i32 0, i32 0))
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__fail(%String* %35)
  unreachable

continue__1:                                      ; preds = %then1__1, %then0__1
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AddI__ctladj(%Array* %__controlQubits__, { { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %10 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %11 = icmp eq i64 %9, %10
  br i1 %11, label %then0__1, label %test1__1

then0__1:                                         ; preds = %entry
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %13, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { %Array* }* %xs, { %Array* }** %14, align 8
  store { %Array* }* %ys, { %Array* }** %15, align 8
  call void @Microsoft__Quantum__Arithmetic__RippleCarryAdderNoCarryTTK__ctladj(%Array* %__controlQubits__, { { %Array* }*, { %Array* }* }* %13)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  br label %continue__1

test1__1:                                         ; preds = %entry
  %16 = icmp sgt i64 %10, %9
  br i1 %16, label %then1__1, label %else__1

then1__1:                                         ; preds = %test1__1
  %17 = sub i64 %10, %9
  %18 = sub i64 %17, 1
  %__qsVar0__qs__ = call %Array* @__quantum__rt__qubit_allocate_array(i64 %18)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar0__qs__, i32 1)
  %19 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %20 = bitcast %Tuple* %19 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %21 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %20, i32 0, i32 0
  %22 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %20, i32 0, i32 1
  %23 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %20, i32 0, i32 2
  %24 = call %Array* @__quantum__rt__array_concatenate(%Array* %3, %Array* %__qsVar0__qs__)
  %25 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %24)
  call void @__quantum__rt__array_update_reference_count(%Array* %24, i32 -1)
  %26 = call %Array* @Microsoft__Quantum__Arrays___283fa6e23b0f4b32a19af5a6a52c5177_Most__body(%Array* %7)
  %27 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %26)
  call void @__quantum__rt__array_update_reference_count(%Array* %26, i32 -1)
  %28 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %7)
  store { %Array* }* %25, { %Array* }** %21, align 8
  store { %Array* }* %27, { %Array* }** %22, align 8
  store %Qubit* %28, %Qubit** %23, align 8
  call void @Microsoft__Quantum__Arithmetic__RippleCarryAdderTTK__ctladj(%Array* %__controlQubits__, { { %Array* }*, { %Array* }*, %Qubit* }* %20)
  %29 = getelementptr inbounds { %Array* }, { %Array* }* %25, i32 0, i32 0
  %30 = load %Array*, %Array** %29, align 8
  %31 = getelementptr inbounds { %Array* }, { %Array* }* %27, i32 0, i32 0
  %32 = load %Array*, %Array** %31, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar0__qs__, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %30, i32 -1)
  %33 = bitcast { %Array* }* %25 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %32, i32 -1)
  %34 = bitcast { %Array* }* %27 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %34, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %__qsVar0__qs__)
  br label %continue__1

else__1:                                          ; preds = %test1__1
  %35 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([41 x i8], [41 x i8]* @27, i32 0, i32 0))
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__fail(%String* %35)
  unreachable

continue__1:                                      ; preds = %then1__1, %then0__1
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__RippleCarryAdderNoCarryTTK__body({ %Array* }* %xs, { %Array* }* %ys) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %nQubits = call i64 @__quantum__rt__array_get_size_1d(%Array* %1)
  %6 = call i64 @__quantum__rt__array_get_size_1d(%Array* %4)
  %7 = icmp eq i64 %nQubits, %6
  %8 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @41, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactB__body(i1 %7, i1 true, %String* %8)
  %9 = icmp sgt i64 %nQubits, 1
  br i1 %9, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  %10 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %11 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %13, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { %Array* }* %xs, { %Array* }** %14, align 8
  store { %Array* }* %ys, { %Array* }** %15, align 8
  call void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__body(%Callable* %10, %Callable* %11, { { %Array* }*, { %Array* }* }* %13)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  %16 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %1, i64 0)
  %17 = bitcast i8* %16 to %Qubit**
  %18 = load %Qubit*, %Qubit** %17, align 8
  %19 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %4, i64 0)
  %20 = bitcast i8* %19 to %Qubit**
  %21 = load %Qubit*, %Qubit** %20, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %18, %Qubit* %21)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %8, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__RippleCarryAdderTTK__body({ %Array* }* %xs, { %Array* }* %ys, %Qubit* %carry) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %nQubits = call i64 @__quantum__rt__array_get_size_1d(%Array* %1)
  %6 = call i64 @__quantum__rt__array_get_size_1d(%Array* %4)
  %7 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @45, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %nQubits, i64 %6, %String* %7)
  %8 = icmp sgt i64 %nQubits, 1
  br i1 %8, label %then0__1, label %else__1

then0__1:                                         ; preds = %entry
  %9 = sub i64 %nQubits, 1
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %1, i64 %9)
  %11 = bitcast i8* %10 to %Qubit**
  %12 = load %Qubit*, %Qubit** %11, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %12, %Qubit* %carry)
  %13 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %14 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %15 = bitcast %Tuple* %14 to { %Callable*, %Qubit* }*
  %16 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %15, i32 0, i32 0
  %17 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %15, i32 0, i32 1
  %18 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  store %Callable* %18, %Callable** %16, align 8
  store %Qubit* %carry, %Qubit** %17, align 8
  %19 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__19, [2 x void (%Tuple*, i32)*]* @MemoryManagement__7, %Tuple* %14)
  %20 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %21 = bitcast %Tuple* %20 to { { %Array* }*, { %Array* }* }*
  %22 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %21, i32 0, i32 0
  %23 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %21, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { %Array* }* %xs, { %Array* }** %22, align 8
  store { %Array* }* %ys, { %Array* }** %23, align 8
  call void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__body(%Callable* %13, %Callable* %19, { { %Array* }*, { %Array* }* }* %21)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %13, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %13, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %19, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %19, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  br label %continue__1

else__1:                                          ; preds = %entry
  %24 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %1, i64 0)
  %25 = bitcast i8* %24 to %Qubit**
  %26 = load %Qubit*, %Qubit** %25, align 8
  %27 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %4, i64 0)
  %28 = bitcast i8* %27 to %Qubit**
  %29 = load %Qubit*, %Qubit** %28, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__body(%Qubit* %26, %Qubit* %29, %Qubit* %carry)
  br label %continue__1

continue__1:                                      ; preds = %else__1, %then0__1
  %30 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %1, i64 0)
  %31 = bitcast i8* %30 to %Qubit**
  %32 = load %Qubit*, %Qubit** %31, align 8
  %33 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %4, i64 0)
  %34 = bitcast i8* %33 to %Qubit**
  %35 = load %Qubit*, %Qubit** %34, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %32, %Qubit* %35)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %7, i32 -1)
  ret void
}

define %Array* @Microsoft__Quantum__Arrays___283fa6e23b0f4b32a19af5a6a52c5177_Most__body(%Array* %array) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %array)
  %1 = sub i64 %0, 2
  %2 = load %Range, %Range* @EmptyRange, align 4
  %3 = insertvalue %Range %2, i64 0, 0
  %4 = insertvalue %Range %3, i64 1, 1
  %5 = insertvalue %Range %4, i64 %1, 2
  %6 = call %Array* @__quantum__rt__array_slice_1d(%Array* %array, %Range %5, i1 true)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  ret %Array* %6
}

define %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %array) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %array)
  %1 = icmp sgt i64 %0, 0
  %2 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([39 x i8], [39 x i8]* @51, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactB__body(i1 %1, i1 true, %String* %2)
  %3 = sub i64 %0, 1
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %array, i64 %3)
  %5 = bitcast i8* %4 to %Qubit**
  %6 = load %Qubit*, %Qubit** %5, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %2, i32 -1)
  ret %Qubit* %6
}

define void @Microsoft__Quantum__Arithmetic__RippleCarryAdderNoCarryTTK__adj({ %Array* }* %xs, { %Array* }* %ys) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %__qsVar0__nQubits__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %1)
  %6 = call i64 @__quantum__rt__array_get_size_1d(%Array* %4)
  %7 = icmp eq i64 %__qsVar0__nQubits__, %6
  %8 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @42, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactB__body(i1 %7, i1 true, %String* %8)
  %9 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %1, i64 0)
  %10 = bitcast i8* %9 to %Qubit**
  %11 = load %Qubit*, %Qubit** %10, align 8
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %4, i64 0)
  %13 = bitcast i8* %12 to %Qubit**
  %14 = load %Qubit*, %Qubit** %13, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %11, %Qubit* %14)
  %15 = icmp sgt i64 %__qsVar0__nQubits__, 1
  br i1 %15, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  %16 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %17 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %18 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %19 = bitcast %Tuple* %18 to { { %Array* }*, { %Array* }* }*
  %20 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %19, i32 0, i32 0
  %21 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %19, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { %Array* }* %xs, { %Array* }** %20, align 8
  store { %Array* }* %ys, { %Array* }** %21, align 8
  call void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__adj(%Callable* %16, %Callable* %17, { { %Array* }*, { %Array* }* }* %19)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %16, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %16, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %17, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %17, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %18, i32 -1)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %8, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__RippleCarryAdderTTK__adj({ %Array* }* %xs, { %Array* }* %ys, %Qubit* %carry) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %__qsVar0__nQubits__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %1)
  %6 = call i64 @__quantum__rt__array_get_size_1d(%Array* %4)
  %7 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @46, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %__qsVar0__nQubits__, i64 %6, %String* %7)
  %8 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %1, i64 0)
  %9 = bitcast i8* %8 to %Qubit**
  %10 = load %Qubit*, %Qubit** %9, align 8
  %11 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %4, i64 0)
  %12 = bitcast i8* %11 to %Qubit**
  %13 = load %Qubit*, %Qubit** %12, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %10, %Qubit* %13)
  %14 = icmp sgt i64 %__qsVar0__nQubits__, 1
  br i1 %14, label %then0__1, label %else__1

then0__1:                                         ; preds = %entry
  %15 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %16 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %17 = bitcast %Tuple* %16 to { %Callable*, %Qubit* }*
  %18 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %17, i32 0, i32 0
  %19 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %17, i32 0, i32 1
  %20 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  store %Callable* %20, %Callable** %18, align 8
  store %Qubit* %carry, %Qubit** %19, align 8
  %21 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__20, [2 x void (%Tuple*, i32)*]* @MemoryManagement__7, %Tuple* %16)
  %22 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %23 = bitcast %Tuple* %22 to { { %Array* }*, { %Array* }* }*
  %24 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %23, i32 0, i32 0
  %25 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %23, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { %Array* }* %xs, { %Array* }** %24, align 8
  store { %Array* }* %ys, { %Array* }** %25, align 8
  call void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__adj(%Callable* %15, %Callable* %21, { { %Array* }*, { %Array* }* }* %23)
  %26 = sub i64 %__qsVar0__nQubits__, 1
  %27 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %1, i64 %26)
  %28 = bitcast i8* %27 to %Qubit**
  %29 = load %Qubit*, %Qubit** %28, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %29, %Qubit* %carry)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %21, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %21, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %22, i32 -1)
  br label %continue__1

else__1:                                          ; preds = %entry
  %30 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %1, i64 0)
  %31 = bitcast i8* %30 to %Qubit**
  %32 = load %Qubit*, %Qubit** %31, align 8
  %33 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %4, i64 0)
  %34 = bitcast i8* %33 to %Qubit**
  %35 = load %Qubit*, %Qubit** %34, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__adj(%Qubit* %32, %Qubit* %35, %Qubit* %carry)
  br label %continue__1

continue__1:                                      ; preds = %else__1, %then0__1
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__RippleCarryAdderNoCarryTTK__ctl(%Array* %__controlQubits__, { { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %nQubits = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %9 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %10 = icmp eq i64 %nQubits, %9
  %11 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @43, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactB__body(i1 %10, i1 true, %String* %11)
  %12 = icmp sgt i64 %nQubits, 1
  br i1 %12, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  %13 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %14 = bitcast %Tuple* %13 to { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }*
  %15 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %14, i32 0, i32 0
  %16 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %14, i32 0, i32 1
  %17 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %14, i32 0, i32 2
  %18 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %19 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %20 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %21 = bitcast %Tuple* %20 to { { %Array* }*, { %Array* }* }*
  %22 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %21, i32 0, i32 0
  %23 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %21, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { %Array* }* %xs, { %Array* }** %22, align 8
  store { %Array* }* %ys, { %Array* }** %23, align 8
  store %Callable* %18, %Callable** %15, align 8
  store %Callable* %19, %Callable** %16, align 8
  store { { %Array* }*, { %Array* }* }* %21, { { %Array* }*, { %Array* }* }** %17, align 8
  call void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__ctl(%Array* %__controlQubits__, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %14)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %19, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %19, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  %24 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %25 = bitcast %Tuple* %24 to { %Qubit*, %Qubit* }*
  %26 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %25, i32 0, i32 0
  %27 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %25, i32 0, i32 1
  %28 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 0)
  %29 = bitcast i8* %28 to %Qubit**
  %30 = load %Qubit*, %Qubit** %29, align 8
  %31 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 0)
  %32 = bitcast i8* %31 to %Qubit**
  %33 = load %Qubit*, %Qubit** %32, align 8
  store %Qubit* %30, %Qubit** %26, align 8
  store %Qubit* %33, %Qubit** %27, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %__controlQubits__, { %Qubit*, %Qubit* }* %25)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %11, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %24, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__RippleCarryAdderTTK__ctl(%Array* %__controlQubits__, { { %Array* }*, { %Array* }*, %Qubit* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 2
  %carry = load %Qubit*, %Qubit** %9, align 8
  %nQubits = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %10 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %11 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @47, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %nQubits, i64 %10, %String* %11)
  %12 = icmp sgt i64 %nQubits, 1
  br i1 %12, label %then0__1, label %else__1

then0__1:                                         ; preds = %entry
  %13 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %14 = bitcast %Tuple* %13 to { %Qubit*, %Qubit* }*
  %15 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %14, i32 0, i32 0
  %16 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %14, i32 0, i32 1
  %17 = sub i64 %nQubits, 1
  %18 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 %17)
  %19 = bitcast i8* %18 to %Qubit**
  %20 = load %Qubit*, %Qubit** %19, align 8
  store %Qubit* %20, %Qubit** %15, align 8
  store %Qubit* %carry, %Qubit** %16, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %__controlQubits__, { %Qubit*, %Qubit* }* %14)
  %21 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %22 = bitcast %Tuple* %21 to { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }*
  %23 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %22, i32 0, i32 0
  %24 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %22, i32 0, i32 1
  %25 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %22, i32 0, i32 2
  %26 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %27 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %28 = bitcast %Tuple* %27 to { %Callable*, %Qubit* }*
  %29 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %28, i32 0, i32 0
  %30 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %28, i32 0, i32 1
  %31 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  store %Callable* %31, %Callable** %29, align 8
  store %Qubit* %carry, %Qubit** %30, align 8
  %32 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__21, [2 x void (%Tuple*, i32)*]* @MemoryManagement__7, %Tuple* %27)
  %33 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %34 = bitcast %Tuple* %33 to { { %Array* }*, { %Array* }* }*
  %35 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %34, i32 0, i32 0
  %36 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %34, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { %Array* }* %xs, { %Array* }** %35, align 8
  store { %Array* }* %ys, { %Array* }** %36, align 8
  store %Callable* %26, %Callable** %23, align 8
  store %Callable* %32, %Callable** %24, align 8
  store { { %Array* }*, { %Array* }* }* %34, { { %Array* }*, { %Array* }* }** %25, align 8
  call void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__ctl(%Array* %__controlQubits__, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %22)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %26, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %26, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %32, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %32, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %21, i32 -1)
  br label %continue__1

else__1:                                          ; preds = %entry
  %37 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %38 = bitcast %Tuple* %37 to { %Qubit*, %Qubit*, %Qubit* }*
  %39 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %38, i32 0, i32 0
  %40 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %38, i32 0, i32 1
  %41 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %38, i32 0, i32 2
  %42 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 0)
  %43 = bitcast i8* %42 to %Qubit**
  %44 = load %Qubit*, %Qubit** %43, align 8
  %45 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 0)
  %46 = bitcast i8* %45 to %Qubit**
  %47 = load %Qubit*, %Qubit** %46, align 8
  store %Qubit* %44, %Qubit** %39, align 8
  store %Qubit* %47, %Qubit** %40, align 8
  store %Qubit* %carry, %Qubit** %41, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__ctl(%Array* %__controlQubits__, { %Qubit*, %Qubit*, %Qubit* }* %38)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %37, i32 -1)
  br label %continue__1

continue__1:                                      ; preds = %else__1, %then0__1
  %48 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %49 = bitcast %Tuple* %48 to { %Qubit*, %Qubit* }*
  %50 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %49, i32 0, i32 0
  %51 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %49, i32 0, i32 1
  %52 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 0)
  %53 = bitcast i8* %52 to %Qubit**
  %54 = load %Qubit*, %Qubit** %53, align 8
  %55 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 0)
  %56 = bitcast i8* %55 to %Qubit**
  %57 = load %Qubit*, %Qubit** %56, align 8
  store %Qubit* %54, %Qubit** %50, align 8
  store %Qubit* %57, %Qubit** %51, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %__controlQubits__, { %Qubit*, %Qubit* }* %49)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %11, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %48, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__RippleCarryAdderNoCarryTTK__ctladj(%Array* %__controlQubits__, { { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %__qsVar0__nQubits__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %9 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %10 = icmp eq i64 %__qsVar0__nQubits__, %9
  %11 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @44, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactB__body(i1 %10, i1 true, %String* %11)
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Qubit*, %Qubit* }*
  %14 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %13, i32 0, i32 1
  %16 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 0)
  %17 = bitcast i8* %16 to %Qubit**
  %18 = load %Qubit*, %Qubit** %17, align 8
  %19 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 0)
  %20 = bitcast i8* %19 to %Qubit**
  %21 = load %Qubit*, %Qubit** %20, align 8
  store %Qubit* %18, %Qubit** %14, align 8
  store %Qubit* %21, %Qubit** %15, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %__controlQubits__, { %Qubit*, %Qubit* }* %13)
  %22 = icmp sgt i64 %__qsVar0__nQubits__, 1
  br i1 %22, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  %23 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %24 = bitcast %Tuple* %23 to { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }*
  %25 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %24, i32 0, i32 0
  %26 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %24, i32 0, i32 1
  %27 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %24, i32 0, i32 2
  %28 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %29 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %30 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %31 = bitcast %Tuple* %30 to { { %Array* }*, { %Array* }* }*
  %32 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %31, i32 0, i32 0
  %33 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %31, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { %Array* }* %xs, { %Array* }** %32, align 8
  store { %Array* }* %ys, { %Array* }** %33, align 8
  store %Callable* %28, %Callable** %25, align 8
  store %Callable* %29, %Callable** %26, align 8
  store { { %Array* }*, { %Array* }* }* %31, { { %Array* }*, { %Array* }* }** %27, align 8
  call void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__ctladj(%Array* %__controlQubits__, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %24)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %28, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %28, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %29, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %30, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %23, i32 -1)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %11, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__RippleCarryAdderTTK__ctladj(%Array* %__controlQubits__, { { %Array* }*, { %Array* }*, %Qubit* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 2
  %carry = load %Qubit*, %Qubit** %9, align 8
  %__qsVar0__nQubits__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %10 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %11 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @48, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %__qsVar0__nQubits__, i64 %10, %String* %11)
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Qubit*, %Qubit* }*
  %14 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %13, i32 0, i32 1
  %16 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 0)
  %17 = bitcast i8* %16 to %Qubit**
  %18 = load %Qubit*, %Qubit** %17, align 8
  %19 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 0)
  %20 = bitcast i8* %19 to %Qubit**
  %21 = load %Qubit*, %Qubit** %20, align 8
  store %Qubit* %18, %Qubit** %14, align 8
  store %Qubit* %21, %Qubit** %15, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %__controlQubits__, { %Qubit*, %Qubit* }* %13)
  %22 = icmp sgt i64 %__qsVar0__nQubits__, 1
  br i1 %22, label %then0__1, label %else__1

then0__1:                                         ; preds = %entry
  %23 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %24 = bitcast %Tuple* %23 to { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }*
  %25 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %24, i32 0, i32 0
  %26 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %24, i32 0, i32 1
  %27 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %24, i32 0, i32 2
  %28 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %29 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %30 = bitcast %Tuple* %29 to { %Callable*, %Qubit* }*
  %31 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %30, i32 0, i32 0
  %32 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %30, i32 0, i32 1
  %33 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder__, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  store %Callable* %33, %Callable** %31, align 8
  store %Qubit* %carry, %Qubit** %32, align 8
  %34 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__22, [2 x void (%Tuple*, i32)*]* @MemoryManagement__7, %Tuple* %29)
  %35 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %36 = bitcast %Tuple* %35 to { { %Array* }*, { %Array* }* }*
  %37 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %36, i32 0, i32 0
  %38 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %36, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { %Array* }* %xs, { %Array* }** %37, align 8
  store { %Array* }* %ys, { %Array* }** %38, align 8
  store %Callable* %28, %Callable** %25, align 8
  store %Callable* %34, %Callable** %26, align 8
  store { { %Array* }*, { %Array* }* }* %36, { { %Array* }*, { %Array* }* }** %27, align 8
  call void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__ctladj(%Array* %__controlQubits__, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %24)
  %39 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %40 = bitcast %Tuple* %39 to { %Qubit*, %Qubit* }*
  %41 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %40, i32 0, i32 0
  %42 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %40, i32 0, i32 1
  %43 = sub i64 %__qsVar0__nQubits__, 1
  %44 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 %43)
  %45 = bitcast i8* %44 to %Qubit**
  %46 = load %Qubit*, %Qubit** %45, align 8
  store %Qubit* %46, %Qubit** %41, align 8
  store %Qubit* %carry, %Qubit** %42, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %__controlQubits__, { %Qubit*, %Qubit* }* %40)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %28, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %28, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %34, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %34, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %35, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %23, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %39, i32 -1)
  br label %continue__1

else__1:                                          ; preds = %entry
  %47 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %48 = bitcast %Tuple* %47 to { %Qubit*, %Qubit*, %Qubit* }*
  %49 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %48, i32 0, i32 0
  %50 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %48, i32 0, i32 1
  %51 = getelementptr inbounds { %Qubit*, %Qubit*, %Qubit* }, { %Qubit*, %Qubit*, %Qubit* }* %48, i32 0, i32 2
  %52 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %3, i64 0)
  %53 = bitcast i8* %52 to %Qubit**
  %54 = load %Qubit*, %Qubit** %53, align 8
  %55 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 0)
  %56 = bitcast i8* %55 to %Qubit**
  %57 = load %Qubit*, %Qubit** %56, align 8
  store %Qubit* %54, %Qubit** %49, align 8
  store %Qubit* %57, %Qubit** %50, align 8
  store %Qubit* %carry, %Qubit** %51, align 8
  call void @Microsoft__Quantum__Intrinsic__CCNOT__ctladj(%Array* %__controlQubits__, { %Qubit*, %Qubit*, %Qubit* }* %48)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %47, i32 -1)
  br label %continue__1

continue__1:                                      ; preds = %else__1, %then0__1
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %11, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__body({ i64, %Array* }* %fp) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %xs = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %1 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 1)
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %p = load i64, i64* %2, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__body(%Array* %xs)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__adj({ i64, %Array* }* %fp) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %__qsVar1__xs__ = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %1 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 1)
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %__qsVar0__p__ = load i64, i64* %2, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__adj(%Array* %__qsVar1__xs__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__ctl(%Array* %__controlQubits__, { i64, %Array* }* %fp) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %xs = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %1 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 1)
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %p = load i64, i64* %2, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__ctl(%Array* %__controlQubits__, %Array* %xs)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__ctladj(%Array* %__controlQubits__, { i64, %Array* }* %fp) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %__qsVar1__xs__ = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %1 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 1)
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %__qsVar0__p__ = load i64, i64* %2, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__ctladj(%Array* %__controlQubits__, %Array* %__qsVar1__xs__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__ctl(%Array* %controls, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %coefficients = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %fpx = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %q = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 1)
  %4 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %result = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 0)
  %11 = bitcast i8* %10 to { i64, %Array* }**
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 1)
  %13 = bitcast i8* %12 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %q, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { i64, %Array* }* %fpx, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %13, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %9)
  call void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__body({ i64, %Array* }* %result)
  %14 = call i64 @__quantum__rt__array_get_size_1d(%Array* %coefficients)
  %halfDegree = sub i64 %14, 1
  %15 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 0
  %p = load i64, i64* %15, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %q)
  %16 = icmp eq i64 %halfDegree, 0
  br i1 %16, label %then0__1, label %test1__1

then0__1:                                         ; preds = %entry
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %18 = bitcast %Tuple* %17 to { double, { i64, %Array* }* }*
  %19 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %18, i32 0, i32 1
  %21 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 0)
  %22 = bitcast i8* %21 to double*
  %23 = load double, double* %22, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store double %23, double* %19, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %20, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctl(%Array* %controls, { double, { i64, %Array* }* }* %18)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  br label %continue__1

test1__1:                                         ; preds = %entry
  %24 = icmp sgt i64 %halfDegree, 0
  br i1 %24, label %then1__1, label %continue__1

then1__1:                                         ; preds = %test1__1
  %xsSquared = call %Array* @__quantum__rt__qubit_allocate_array(i64 %n)
  call void @__quantum__rt__array_update_alias_count(%Array* %xsSquared, i32 1)
  %fpxSquared = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %p, %Array* %xsSquared)
  %25 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpxSquared, i32 0, i32 1
  %26 = load %Array*, %Array** %25, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %26, i32 1)
  %27 = bitcast { i64, %Array* }* %fpxSquared to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 1)
  %28 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %29 = bitcast %Tuple* %28 to { %Callable*, { i64, %Array* }* }*
  %30 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %29, i32 0, i32 0
  %31 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %29, i32 0, i32 1
  %32 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__SquareFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__array_update_reference_count(%Array* %q, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  store %Callable* %32, %Callable** %30, align 8
  store { i64, %Array* }* %fpx, { i64, %Array* }** %31, align 8
  %33 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__9, [2 x void (%Tuple*, i32)*]* @MemoryManagement__2, %Tuple* %28)
  %34 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 4))
  %35 = bitcast %Tuple* %34 to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %36 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %35, i32 0, i32 0
  %37 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %35, i32 0, i32 1
  %38 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %35, i32 0, i32 2
  %39 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %35, i32 0, i32 3
  %40 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__callable_make_controlled(%Callable* %40)
  call void @__quantum__rt__array_update_reference_count(%Array* %controls, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store %Callable* %40, %Callable** %36, align 8
  store %Array* %controls, %Array** %37, align 8
  store %Array* %coefficients, %Array** %38, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %39, align 8
  %41 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__10, [2 x void (%Tuple*, i32)*]* @MemoryManagement__3, %Tuple* %34)
  call void @Microsoft__Quantum__Canon___9f62d661957643458f5ddbb073487adf_ApplyWithCA__body(%Callable* %33, %Callable* %41, { i64, %Array* }* %fpxSquared)
  call void @__quantum__rt__array_update_alias_count(%Array* %xsSquared, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %26, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %26, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %33, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %33, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %41, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %41, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %xsSquared)
  br label %continue__1

continue__1:                                      ; preds = %then1__1, %test1__1, %then0__1
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 -1)
  br label %header__1

header__1:                                        ; preds = %exiting__1, %continue__1
  %42 = phi i64 [ 0, %continue__1 ], [ %50, %exiting__1 ]
  %43 = icmp sle i64 %42, 1
  br i1 %43, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %44 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 %42)
  %45 = bitcast i8* %44 to { i64, %Array* }**
  %46 = load { i64, %Array* }*, { i64, %Array* }** %45, align 8
  %47 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %46, i32 0, i32 1
  %48 = load %Array*, %Array** %47, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %48, i32 -1)
  %49 = bitcast { i64, %Array* }* %46 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %49, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %50 = add i64 %42, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__adj(%Array* %coefficients, { i64, %Array* }* %fpx, { i64, %Array* }* %result) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store %Array* %coefficients, %Array** %9, align 8
  store { i64, %Array* }* %fpx, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %11, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__ctladj(%Array* %6, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__ctladj(%Array* %controls, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %coefficients = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %fpx = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %__qsVar2__q__ = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 1)
  %4 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %result = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 0)
  %11 = bitcast i8* %10 to { i64, %Array* }**
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 1)
  %13 = bitcast i8* %12 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar2__q__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { i64, %Array* }* %fpx, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %13, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %9)
  %14 = call i64 @__quantum__rt__array_get_size_1d(%Array* %coefficients)
  %__qsVar0__halfDegree__ = sub i64 %14, 1
  %15 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 0
  %__qsVar1__p__ = load i64, i64* %15, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 1)
  %__qsVar3__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %__qsVar2__q__)
  %16 = icmp eq i64 %__qsVar0__halfDegree__, 0
  br i1 %16, label %then0__1, label %test1__1

then0__1:                                         ; preds = %entry
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %18 = bitcast %Tuple* %17 to { double, { i64, %Array* }* }*
  %19 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %18, i32 0, i32 1
  %21 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 0)
  %22 = bitcast i8* %21 to double*
  %23 = load double, double* %22, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store double %23, double* %19, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %20, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctladj(%Array* %controls, { double, { i64, %Array* }* }* %18)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  br label %continue__1

test1__1:                                         ; preds = %entry
  %24 = icmp sgt i64 %__qsVar0__halfDegree__, 0
  br i1 %24, label %then1__1, label %continue__1

then1__1:                                         ; preds = %test1__1
  %__qsVar4__xsSquared__ = call %Array* @__quantum__rt__qubit_allocate_array(i64 %__qsVar3__n__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar4__xsSquared__, i32 1)
  %__qsVar5__fpxSquared__ = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__qsVar1__p__, %Array* %__qsVar4__xsSquared__)
  %25 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %__qsVar5__fpxSquared__, i32 0, i32 1
  %26 = load %Array*, %Array** %25, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %26, i32 1)
  %27 = bitcast { i64, %Array* }* %__qsVar5__fpxSquared__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 1)
  %28 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %29 = bitcast %Tuple* %28 to { %Callable*, { i64, %Array* }* }*
  %30 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %29, i32 0, i32 0
  %31 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %29, i32 0, i32 1
  %32 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__SquareFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar2__q__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  store %Callable* %32, %Callable** %30, align 8
  store { i64, %Array* }* %fpx, { i64, %Array* }** %31, align 8
  %33 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__11, [2 x void (%Tuple*, i32)*]* @MemoryManagement__2, %Tuple* %28)
  %34 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 4))
  %35 = bitcast %Tuple* %34 to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %36 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %35, i32 0, i32 0
  %37 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %35, i32 0, i32 1
  %38 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %35, i32 0, i32 2
  %39 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %35, i32 0, i32 3
  %40 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__callable_make_controlled(%Callable* %40)
  call void @__quantum__rt__array_update_reference_count(%Array* %controls, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store %Callable* %40, %Callable** %36, align 8
  store %Array* %controls, %Array** %37, align 8
  store %Array* %coefficients, %Array** %38, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %39, align 8
  %41 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__12, [2 x void (%Tuple*, i32)*]* @MemoryManagement__3, %Tuple* %34)
  call void @Microsoft__Quantum__Canon___9f62d661957643458f5ddbb073487adf_ApplyWithCA__adj(%Callable* %33, %Callable* %41, { i64, %Array* }* %__qsVar5__fpxSquared__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar4__xsSquared__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %26, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %26, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %33, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %33, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %41, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %41, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %__qsVar4__xsSquared__)
  br label %continue__1

continue__1:                                      ; preds = %then1__1, %test1__1, %then0__1
  call void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__adj({ i64, %Array* }* %result)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 -1)
  br label %header__1

header__1:                                        ; preds = %exiting__1, %continue__1
  %42 = phi i64 [ 0, %continue__1 ], [ %50, %exiting__1 ]
  %43 = icmp sle i64 %42, 1
  br i1 %43, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %44 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 %42)
  %45 = bitcast i8* %44 to { i64, %Array* }**
  %46 = load { i64, %Array* }*, { i64, %Array* }** %45, align 8
  %47 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %46, i32 0, i32 1
  %48 = load %Array*, %Array** %47, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %48, i32 -1)
  %49 = bitcast { i64, %Array* }* %46 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %49, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %50 = add i64 %42, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %fixedPoints) {
entry:
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %fixedPoints)
  %1 = sub i64 %0, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %2 = phi i64 [ 0, %entry ], [ %10, %exiting__1 ]
  %3 = icmp sle i64 %2, %1
  br i1 %3, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %fixedPoints, i64 %2)
  %5 = bitcast i8* %4 to { i64, %Array* }**
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %6, i32 0, i32 1
  %8 = load %Array*, %Array** %7, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 1)
  %9 = bitcast { i64, %Array* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %10 = add i64 %2, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %fixedPoints, i32 1)
  %11 = icmp eq i64 %0, 0
  br i1 %11, label %then0__1, label %continue__1

then0__1:                                         ; preds = %exit__1
  %12 = sub i64 %0, 1
  br label %header__2

continue__1:                                      ; preds = %exit__1
  %13 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %fixedPoints, i64 0)
  %14 = bitcast i8* %13 to { i64, %Array* }**
  %15 = load { i64, %Array* }*, { i64, %Array* }** %14, align 8
  %16 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %15, i32 0, i32 0
  %position = load i64, i64* %16, align 4
  %17 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %15, i32 0, i32 1
  %register = load %Array*, %Array** %17, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 1)
  %18 = icmp sgt i64 %position, 0
  %19 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @28, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__Fact__body(i1 %18, %String* %19)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %register)
  %20 = call %Array* @Microsoft__Quantum__Arrays___a5a25c88e98b4395a077e1efe49da681_Most__body(%Array* %fixedPoints)
  %21 = call i64 @__quantum__rt__array_get_size_1d(%Array* %20)
  %22 = sub i64 %21, 1
  br label %header__3

header__2:                                        ; preds = %exiting__2, %then0__1
  %23 = phi i64 [ 0, %then0__1 ], [ %31, %exiting__2 ]
  %24 = icmp sle i64 %23, %12
  br i1 %24, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %25 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %fixedPoints, i64 %23)
  %26 = bitcast i8* %25 to { i64, %Array* }**
  %27 = load { i64, %Array* }*, { i64, %Array* }** %26, align 8
  %28 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %27, i32 0, i32 1
  %29 = load %Array*, %Array** %28, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %29, i32 -1)
  %30 = bitcast { i64, %Array* }* %27 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %30, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %31 = add i64 %23, 1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %fixedPoints, i32 -1)
  ret void

header__3:                                        ; preds = %exiting__3, %continue__1
  %32 = phi i64 [ 0, %continue__1 ], [ %42, %exiting__3 ]
  %33 = icmp sle i64 %32, %22
  br i1 %33, label %body__3, label %exit__3

body__3:                                          ; preds = %header__3
  %34 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %20, i64 %32)
  %35 = bitcast i8* %34 to { i64, %Array* }**
  %fp = load { i64, %Array* }*, { i64, %Array* }** %35, align 8
  %36 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %reg = load %Array*, %Array** %36, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %reg, i32 1)
  %37 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %37, i32 1)
  %38 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %pos = load i64, i64* %38, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %reg, i32 1)
  %39 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([62 x i8], [62 x i8]* @29, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %pos, i64 %position, %String* %39)
  %40 = call i64 @__quantum__rt__array_get_size_1d(%Array* %reg)
  %41 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([57 x i8], [57 x i8]* @30, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %40, i64 %n, %String* %41)
  call void @__quantum__rt__array_update_alias_count(%Array* %reg, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %37, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %reg, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %39, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %41, i32 -1)
  br label %exiting__3

exiting__3:                                       ; preds = %body__3
  %42 = add i64 %32, 1
  br label %header__3

exit__3:                                          ; preds = %header__3
  %43 = sub i64 %0, 1
  br label %header__4

header__4:                                        ; preds = %exiting__4, %exit__3
  %44 = phi i64 [ 0, %exit__3 ], [ %52, %exiting__4 ]
  %45 = icmp sle i64 %44, %43
  br i1 %45, label %body__4, label %exit__4

body__4:                                          ; preds = %header__4
  %46 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %fixedPoints, i64 %44)
  %47 = bitcast i8* %46 to { i64, %Array* }**
  %48 = load { i64, %Array* }*, { i64, %Array* }** %47, align 8
  %49 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %48, i32 0, i32 1
  %50 = load %Array*, %Array** %49, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %50, i32 -1)
  %51 = bitcast { i64, %Array* }* %48 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %51, i32 -1)
  br label %exiting__4

exiting__4:                                       ; preds = %body__4
  %52 = add i64 %44, 1
  br label %header__4

exit__4:                                          ; preds = %header__4
  call void @__quantum__rt__array_update_alias_count(%Array* %fixedPoints, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %19, i32 -1)
  %53 = sub i64 %21, 1
  br label %header__5

header__5:                                        ; preds = %exiting__5, %exit__4
  %54 = phi i64 [ 0, %exit__4 ], [ %62, %exiting__5 ]
  %55 = icmp sle i64 %54, %53
  br i1 %55, label %body__5, label %exit__5

body__5:                                          ; preds = %header__5
  %56 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %20, i64 %54)
  %57 = bitcast i8* %56 to { i64, %Array* }**
  %58 = load { i64, %Array* }*, { i64, %Array* }** %57, align 8
  %59 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %58, i32 0, i32 1
  %60 = load %Array*, %Array** %59, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %60, i32 -1)
  %61 = bitcast { i64, %Array* }* %58 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %61, i32 -1)
  br label %exiting__5

exiting__5:                                       ; preds = %body__5
  %62 = add i64 %54, 1
  br label %header__5

exit__5:                                          ; preds = %header__5
  call void @__quantum__rt__array_update_reference_count(%Array* %20, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__9__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  store { i64, %Array* }* %2, { i64, %Array* }** %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %9, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__9__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  store { i64, %Array* }* %2, { i64, %Array* }** %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  %10 = call %Callable* @__quantum__rt__callable_copy(%Callable* %9, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %10)
  call void @__quantum__rt__callable_invoke(%Callable* %10, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__9__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %7, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__9__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %7, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareFxP__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareFxP__body({ i64, %Array* }* %3, { i64, %Array* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareFxP__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareFxP__adj({ i64, %Array* }* %3, { i64, %Array* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareFxP__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareFxP__ctl(%Array* %3, { { i64, %Array* }*, { i64, %Array* }* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareFxP__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareFxP__ctladj(%Array* %3, { { i64, %Array* }*, { i64, %Array* }* }* %4)
  ret void
}

define void @Lifted__PartialApplication__10__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %4 = load %Array*, %Array** %3, align 8
  %5 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 3
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 2
  store %Array* %4, %Array** %9, align 8
  %12 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %12, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %6, { i64, %Array* }** %11, align 8
  %13 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %14 = bitcast %Tuple* %13 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %15 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %14, i32 0, i32 0
  %16 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %14, i32 0, i32 1
  store %Array* %2, %Array** %15, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %16, align 8
  %17 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %18 = load %Callable*, %Callable** %17, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %13, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__10__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %4 = load %Array*, %Array** %3, align 8
  %5 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 3
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 2
  store %Array* %4, %Array** %9, align 8
  %12 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %12, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %6, { i64, %Array* }** %11, align 8
  %13 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %14 = bitcast %Tuple* %13 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %15 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %14, i32 0, i32 0
  %16 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %14, i32 0, i32 1
  store %Array* %2, %Array** %15, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %16, align 8
  %17 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %18 = load %Callable*, %Callable** %17, align 8
  %19 = call %Callable* @__quantum__rt__callable_copy(%Callable* %18, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %19, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %19)
  call void @__quantum__rt__callable_invoke(%Callable* %19, %Tuple* %13, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %19, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %19, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__10__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 2
  %9 = load %Array*, %Array** %8, align 8
  %10 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 3
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %14 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 2
  store %Array* %9, %Array** %14, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %15, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %19 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 1
  store %Array* %7, %Array** %19, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %20, align 8
  %21 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %22 = bitcast %Tuple* %21 to { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }*
  %23 = getelementptr inbounds { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %22, i32 0, i32 0
  %24 = getelementptr inbounds { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %22, i32 0, i32 1
  store %Array* %3, %Array** %23, align 8
  store { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }** %24, align 8
  %25 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 0
  %26 = load %Callable*, %Callable** %25, align 8
  %27 = call %Callable* @__quantum__rt__callable_copy(%Callable* %26, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %27, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %27)
  call void @__quantum__rt__callable_invoke(%Callable* %27, %Tuple* %21, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %21, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %27, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %27, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__10__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 2
  %9 = load %Array*, %Array** %8, align 8
  %10 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 3
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %14 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 2
  store %Array* %9, %Array** %14, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %15, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %19 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 1
  store %Array* %7, %Array** %19, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %20, align 8
  %21 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %22 = bitcast %Tuple* %21 to { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }*
  %23 = getelementptr inbounds { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %22, i32 0, i32 0
  %24 = getelementptr inbounds { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %22, i32 0, i32 1
  store %Array* %3, %Array** %23, align 8
  store { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }** %24, align 8
  %25 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 0
  %26 = load %Callable*, %Callable** %25, align 8
  %27 = call %Callable* @__quantum__rt__callable_copy(%Callable* %26, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %27, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %27)
  call void @__quantum__rt__callable_make_controlled(%Callable* %27)
  call void @__quantum__rt__callable_invoke(%Callable* %27, %Tuple* %21, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %21, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %27, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %27, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %4 = load %Array*, %Array** %1, align 8
  %5 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %6 = load { i64, %Array* }*, { i64, %Array* }** %3, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__body(%Array* %4, { i64, %Array* }* %5, { i64, %Array* }* %6)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %4 = load %Array*, %Array** %1, align 8
  %5 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %6 = load { i64, %Array* }*, { i64, %Array* }** %3, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__adj(%Array* %4, { i64, %Array* }* %5, { i64, %Array* }* %6)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { %Array*, { i64, %Array* }*, { i64, %Array* }* }*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__ctl(%Array* %3, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { %Array*, { i64, %Array* }*, { i64, %Array* }* }*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__ctladj(%Array* %3, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %4)
  ret void
}

define void @MemoryManagement__3__RefCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 %count-change)
  %5 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %6 = load %Array*, %Array** %5, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 %count-change)
  %7 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 3
  %8 = load { i64, %Array* }*, { i64, %Array* }** %7, align 8
  %9 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %8, i32 0, i32 1
  %10 = load %Array*, %Array** %9, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %10, i32 %count-change)
  %11 = bitcast { i64, %Array* }* %8 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 %count-change)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @MemoryManagement__3__AliasCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 %count-change)
  %5 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %6 = load %Array*, %Array** %5, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %6, i32 %count-change)
  %7 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 3
  %8 = load { i64, %Array* }*, { i64, %Array* }** %7, align 8
  %9 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %8, i32 0, i32 1
  %10 = load %Array*, %Array** %9, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %10, i32 %count-change)
  %11 = bitcast { i64, %Array* }* %8 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %11, i32 %count-change)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareFxP__body({ i64, %Array* }* %fp, { i64, %Array* }* %result) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %8 = bitcast %Tuple* %7 to { { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { i64, %Array* }* %fp, { i64, %Array* }** %9, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %10, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareFxP__ctl(%Array* %6, { { i64, %Array* }*, { i64, %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareFxP__adj({ i64, %Array* }* %fp, { i64, %Array* }* %result) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %8 = bitcast %Tuple* %7 to { { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { i64, %Array* }* %fp, { i64, %Array* }** %9, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %10, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareFxP__ctladj(%Array* %6, { { i64, %Array* }*, { i64, %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareFxP__ctl(%Array* %controls, { { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %fp = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %xs = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %3 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 1)
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %result = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %ys = load %Array*, %Array** %5, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 1)
  %6 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %8 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 0)
  %9 = bitcast i8* %8 to { i64, %Array* }**
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 1)
  %11 = bitcast i8* %10 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %xs, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %ys, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  store { i64, %Array* }* %fp, { i64, %Array* }** %9, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %11, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %7)
  call void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__body({ i64, %Array* }* %result)
  %12 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %px = load i64, i64* %12, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %13 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 0
  %py = load i64, i64* %13, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %xs)
  %14 = mul i64 2, %n
  %tmpResult = call %Array* @__quantum__rt__qubit_allocate_array(i64 %14)
  call void @__quantum__rt__array_update_alias_count(%Array* %tmpResult, i32 1)
  %15 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %xs)
  %xsInt = call { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %15)
  %16 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xsInt, i32 0, i32 0
  %17 = load { %Array* }*, { %Array* }** %16, align 8
  %18 = getelementptr inbounds { %Array* }, { %Array* }* %17, i32 0, i32 0
  %19 = load %Array*, %Array** %18, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %19, i32 1)
  %20 = bitcast { %Array* }* %17 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 1)
  %21 = bitcast { { %Array* }* }* %xsInt to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %21, i32 1)
  %22 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %tmpResult)
  %tmpResultInt = call { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %22)
  %23 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %tmpResultInt, i32 0, i32 0
  %24 = load { %Array* }*, { %Array* }** %23, align 8
  %25 = getelementptr inbounds { %Array* }, { %Array* }* %24, i32 0, i32 0
  %26 = load %Array*, %Array** %25, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %26, i32 1)
  %27 = bitcast { %Array* }* %24 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 1)
  %28 = bitcast { { %Array* }* }* %tmpResultInt to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %28, i32 1)
  call void @Microsoft__Quantum__Arithmetic__SquareSI__body({ { %Array* }* }* %xsInt, { { %Array* }* }* %tmpResultInt)
  %29 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %30 = bitcast %Tuple* %29 to { %Callable*, %Array* }*
  %31 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %30, i32 0, i32 0
  %32 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %30, i32 0, i32 1
  %33 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %34 = sub i64 %n, %px
  %35 = mul i64 2, %n
  %36 = sub i64 %35, %px
  %37 = sub i64 %36, 1
  %38 = load %Range, %Range* @EmptyRange, align 4
  %39 = insertvalue %Range %38, i64 %34, 0
  %40 = insertvalue %Range %39, i64 1, 1
  %41 = insertvalue %Range %40, i64 %37, 2
  %42 = call %Array* @__quantum__rt__array_slice_1d(%Array* %tmpResult, %Range %41, i1 true)
  %43 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %42, %Array* %ys)
  call void @__quantum__rt__array_update_reference_count(%Array* %42, i32 -1)
  store %Callable* %33, %Callable** %31, align 8
  store %Array* %43, %Array** %32, align 8
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__ctl(%Array* %controls, { %Callable*, %Array* }* %30)
  call void @Microsoft__Quantum__Arithmetic__SquareSI__adj({ { %Array* }* }* %xsInt, { { %Array* }* }* %tmpResultInt)
  %44 = getelementptr inbounds { %Array* }, { %Array* }* %15, i32 0, i32 0
  %45 = load %Array*, %Array** %44, align 8
  %46 = getelementptr inbounds { %Array* }, { %Array* }* %22, i32 0, i32 0
  %47 = load %Array*, %Array** %46, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %tmpResult, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %21, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %26, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %28, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %45, i32 -1)
  %48 = bitcast { %Array* }* %15 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %48, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %21, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %47, i32 -1)
  %49 = bitcast { %Array* }* %22 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %49, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %26, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %28, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %33, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %33, i32 -1)
  %50 = call i64 @__quantum__rt__array_get_size_1d(%Array* %43)
  %51 = sub i64 %50, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %52 = phi i64 [ 0, %entry ], [ %58, %exiting__1 ]
  %53 = icmp sle i64 %52, %51
  br i1 %53, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %54 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %43, i64 %52)
  %55 = bitcast i8* %54 to { %Qubit*, %Qubit* }**
  %56 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %55, align 8
  %57 = bitcast { %Qubit*, %Qubit* }* %56 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %57, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %58 = add i64 %52, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %43, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %29, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %tmpResult)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 -1)
  br label %header__2

header__2:                                        ; preds = %exiting__2, %exit__1
  %59 = phi i64 [ 0, %exit__1 ], [ %67, %exiting__2 ]
  %60 = icmp sle i64 %59, 1
  br i1 %60, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %61 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 %59)
  %62 = bitcast i8* %61 to { i64, %Array* }**
  %63 = load { i64, %Array* }*, { i64, %Array* }** %62, align 8
  %64 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %63, i32 0, i32 1
  %65 = load %Array*, %Array** %64, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %65, i32 -1)
  %66 = bitcast { i64, %Array* }* %63 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %66, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %67 = add i64 %59, 1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareFxP__ctladj(%Array* %controls, { { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %fp = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 1
  %__qsVar1__xs__ = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %3 = bitcast { i64, %Array* }* %fp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 1)
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %result = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %__qsVar3__ys__ = load %Array*, %Array** %5, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 1)
  %6 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %8 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 0)
  %9 = bitcast i8* %8 to { i64, %Array* }**
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 1)
  %11 = bitcast i8* %10 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar1__xs__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar3__ys__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  store { i64, %Array* }* %fp, { i64, %Array* }** %9, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %11, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %7)
  %12 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp, i32 0, i32 0
  %__qsVar0__px__ = load i64, i64* %12, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %13 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 0
  %__qsVar2__py__ = load i64, i64* %13, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 1)
  %__qsVar4__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %__qsVar1__xs__)
  %14 = mul i64 2, %__qsVar4__n__
  %__qsVar5__tmpResult__ = call %Array* @__quantum__rt__qubit_allocate_array(i64 %14)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar5__tmpResult__, i32 1)
  %15 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__qsVar1__xs__)
  %__qsVar6__xsInt__ = call { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %15)
  %16 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %__qsVar6__xsInt__, i32 0, i32 0
  %17 = load { %Array* }*, { %Array* }** %16, align 8
  %18 = getelementptr inbounds { %Array* }, { %Array* }* %17, i32 0, i32 0
  %19 = load %Array*, %Array** %18, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %19, i32 1)
  %20 = bitcast { %Array* }* %17 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 1)
  %21 = bitcast { { %Array* }* }* %__qsVar6__xsInt__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %21, i32 1)
  %22 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__qsVar5__tmpResult__)
  %__qsVar7__tmpResultInt__ = call { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %22)
  %23 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %__qsVar7__tmpResultInt__, i32 0, i32 0
  %24 = load { %Array* }*, { %Array* }** %23, align 8
  %25 = getelementptr inbounds { %Array* }, { %Array* }* %24, i32 0, i32 0
  %26 = load %Array*, %Array** %25, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %26, i32 1)
  %27 = bitcast { %Array* }* %24 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 1)
  %28 = bitcast { { %Array* }* }* %__qsVar7__tmpResultInt__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %28, i32 1)
  call void @Microsoft__Quantum__Arithmetic__SquareSI__body({ { %Array* }* }* %__qsVar6__xsInt__, { { %Array* }* }* %__qsVar7__tmpResultInt__)
  %29 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %30 = bitcast %Tuple* %29 to { %Callable*, %Array* }*
  %31 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %30, i32 0, i32 0
  %32 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %30, i32 0, i32 1
  %33 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %34 = sub i64 %__qsVar4__n__, %__qsVar0__px__
  %35 = mul i64 2, %__qsVar4__n__
  %36 = sub i64 %35, %__qsVar0__px__
  %37 = sub i64 %36, 1
  %38 = load %Range, %Range* @EmptyRange, align 4
  %39 = insertvalue %Range %38, i64 %34, 0
  %40 = insertvalue %Range %39, i64 1, 1
  %41 = insertvalue %Range %40, i64 %37, 2
  %42 = call %Array* @__quantum__rt__array_slice_1d(%Array* %__qsVar5__tmpResult__, %Range %41, i1 true)
  %43 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %42, %Array* %__qsVar3__ys__)
  call void @__quantum__rt__array_update_reference_count(%Array* %42, i32 -1)
  store %Callable* %33, %Callable** %31, align 8
  store %Array* %43, %Array** %32, align 8
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__ctladj(%Array* %controls, { %Callable*, %Array* }* %30)
  call void @Microsoft__Quantum__Arithmetic__SquareSI__adj({ { %Array* }* }* %__qsVar6__xsInt__, { { %Array* }* }* %__qsVar7__tmpResultInt__)
  %44 = getelementptr inbounds { %Array* }, { %Array* }* %15, i32 0, i32 0
  %45 = load %Array*, %Array** %44, align 8
  %46 = getelementptr inbounds { %Array* }, { %Array* }* %22, i32 0, i32 0
  %47 = load %Array*, %Array** %46, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar5__tmpResult__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %21, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %26, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %28, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %45, i32 -1)
  %48 = bitcast { %Array* }* %15 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %48, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %21, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %47, i32 -1)
  %49 = bitcast { %Array* }* %22 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %49, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %26, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %28, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %33, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %33, i32 -1)
  %50 = call i64 @__quantum__rt__array_get_size_1d(%Array* %43)
  %51 = sub i64 %50, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %52 = phi i64 [ 0, %entry ], [ %58, %exiting__1 ]
  %53 = icmp sle i64 %52, %51
  br i1 %53, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %54 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %43, i64 %52)
  %55 = bitcast i8* %54 to { %Qubit*, %Qubit* }**
  %56 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %55, align 8
  %57 = bitcast { %Qubit*, %Qubit* }* %56 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %57, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %58 = add i64 %52, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %43, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %29, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %__qsVar5__tmpResult__)
  call void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__adj({ i64, %Array* }* %result)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 -1)
  br label %header__2

header__2:                                        ; preds = %exiting__2, %exit__1
  %59 = phi i64 [ 0, %exit__1 ], [ %67, %exiting__2 ]
  %60 = icmp sle i64 %59, 1
  br i1 %60, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %61 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %7, i64 %59)
  %62 = bitcast i8* %61 to { i64, %Array* }**
  %63 = load { i64, %Array* }*, { i64, %Array* }** %62, align 8
  %64 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %63, i32 0, i32 1
  %65 = load %Array*, %Array** %64, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %65, i32 -1)
  %66 = bitcast { i64, %Array* }* %63 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %66, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %67 = add i64 %59, 1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__adj(%Array* %coefficients, { i64, %Array* }* %fpx, { i64, %Array* }* %result) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store %Array* %coefficients, %Array** %9, align 8
  store { i64, %Array* }* %fpx, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %11, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__ctladj(%Array* %6, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__ctl(%Array* %controls, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %coefficients = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %fpx = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %q = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 1)
  %4 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %result = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 0)
  %11 = bitcast i8* %10 to { i64, %Array* }**
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 1)
  %13 = bitcast i8* %12 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %q, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { i64, %Array* }* %fpx, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %13, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %9)
  call void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__body({ i64, %Array* }* %result)
  %14 = call i64 @__quantum__rt__array_get_size_1d(%Array* %coefficients)
  %degree = sub i64 %14, 1
  %15 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 0
  %p = load i64, i64* %15, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %q)
  %16 = icmp eq i64 %degree, 0
  br i1 %16, label %then0__1, label %test1__1

then0__1:                                         ; preds = %entry
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %18 = bitcast %Tuple* %17 to { double, { i64, %Array* }* }*
  %19 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %18, i32 0, i32 1
  %21 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 0)
  %22 = bitcast i8* %21 to double*
  %23 = load double, double* %22, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store double %23, double* %19, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %20, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctl(%Array* %controls, { double, { i64, %Array* }* }* %18)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  br label %continue__1

test1__1:                                         ; preds = %entry
  %24 = icmp sgt i64 %degree, 0
  br i1 %24, label %then1__1, label %continue__1

then1__1:                                         ; preds = %test1__1
  %25 = mul i64 %n, %degree
  %qubits = call %Array* @__quantum__rt__qubit_allocate_array(i64 %25)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 1)
  %26 = sub i64 %degree, 1
  %27 = mul i64 %26, %n
  %28 = mul i64 %degree, %n
  %29 = sub i64 %28, 1
  %30 = load %Range, %Range* @EmptyRange, align 4
  %31 = insertvalue %Range %30, i64 %27, 0
  %32 = insertvalue %Range %31, i64 1, 1
  %33 = insertvalue %Range %32, i64 %29, 2
  %34 = call %Array* @__quantum__rt__array_slice_1d(%Array* %qubits, %Range %33, i1 true)
  %firstIterate = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %p, %Array* %34)
  %35 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %firstIterate, i32 0, i32 1
  %36 = load %Array*, %Array** %35, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %36, i32 1)
  %37 = bitcast { i64, %Array* }* %firstIterate to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %37, i32 1)
  %38 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 %degree)
  %39 = bitcast i8* %38 to double*
  %40 = load double, double* %39, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__body(double %40, { i64, %Array* }* %firstIterate)
  br label %preheader__1

continue__1:                                      ; preds = %exit__2, %test1__1, %then0__1
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 -1)
  br label %header__3

preheader__1:                                     ; preds = %then1__1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %d = phi i64 [ %degree, %preheader__1 ], [ %73, %exiting__1 ]
  %41 = icmp sle i64 %d, 2
  %42 = icmp sge i64 %d, 2
  %43 = select i1 false, i1 %41, i1 %42
  br i1 %43, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %44 = sub i64 %d, 1
  %45 = mul i64 %44, %n
  %46 = mul i64 %d, %n
  %47 = sub i64 %46, 1
  %48 = load %Range, %Range* @EmptyRange, align 4
  %49 = insertvalue %Range %48, i64 %45, 0
  %50 = insertvalue %Range %49, i64 1, 1
  %51 = insertvalue %Range %50, i64 %47, 2
  %52 = call %Array* @__quantum__rt__array_slice_1d(%Array* %qubits, %Range %51, i1 true)
  %currentIterate = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %p, %Array* %52)
  %53 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %currentIterate, i32 0, i32 1
  %54 = load %Array*, %Array** %53, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %54, i32 1)
  %55 = bitcast { i64, %Array* }* %currentIterate to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %55, i32 1)
  %56 = sub i64 %d, 2
  %57 = mul i64 %56, %n
  %58 = sub i64 %d, 1
  %59 = mul i64 %58, %n
  %60 = sub i64 %59, 1
  %61 = load %Range, %Range* @EmptyRange, align 4
  %62 = insertvalue %Range %61, i64 %57, 0
  %63 = insertvalue %Range %62, i64 1, 1
  %64 = insertvalue %Range %63, i64 %60, 2
  %65 = call %Array* @__quantum__rt__array_slice_1d(%Array* %qubits, %Range %64, i1 true)
  %nextIterate = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %p, %Array* %65)
  %66 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %nextIterate, i32 0, i32 1
  %67 = load %Array*, %Array** %66, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %67, i32 1)
  %68 = bitcast { i64, %Array* }* %nextIterate to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %68, i32 1)
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__body({ i64, %Array* }* %currentIterate, { i64, %Array* }* %fpx, { i64, %Array* }* %nextIterate)
  %69 = sub i64 %d, 1
  %70 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 %69)
  %71 = bitcast i8* %70 to double*
  %72 = load double, double* %71, align 8
  call void @Microsoft__Quantum__Arithmetic__AddConstantFxP__body(double %72, { i64, %Array* }* %nextIterate)
  call void @__quantum__rt__array_update_alias_count(%Array* %54, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %55, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %67, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %68, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %52, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %54, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %55, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %65, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %67, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %68, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %73 = add i64 %d, -1
  br label %header__1

exit__1:                                          ; preds = %header__1
  %74 = sub i64 %n, 1
  %75 = load %Range, %Range* @EmptyRange, align 4
  %76 = insertvalue %Range %75, i64 0, 0
  %77 = insertvalue %Range %76, i64 1, 1
  %78 = insertvalue %Range %77, i64 %74, 2
  %79 = call %Array* @__quantum__rt__array_slice_1d(%Array* %qubits, %Range %78, i1 true)
  %finalIterate = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %p, %Array* %79)
  %80 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %finalIterate, i32 0, i32 1
  %81 = load %Array*, %Array** %80, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %81, i32 1)
  %82 = bitcast { i64, %Array* }* %finalIterate to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %82, i32 1)
  %83 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %84 = bitcast %Tuple* %83 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %85 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %84, i32 0, i32 0
  %86 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %84, i32 0, i32 1
  %87 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %84, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %81, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %82, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %q, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { i64, %Array* }* %finalIterate, { i64, %Array* }** %85, align 8
  store { i64, %Array* }* %fpx, { i64, %Array* }** %86, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %87, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctl(%Array* %controls, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %84)
  %88 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %89 = bitcast %Tuple* %88 to { double, { i64, %Array* }* }*
  %90 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %89, i32 0, i32 0
  %91 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %89, i32 0, i32 1
  %92 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 0)
  %93 = bitcast i8* %92 to double*
  %94 = load double, double* %93, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store double %94, double* %90, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %91, align 8
  call void @Microsoft__Quantum__Arithmetic__AddConstantFxP__ctl(%Array* %controls, { double, { i64, %Array* }* }* %89)
  br label %header__2

header__2:                                        ; preds = %exiting__2, %exit__1
  %d__1 = phi i64 [ 2, %exit__1 ], [ %125, %exiting__2 ]
  %95 = icmp sle i64 %d__1, %degree
  br i1 %95, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %96 = sub i64 %d__1, 1
  %97 = mul i64 %96, %n
  %98 = mul i64 %d__1, %n
  %99 = sub i64 %98, 1
  %100 = load %Range, %Range* @EmptyRange, align 4
  %101 = insertvalue %Range %100, i64 %97, 0
  %102 = insertvalue %Range %101, i64 1, 1
  %103 = insertvalue %Range %102, i64 %99, 2
  %104 = call %Array* @__quantum__rt__array_slice_1d(%Array* %qubits, %Range %103, i1 true)
  %currentIterate__1 = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %p, %Array* %104)
  %105 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %currentIterate__1, i32 0, i32 1
  %106 = load %Array*, %Array** %105, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %106, i32 1)
  %107 = bitcast { i64, %Array* }* %currentIterate__1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %107, i32 1)
  %108 = sub i64 %d__1, 2
  %109 = mul i64 %108, %n
  %110 = sub i64 %d__1, 1
  %111 = mul i64 %110, %n
  %112 = sub i64 %111, 1
  %113 = load %Range, %Range* @EmptyRange, align 4
  %114 = insertvalue %Range %113, i64 %109, 0
  %115 = insertvalue %Range %114, i64 1, 1
  %116 = insertvalue %Range %115, i64 %112, 2
  %117 = call %Array* @__quantum__rt__array_slice_1d(%Array* %qubits, %Range %116, i1 true)
  %nextIterate__1 = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %p, %Array* %117)
  %118 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %nextIterate__1, i32 0, i32 1
  %119 = load %Array*, %Array** %118, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %119, i32 1)
  %120 = bitcast { i64, %Array* }* %nextIterate__1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %120, i32 1)
  %121 = sub i64 %d__1, 1
  %122 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 %121)
  %123 = bitcast i8* %122 to double*
  %124 = load double, double* %123, align 8
  call void @Microsoft__Quantum__Arithmetic__AddConstantFxP__adj(double %124, { i64, %Array* }* %nextIterate__1)
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__adj({ i64, %Array* }* %currentIterate__1, { i64, %Array* }* %fpx, { i64, %Array* }* %nextIterate__1)
  call void @__quantum__rt__array_update_alias_count(%Array* %106, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %107, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %119, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %120, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %104, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %106, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %107, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %117, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %119, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %120, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %125 = add i64 %d__1, 1
  br label %header__2

exit__2:                                          ; preds = %header__2
  %126 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 %degree)
  %127 = bitcast i8* %126 to double*
  %128 = load double, double* %127, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__body(double %128, { i64, %Array* }* %firstIterate)
  call void @__quantum__rt__array_update_alias_count(%Array* %qubits, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %36, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %37, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %81, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %82, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %34, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %36, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %37, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %79, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %81, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %82, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %81, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %82, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %q, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %83, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %88, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %qubits)
  br label %continue__1

header__3:                                        ; preds = %exiting__3, %continue__1
  %129 = phi i64 [ 0, %continue__1 ], [ %137, %exiting__3 ]
  %130 = icmp sle i64 %129, 1
  br i1 %130, label %body__3, label %exit__3

body__3:                                          ; preds = %header__3
  %131 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 %129)
  %132 = bitcast i8* %131 to { i64, %Array* }**
  %133 = load { i64, %Array* }*, { i64, %Array* }** %132, align 8
  %134 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %133, i32 0, i32 1
  %135 = load %Array*, %Array** %134, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %135, i32 -1)
  %136 = bitcast { i64, %Array* }* %133 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %136, i32 -1)
  br label %exiting__3

exiting__3:                                       ; preds = %body__3
  %137 = add i64 %129, 1
  br label %header__3

exit__3:                                          ; preds = %header__3
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluatePolynomialFxP__ctladj(%Array* %controls, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %coefficients = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %fpx = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %__qsVar2__q__ = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 1)
  %4 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %result = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 0)
  %11 = bitcast i8* %10 to { i64, %Array* }**
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 1)
  %13 = bitcast i8* %12 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar2__q__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { i64, %Array* }* %fpx, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %13, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %9)
  %14 = call i64 @__quantum__rt__array_get_size_1d(%Array* %coefficients)
  %__qsVar0__degree__ = sub i64 %14, 1
  %15 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 0
  %__qsVar1__p__ = load i64, i64* %15, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 1)
  %__qsVar3__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %__qsVar2__q__)
  %16 = icmp eq i64 %__qsVar0__degree__, 0
  br i1 %16, label %then0__1, label %test1__1

then0__1:                                         ; preds = %entry
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %18 = bitcast %Tuple* %17 to { double, { i64, %Array* }* }*
  %19 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %18, i32 0, i32 1
  %21 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 0)
  %22 = bitcast i8* %21 to double*
  %23 = load double, double* %22, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store double %23, double* %19, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %20, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__ctladj(%Array* %controls, { double, { i64, %Array* }* }* %18)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  br label %continue__1

test1__1:                                         ; preds = %entry
  %24 = icmp sgt i64 %__qsVar0__degree__, 0
  br i1 %24, label %then1__1, label %continue__1

then1__1:                                         ; preds = %test1__1
  %25 = mul i64 %__qsVar3__n__, %__qsVar0__degree__
  %__qsVar4__qubits__ = call %Array* @__quantum__rt__qubit_allocate_array(i64 %25)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar4__qubits__, i32 1)
  %26 = sub i64 %__qsVar0__degree__, 1
  %27 = mul i64 %26, %__qsVar3__n__
  %28 = mul i64 %__qsVar0__degree__, %__qsVar3__n__
  %29 = sub i64 %28, 1
  %30 = load %Range, %Range* @EmptyRange, align 4
  %31 = insertvalue %Range %30, i64 %27, 0
  %32 = insertvalue %Range %31, i64 1, 1
  %33 = insertvalue %Range %32, i64 %29, 2
  %34 = call %Array* @__quantum__rt__array_slice_1d(%Array* %__qsVar4__qubits__, %Range %33, i1 true)
  %__qsVar5__firstIterate__ = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__qsVar1__p__, %Array* %34)
  %35 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %__qsVar5__firstIterate__, i32 0, i32 1
  %36 = load %Array*, %Array** %35, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %36, i32 1)
  %37 = bitcast { i64, %Array* }* %__qsVar5__firstIterate__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %37, i32 1)
  %38 = sub i64 %__qsVar3__n__, 1
  %39 = load %Range, %Range* @EmptyRange, align 4
  %40 = insertvalue %Range %39, i64 0, 0
  %41 = insertvalue %Range %40, i64 1, 1
  %42 = insertvalue %Range %41, i64 %38, 2
  %43 = call %Array* @__quantum__rt__array_slice_1d(%Array* %__qsVar4__qubits__, %Range %42, i1 true)
  %__qsVar9__finalIterate__ = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__qsVar1__p__, %Array* %43)
  %44 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %__qsVar9__finalIterate__, i32 0, i32 1
  %45 = load %Array*, %Array** %44, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %45, i32 1)
  %46 = bitcast { i64, %Array* }* %__qsVar9__finalIterate__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %46, i32 1)
  %47 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 %__qsVar0__degree__)
  %48 = bitcast i8* %47 to double*
  %49 = load double, double* %48, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__adj(double %49, { i64, %Array* }* %__qsVar5__firstIterate__)
  %50 = sub i64 %__qsVar0__degree__, 2
  %51 = udiv i64 %50, 1
  %52 = mul i64 1, %51
  %53 = add i64 2, %52
  %54 = load %Range, %Range* @EmptyRange, align 4
  %55 = insertvalue %Range %54, i64 %53, 0
  %56 = insertvalue %Range %55, i64 -1, 1
  %57 = insertvalue %Range %56, i64 2, 2
  %58 = extractvalue %Range %57, 0
  %59 = extractvalue %Range %57, 1
  %60 = extractvalue %Range %57, 2
  br label %preheader__1

continue__1:                                      ; preds = %exit__2, %test1__1, %then0__1
  call void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__adj({ i64, %Array* }* %result)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 -1)
  br label %header__3

preheader__1:                                     ; preds = %then1__1
  %61 = icmp sgt i64 %59, 0
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %__qsVar10__d__ = phi i64 [ %58, %preheader__1 ], [ %94, %exiting__1 ]
  %62 = icmp sle i64 %__qsVar10__d__, %60
  %63 = icmp sge i64 %__qsVar10__d__, %60
  %64 = select i1 %61, i1 %62, i1 %63
  br i1 %64, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %65 = sub i64 %__qsVar10__d__, 1
  %66 = mul i64 %65, %__qsVar3__n__
  %67 = mul i64 %__qsVar10__d__, %__qsVar3__n__
  %68 = sub i64 %67, 1
  %69 = load %Range, %Range* @EmptyRange, align 4
  %70 = insertvalue %Range %69, i64 %66, 0
  %71 = insertvalue %Range %70, i64 1, 1
  %72 = insertvalue %Range %71, i64 %68, 2
  %73 = call %Array* @__quantum__rt__array_slice_1d(%Array* %__qsVar4__qubits__, %Range %72, i1 true)
  %__qsVar11__currentIterate__ = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__qsVar1__p__, %Array* %73)
  %74 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %__qsVar11__currentIterate__, i32 0, i32 1
  %75 = load %Array*, %Array** %74, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %75, i32 1)
  %76 = bitcast { i64, %Array* }* %__qsVar11__currentIterate__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %76, i32 1)
  %77 = sub i64 %__qsVar10__d__, 2
  %78 = mul i64 %77, %__qsVar3__n__
  %79 = sub i64 %__qsVar10__d__, 1
  %80 = mul i64 %79, %__qsVar3__n__
  %81 = sub i64 %80, 1
  %82 = load %Range, %Range* @EmptyRange, align 4
  %83 = insertvalue %Range %82, i64 %78, 0
  %84 = insertvalue %Range %83, i64 1, 1
  %85 = insertvalue %Range %84, i64 %81, 2
  %86 = call %Array* @__quantum__rt__array_slice_1d(%Array* %__qsVar4__qubits__, %Range %85, i1 true)
  %__qsVar12__nextIterate__ = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__qsVar1__p__, %Array* %86)
  %87 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %__qsVar12__nextIterate__, i32 0, i32 1
  %88 = load %Array*, %Array** %87, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %88, i32 1)
  %89 = bitcast { i64, %Array* }* %__qsVar12__nextIterate__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %89, i32 1)
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__body({ i64, %Array* }* %__qsVar11__currentIterate__, { i64, %Array* }* %fpx, { i64, %Array* }* %__qsVar12__nextIterate__)
  %90 = sub i64 %__qsVar10__d__, 1
  %91 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 %90)
  %92 = bitcast i8* %91 to double*
  %93 = load double, double* %92, align 8
  call void @Microsoft__Quantum__Arithmetic__AddConstantFxP__body(double %93, { i64, %Array* }* %__qsVar12__nextIterate__)
  call void @__quantum__rt__array_update_alias_count(%Array* %75, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %76, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %88, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %89, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %73, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %75, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %76, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %86, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %88, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %89, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %94 = add i64 %__qsVar10__d__, %59
  br label %header__1

exit__1:                                          ; preds = %header__1
  %95 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ double, { i64, %Array* }* }* getelementptr ({ double, { i64, %Array* }* }, { double, { i64, %Array* }* }* null, i32 1) to i64))
  %96 = bitcast %Tuple* %95 to { double, { i64, %Array* }* }*
  %97 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %96, i32 0, i32 0
  %98 = getelementptr inbounds { double, { i64, %Array* }* }, { double, { i64, %Array* }* }* %96, i32 0, i32 1
  %99 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 0)
  %100 = bitcast i8* %99 to double*
  %101 = load double, double* %100, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store double %101, double* %97, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %98, align 8
  call void @Microsoft__Quantum__Arithmetic__AddConstantFxP__ctladj(%Array* %controls, { double, { i64, %Array* }* }* %96)
  %102 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %103 = bitcast %Tuple* %102 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %104 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %103, i32 0, i32 0
  %105 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %103, i32 0, i32 1
  %106 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %103, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %45, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %46, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar2__q__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { i64, %Array* }* %__qsVar9__finalIterate__, { i64, %Array* }** %104, align 8
  store { i64, %Array* }* %fpx, { i64, %Array* }** %105, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %106, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctladj(%Array* %controls, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %103)
  %107 = sub i64 2, %__qsVar0__degree__
  %108 = udiv i64 %107, -1
  %109 = mul i64 -1, %108
  %110 = add i64 %__qsVar0__degree__, %109
  %111 = load %Range, %Range* @EmptyRange, align 4
  %112 = insertvalue %Range %111, i64 %110, 0
  %113 = insertvalue %Range %112, i64 1, 1
  %114 = insertvalue %Range %113, i64 %__qsVar0__degree__, 2
  %115 = extractvalue %Range %114, 0
  %116 = extractvalue %Range %114, 1
  %117 = extractvalue %Range %114, 2
  br label %preheader__2

preheader__2:                                     ; preds = %exit__1
  %118 = icmp sgt i64 %116, 0
  br label %header__2

header__2:                                        ; preds = %exiting__2, %preheader__2
  %__qsVar6__d__ = phi i64 [ %115, %preheader__2 ], [ %151, %exiting__2 ]
  %119 = icmp sle i64 %__qsVar6__d__, %117
  %120 = icmp sge i64 %__qsVar6__d__, %117
  %121 = select i1 %118, i1 %119, i1 %120
  br i1 %121, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %122 = sub i64 %__qsVar6__d__, 1
  %123 = mul i64 %122, %__qsVar3__n__
  %124 = mul i64 %__qsVar6__d__, %__qsVar3__n__
  %125 = sub i64 %124, 1
  %126 = load %Range, %Range* @EmptyRange, align 4
  %127 = insertvalue %Range %126, i64 %123, 0
  %128 = insertvalue %Range %127, i64 1, 1
  %129 = insertvalue %Range %128, i64 %125, 2
  %130 = call %Array* @__quantum__rt__array_slice_1d(%Array* %__qsVar4__qubits__, %Range %129, i1 true)
  %__qsVar7__currentIterate__ = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__qsVar1__p__, %Array* %130)
  %131 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %__qsVar7__currentIterate__, i32 0, i32 1
  %132 = load %Array*, %Array** %131, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %132, i32 1)
  %133 = bitcast { i64, %Array* }* %__qsVar7__currentIterate__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %133, i32 1)
  %134 = sub i64 %__qsVar6__d__, 2
  %135 = mul i64 %134, %__qsVar3__n__
  %136 = sub i64 %__qsVar6__d__, 1
  %137 = mul i64 %136, %__qsVar3__n__
  %138 = sub i64 %137, 1
  %139 = load %Range, %Range* @EmptyRange, align 4
  %140 = insertvalue %Range %139, i64 %135, 0
  %141 = insertvalue %Range %140, i64 1, 1
  %142 = insertvalue %Range %141, i64 %138, 2
  %143 = call %Array* @__quantum__rt__array_slice_1d(%Array* %__qsVar4__qubits__, %Range %142, i1 true)
  %__qsVar8__nextIterate__ = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__qsVar1__p__, %Array* %143)
  %144 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %__qsVar8__nextIterate__, i32 0, i32 1
  %145 = load %Array*, %Array** %144, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %145, i32 1)
  %146 = bitcast { i64, %Array* }* %__qsVar8__nextIterate__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %146, i32 1)
  %147 = sub i64 %__qsVar6__d__, 1
  %148 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 %147)
  %149 = bitcast i8* %148 to double*
  %150 = load double, double* %149, align 8
  call void @Microsoft__Quantum__Arithmetic__AddConstantFxP__adj(double %150, { i64, %Array* }* %__qsVar8__nextIterate__)
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__adj({ i64, %Array* }* %__qsVar7__currentIterate__, { i64, %Array* }* %fpx, { i64, %Array* }* %__qsVar8__nextIterate__)
  call void @__quantum__rt__array_update_alias_count(%Array* %132, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %133, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %145, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %146, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %130, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %132, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %133, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %143, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %145, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %146, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %151 = add i64 %__qsVar6__d__, %116
  br label %header__2

exit__2:                                          ; preds = %header__2
  %152 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %coefficients, i64 %__qsVar0__degree__)
  %153 = bitcast i8* %152 to double*
  %154 = load double, double* %153, align 8
  call void @Microsoft__Quantum__Arithmetic__PrepareFxP__adj(double %154, { i64, %Array* }* %__qsVar5__firstIterate__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar4__qubits__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %36, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %37, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %45, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %46, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %34, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %36, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %37, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %43, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %45, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %46, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %95, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %45, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %46, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar2__q__, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %102, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %__qsVar4__qubits__)
  br label %continue__1

header__3:                                        ; preds = %exiting__3, %continue__1
  %155 = phi i64 [ 0, %continue__1 ], [ %163, %exiting__3 ]
  %156 = icmp sle i64 %155, 1
  br i1 %156, label %body__3, label %exit__3

body__3:                                          ; preds = %header__3
  %157 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 %155)
  %158 = bitcast i8* %157 to { i64, %Array* }**
  %159 = load { i64, %Array* }*, { i64, %Array* }** %158, align 8
  %160 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %159, i32 0, i32 1
  %161 = load %Array*, %Array** %160, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %161, i32 -1)
  %162 = bitcast { i64, %Array* }* %159 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %162, i32 -1)
  br label %exiting__3

exiting__3:                                       ; preds = %body__3
  %163 = add i64 %155, 1
  br label %header__3

exit__3:                                          ; preds = %header__3
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__11__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  store { i64, %Array* }* %2, { i64, %Array* }** %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %9, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__11__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %4 = bitcast %Tuple* %3 to { { i64, %Array* }*, { i64, %Array* }* }*
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  store { i64, %Array* }* %2, { i64, %Array* }** %5, align 8
  %7 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %7, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %0, i32 0, i32 0
  %9 = load %Callable*, %Callable** %8, align 8
  %10 = call %Callable* @__quantum__rt__callable_copy(%Callable* %9, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %10)
  call void @__quantum__rt__callable_invoke(%Callable* %10, %Tuple* %3, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %10, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %10, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__11__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %7, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__11__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  store { i64, %Array* }* %7, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %14 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %9, { { i64, %Array* }*, { i64, %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, { i64, %Array* }* }, { %Callable*, { i64, %Array* }* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__12__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %4 = load %Array*, %Array** %3, align 8
  %5 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 3
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 2
  store %Array* %4, %Array** %9, align 8
  %12 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %12, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %6, { i64, %Array* }** %11, align 8
  %13 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %14 = bitcast %Tuple* %13 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %15 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %14, i32 0, i32 0
  %16 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %14, i32 0, i32 1
  store %Array* %2, %Array** %15, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %16, align 8
  %17 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %18 = load %Callable*, %Callable** %17, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %13, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__12__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %4 = load %Array*, %Array** %3, align 8
  %5 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 3
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 2
  store %Array* %4, %Array** %9, align 8
  %12 = bitcast %Tuple* %arg-tuple to { i64, %Array* }*
  store { i64, %Array* }* %12, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %6, { i64, %Array* }** %11, align 8
  %13 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %14 = bitcast %Tuple* %13 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %15 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %14, i32 0, i32 0
  %16 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %14, i32 0, i32 1
  store %Array* %2, %Array** %15, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %16, align 8
  %17 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %18 = load %Callable*, %Callable** %17, align 8
  %19 = call %Callable* @__quantum__rt__callable_copy(%Callable* %18, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %19, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %19)
  call void @__quantum__rt__callable_invoke(%Callable* %19, %Tuple* %13, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %19, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %19, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__12__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 2
  %9 = load %Array*, %Array** %8, align 8
  %10 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 3
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %14 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 2
  store %Array* %9, %Array** %14, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %15, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %19 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 1
  store %Array* %7, %Array** %19, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %20, align 8
  %21 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %22 = bitcast %Tuple* %21 to { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }*
  %23 = getelementptr inbounds { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %22, i32 0, i32 0
  %24 = getelementptr inbounds { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %22, i32 0, i32 1
  store %Array* %3, %Array** %23, align 8
  store { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }** %24, align 8
  %25 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 0
  %26 = load %Callable*, %Callable** %25, align 8
  %27 = call %Callable* @__quantum__rt__callable_copy(%Callable* %26, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %27, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %27)
  call void @__quantum__rt__callable_invoke(%Callable* %27, %Tuple* %21, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %21, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %27, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %27, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__12__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }* }, { %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, %Array*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 2
  %9 = load %Array*, %Array** %8, align 8
  %10 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 3
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %14 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 2
  store %Array* %9, %Array** %14, align 8
  store { i64, %Array* }* %4, { i64, %Array* }** %15, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %19 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 1
  store %Array* %7, %Array** %19, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %20, align 8
  %21 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %22 = bitcast %Tuple* %21 to { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }*
  %23 = getelementptr inbounds { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %22, i32 0, i32 0
  %24 = getelementptr inbounds { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %22, i32 0, i32 1
  store %Array* %3, %Array** %23, align 8
  store { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }** %24, align 8
  %25 = getelementptr inbounds { %Callable*, %Array*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 0
  %26 = load %Callable*, %Callable** %25, align 8
  %27 = call %Callable* @__quantum__rt__callable_copy(%Callable* %26, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %27, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %27)
  call void @__quantum__rt__callable_make_controlled(%Callable* %27)
  call void @__quantum__rt__callable_invoke(%Callable* %27, %Tuple* %21, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %21, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %27, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %27, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateOddPolynomialFxP__ctl(%Array* %controls, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %coefficients = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %fpx = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %q = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 1)
  %4 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %result = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 0)
  %11 = bitcast i8* %10 to { i64, %Array* }**
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 1)
  %13 = bitcast i8* %12 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %q, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { i64, %Array* }* %fpx, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %13, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %9)
  call void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__body({ i64, %Array* }* %result)
  %14 = call i64 @__quantum__rt__array_get_size_1d(%Array* %coefficients)
  %halfDegree = sub i64 %14, 1
  %15 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 0
  %p = load i64, i64* %15, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %q)
  %16 = icmp sge i64 %halfDegree, 0
  br i1 %16, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  %tmpResult = call %Array* @__quantum__rt__qubit_allocate_array(i64 %n)
  call void @__quantum__rt__array_update_alias_count(%Array* %tmpResult, i32 1)
  %tmpResultFp = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %p, %Array* %tmpResult)
  %17 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %tmpResultFp, i32 0, i32 1
  %18 = load %Array*, %Array** %17, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %18, i32 1)
  %19 = bitcast { i64, %Array* }* %tmpResultFp to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %19, i32 1)
  %20 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %21 = bitcast %Tuple* %20 to { %Callable*, %Array* }*
  %22 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %21, i32 0, i32 0
  %23 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %21, i32 0, i32 1
  %24 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 1)
  store %Callable* %24, %Callable** %22, align 8
  store %Array* %coefficients, %Array** %23, align 8
  %25 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__13, [2 x void (%Tuple*, i32)*]* @MemoryManagement__4, %Tuple* %20)
  %26 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %27 = bitcast %Tuple* %26 to { %Callable*, %Array*, { i64, %Array* }* }*
  %28 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %27, i32 0, i32 0
  %29 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %27, i32 0, i32 1
  %30 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %27, i32 0, i32 2
  %31 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__MultiplyFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__callable_make_controlled(%Callable* %31)
  call void @__quantum__rt__array_update_reference_count(%Array* %controls, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store %Callable* %31, %Callable** %28, align 8
  store %Array* %controls, %Array** %29, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %30, align 8
  %32 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__14, [2 x void (%Tuple*, i32)*]* @MemoryManagement__5, %Tuple* %26)
  %33 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %34 = bitcast %Tuple* %33 to { { i64, %Array* }*, { i64, %Array* }* }*
  %35 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %34, i32 0, i32 0
  %36 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %34, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %q, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 1)
  store { i64, %Array* }* %fpx, { i64, %Array* }** %35, align 8
  store { i64, %Array* }* %tmpResultFp, { i64, %Array* }** %36, align 8
  call void @Microsoft__Quantum__Canon___6f7d9c2cdb674d83b075888f482779f5_ApplyWithCA__body(%Callable* %25, %Callable* %32, { { i64, %Array* }*, { i64, %Array* }* }* %34)
  call void @__quantum__rt__array_update_alias_count(%Array* %tmpResult, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %18, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %25, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %25, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %32, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %32, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %q, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %tmpResult)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %q, i32 -1)
  br label %header__1

header__1:                                        ; preds = %exiting__1, %continue__1
  %37 = phi i64 [ 0, %continue__1 ], [ %45, %exiting__1 ]
  %38 = icmp sle i64 %37, 1
  br i1 %38, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %39 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 %37)
  %40 = bitcast i8* %39 to { i64, %Array* }**
  %41 = load { i64, %Array* }*, { i64, %Array* }** %40, align 8
  %42 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %41, i32 0, i32 1
  %43 = load %Array*, %Array** %42, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %43, i32 -1)
  %44 = bitcast { i64, %Array* }* %41 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %44, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %45 = add i64 %37, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateOddPolynomialFxP__adj(%Array* %coefficients, { i64, %Array* }* %fpx, { i64, %Array* }* %result) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %8 = bitcast %Tuple* %7 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %9 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 1
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store %Array* %coefficients, %Array** %9, align 8
  store { i64, %Array* }* %fpx, { i64, %Array* }** %10, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %11, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluateOddPolynomialFxP__ctladj(%Array* %6, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateOddPolynomialFxP__ctladj(%Array* %controls, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %coefficients = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 1)
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %fpx = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 1
  %__qsVar2__q__ = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 1)
  %4 = bitcast { i64, %Array* }* %fpx to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %result = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 2)
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 0)
  %11 = bitcast i8* %10 to { i64, %Array* }**
  %12 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 1)
  %13 = bitcast i8* %12 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar2__q__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { i64, %Array* }* %fpx, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %13, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %9)
  %14 = call i64 @__quantum__rt__array_get_size_1d(%Array* %coefficients)
  %__qsVar0__halfDegree__ = sub i64 %14, 1
  %15 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fpx, i32 0, i32 0
  %__qsVar1__p__ = load i64, i64* %15, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 1)
  %__qsVar3__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %__qsVar2__q__)
  %16 = icmp sge i64 %__qsVar0__halfDegree__, 0
  br i1 %16, label %then0__1, label %continue__1

then0__1:                                         ; preds = %entry
  %__qsVar4__tmpResult__ = call %Array* @__quantum__rt__qubit_allocate_array(i64 %__qsVar3__n__)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar4__tmpResult__, i32 1)
  %__qsVar5__tmpResultFp__ = call { i64, %Array* }* @Microsoft__Quantum__Arithmetic__FixedPoint__body(i64 %__qsVar1__p__, %Array* %__qsVar4__tmpResult__)
  %17 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %__qsVar5__tmpResultFp__, i32 0, i32 1
  %18 = load %Array*, %Array** %17, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %18, i32 1)
  %19 = bitcast { i64, %Array* }* %__qsVar5__tmpResultFp__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %19, i32 1)
  %20 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %21 = bitcast %Tuple* %20 to { %Callable*, %Array* }*
  %22 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %21, i32 0, i32 0
  %23 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %21, i32 0, i32 1
  %24 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__array_update_reference_count(%Array* %coefficients, i32 1)
  store %Callable* %24, %Callable** %22, align 8
  store %Array* %coefficients, %Array** %23, align 8
  %25 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__15, [2 x void (%Tuple*, i32)*]* @MemoryManagement__4, %Tuple* %20)
  %26 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %27 = bitcast %Tuple* %26 to { %Callable*, %Array*, { i64, %Array* }* }*
  %28 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %27, i32 0, i32 0
  %29 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %27, i32 0, i32 1
  %30 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %27, i32 0, i32 2
  %31 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Arithmetic__MultiplyFxP, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__callable_make_controlled(%Callable* %31)
  call void @__quantum__rt__array_update_reference_count(%Array* %controls, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store %Callable* %31, %Callable** %28, align 8
  store %Array* %controls, %Array** %29, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %30, align 8
  %32 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__16, [2 x void (%Tuple*, i32)*]* @MemoryManagement__5, %Tuple* %26)
  %33 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %34 = bitcast %Tuple* %33 to { { i64, %Array* }*, { i64, %Array* }* }*
  %35 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %34, i32 0, i32 0
  %36 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %34, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar2__q__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 1)
  store { i64, %Array* }* %fpx, { i64, %Array* }** %35, align 8
  store { i64, %Array* }* %__qsVar5__tmpResultFp__, { i64, %Array* }** %36, align 8
  call void @Microsoft__Quantum__Canon___6f7d9c2cdb674d83b075888f482779f5_ApplyWithCA__adj(%Callable* %25, %Callable* %32, { { i64, %Array* }*, { i64, %Array* }* }* %34)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar4__tmpResult__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %18, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %25, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %25, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %32, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %32, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar2__q__, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %__qsVar4__tmpResult__)
  br label %continue__1

continue__1:                                      ; preds = %then0__1, %entry
  call void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__adj({ i64, %Array* }* %result)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %coefficients, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar2__q__, i32 -1)
  br label %header__1

header__1:                                        ; preds = %exiting__1, %continue__1
  %37 = phi i64 [ 0, %continue__1 ], [ %45, %exiting__1 ]
  %38 = icmp sle i64 %37, 1
  br i1 %38, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %39 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %9, i64 %37)
  %40 = bitcast i8* %39 to { i64, %Array* }**
  %41 = load { i64, %Array* }*, { i64, %Array* }** %40, align 8
  %42 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %41, i32 0, i32 1
  %43 = load %Array*, %Array** %42, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %43, i32 -1)
  %44 = bitcast { i64, %Array* }* %41 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %44, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %45 = add i64 %37, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___6f7d9c2cdb674d83b075888f482779f5_ApplyWithCA__body(%Callable* %outerOperation, %Callable* %innerOperation, { { i64, %Array* }*, { i64, %Array* }* }* %target) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %0 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %target, i32 0, i32 0
  %1 = load { i64, %Array* }*, { i64, %Array* }** %0, align 8
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %1, i32 0, i32 1
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { i64, %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %target, i32 0, i32 1
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %6, i32 0, i32 1
  %8 = load %Array*, %Array** %7, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 1)
  %9 = bitcast { i64, %Array* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 1)
  %10 = bitcast { { i64, %Array* }*, { i64, %Array* }* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 1)
  call void @__quantum__rt__callable_invoke(%Callable* %outerOperation, %Tuple* %10, %Tuple* null)
  call void @__quantum__rt__callable_invoke(%Callable* %innerOperation, %Tuple* %10, %Tuple* null)
  %11 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %11)
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %10, %Tuple* null)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %11, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__13__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 0
  %5 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 2
  store %Array* %2, %Array** %10, align 8
  store { i64, %Array* }* %5, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %14, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__13__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 0
  %5 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 2
  store %Array* %2, %Array** %10, align 8
  store { i64, %Array* }* %5, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  %15 = call %Callable* @__quantum__rt__callable_copy(%Callable* %14, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %15)
  call void @__quantum__rt__callable_invoke(%Callable* %15, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__13__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %14 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 2
  store %Array* %7, %Array** %14, align 8
  store { i64, %Array* }* %9, { i64, %Array* }** %15, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %19 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__13__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %14 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 2
  store %Array* %7, %Array** %14, align 8
  store { i64, %Array* }* %9, { i64, %Array* }** %15, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %19 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %23)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %4 = load %Array*, %Array** %1, align 8
  %5 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %6 = load { i64, %Array* }*, { i64, %Array* }** %3, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__body(%Array* %4, { i64, %Array* }* %5, { i64, %Array* }* %6)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %4 = load %Array*, %Array** %1, align 8
  %5 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %6 = load { i64, %Array* }*, { i64, %Array* }** %3, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__adj(%Array* %4, { i64, %Array* }* %5, { i64, %Array* }* %6)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { %Array*, { i64, %Array* }*, { i64, %Array* }* }*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__ctl(%Array* %3, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { %Array*, { i64, %Array* }*, { i64, %Array* }* }*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__EvaluateEvenPolynomialFxP__ctladj(%Array* %3, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %4)
  ret void
}

define void @MemoryManagement__4__RefCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 %count-change)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @MemoryManagement__4__AliasCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 %count-change)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @Lifted__PartialApplication__14__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 0
  %5 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %11 = bitcast %Tuple* %10 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %12 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 1
  %14 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 2
  store { i64, %Array* }* %5, { i64, %Array* }** %12, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %13, align 8
  store { i64, %Array* }* %9, { i64, %Array* }** %14, align 8
  %15 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %16 = bitcast %Tuple* %15 to { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %17 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %16, i32 0, i32 0
  %18 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %16, i32 0, i32 1
  store %Array* %2, %Array** %17, align 8
  store { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }** %18, align 8
  %19 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %20 = load %Callable*, %Callable** %19, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %20, %Tuple* %15, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %15, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__14__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 0
  %5 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %11 = bitcast %Tuple* %10 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %12 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 1
  %14 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 2
  store { i64, %Array* }* %5, { i64, %Array* }** %12, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %13, align 8
  store { i64, %Array* }* %9, { i64, %Array* }** %14, align 8
  %15 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %16 = bitcast %Tuple* %15 to { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %17 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %16, i32 0, i32 0
  %18 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %16, i32 0, i32 1
  store %Array* %2, %Array** %17, align 8
  store { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }** %18, align 8
  %19 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %20 = load %Callable*, %Callable** %19, align 8
  %21 = call %Callable* @__quantum__rt__callable_copy(%Callable* %20, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %21, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %21)
  call void @__quantum__rt__callable_invoke(%Callable* %21, %Tuple* %15, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %15, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %21, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %21, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__14__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 2
  %13 = load { i64, %Array* }*, { i64, %Array* }** %12, align 8
  %14 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %15 = bitcast %Tuple* %14 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %16 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 0
  %17 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 1
  %18 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 2
  store { i64, %Array* }* %9, { i64, %Array* }** %16, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %17, align 8
  store { i64, %Array* }* %13, { i64, %Array* }** %18, align 8
  %19 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %20 = bitcast %Tuple* %19 to { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %21 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, i32 0, i32 0
  %22 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, i32 0, i32 1
  store %Array* %7, %Array** %21, align 8
  store { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }** %22, align 8
  %23 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %24 = bitcast %Tuple* %23 to { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }*
  %25 = getelementptr inbounds { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %24, i32 0, i32 0
  %26 = getelementptr inbounds { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %24, i32 0, i32 1
  store %Array* %3, %Array** %25, align 8
  store { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }** %26, align 8
  %27 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 0
  %28 = load %Callable*, %Callable** %27, align 8
  %29 = call %Callable* @__quantum__rt__callable_copy(%Callable* %28, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %29)
  call void @__quantum__rt__callable_invoke(%Callable* %29, %Tuple* %23, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %23, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %29, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__14__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 2
  %13 = load { i64, %Array* }*, { i64, %Array* }** %12, align 8
  %14 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %15 = bitcast %Tuple* %14 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %16 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 0
  %17 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 1
  %18 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 2
  store { i64, %Array* }* %9, { i64, %Array* }** %16, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %17, align 8
  store { i64, %Array* }* %13, { i64, %Array* }** %18, align 8
  %19 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %20 = bitcast %Tuple* %19 to { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %21 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, i32 0, i32 0
  %22 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, i32 0, i32 1
  store %Array* %7, %Array** %21, align 8
  store { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }** %22, align 8
  %23 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %24 = bitcast %Tuple* %23 to { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }*
  %25 = getelementptr inbounds { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %24, i32 0, i32 0
  %26 = getelementptr inbounds { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %24, i32 0, i32 1
  store %Array* %3, %Array** %25, align 8
  store { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }** %26, align 8
  %27 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 0
  %28 = load %Callable*, %Callable** %27, align 8
  %29 = call %Callable* @__quantum__rt__callable_copy(%Callable* %28, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %29)
  call void @__quantum__rt__callable_make_controlled(%Callable* %29)
  call void @__quantum__rt__callable_invoke(%Callable* %29, %Tuple* %23, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %23, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %29, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyFxP__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %4 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %5 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %6 = load { i64, %Array* }*, { i64, %Array* }** %3, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__body({ i64, %Array* }* %4, { i64, %Array* }* %5, { i64, %Array* }* %6)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyFxP__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %3 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %4 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %5 = load { i64, %Array* }*, { i64, %Array* }** %2, align 8
  %6 = load { i64, %Array* }*, { i64, %Array* }** %3, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__adj({ i64, %Array* }* %4, { i64, %Array* }* %5, { i64, %Array* }* %6)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctl(%Array* %3, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctladj(%Array* %3, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %4)
  ret void
}

define void @MemoryManagement__5__RefCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 %count-change)
  %5 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %6, i32 0, i32 1
  %8 = load %Array*, %Array** %7, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %8, i32 %count-change)
  %9 = bitcast { i64, %Array* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %9, i32 %count-change)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @MemoryManagement__5__AliasCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 %count-change)
  %5 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %6, i32 0, i32 1
  %8 = load %Array*, %Array** %7, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 %count-change)
  %9 = bitcast { i64, %Array* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 %count-change)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyFxP__body({ i64, %Array* }* %fp1, { i64, %Array* }* %fp2, { i64, %Array* }* %result) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fp1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %fp2 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %11 = bitcast %Tuple* %10 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %12 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 1
  %14 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { i64, %Array* }* %fp1, { i64, %Array* }** %12, align 8
  store { i64, %Array* }* %fp2, { i64, %Array* }** %13, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %14, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctl(%Array* %9, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyFxP__adj({ i64, %Array* }* %fp1, { i64, %Array* }* %fp2, { i64, %Array* }* %result) {
entry:
  %0 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 1
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { i64, %Array* }* %fp1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { i64, %Array* }* %fp2 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %11 = bitcast %Tuple* %10 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %12 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 1
  %14 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  store { i64, %Array* }* %fp1, { i64, %Array* }** %12, align 8
  store { i64, %Array* }* %fp2, { i64, %Array* }** %13, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %14, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctladj(%Array* %9, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctl(%Array* %controls, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %fp1 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 1
  %xs = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %3 = bitcast { i64, %Array* }* %fp1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 1)
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %fp2 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 1
  %ys = load %Array*, %Array** %5, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 1)
  %6 = bitcast { i64, %Array* }* %fp2 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %result = load { i64, %Array* }*, { i64, %Array* }** %7, align 8
  %8 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %zs = load %Array*, %Array** %8, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %zs, i32 1)
  %9 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 1)
  %10 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 3)
  %11 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %10, i64 0)
  %12 = bitcast i8* %11 to { i64, %Array* }**
  %13 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %10, i64 1)
  %14 = bitcast i8* %13 to { i64, %Array* }**
  %15 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %10, i64 2)
  %16 = bitcast i8* %15 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %xs, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %ys, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %zs, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %9, i32 1)
  store { i64, %Array* }* %fp1, { i64, %Array* }** %12, align 8
  store { i64, %Array* }* %fp2, { i64, %Array* }** %14, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %16, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %10)
  call void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__body({ i64, %Array* }* %result)
  %17 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 0
  %px = load i64, i64* %17, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 1)
  %18 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 0
  %py = load i64, i64* %18, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 1)
  %19 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 0
  %pz = load i64, i64* %19, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %zs, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %xs)
  %20 = mul i64 2, %n
  %tmpResult = call %Array* @__quantum__rt__qubit_allocate_array(i64 %20)
  call void @__quantum__rt__array_update_alias_count(%Array* %tmpResult, i32 1)
  %21 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %xs)
  %xsInt = call { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %21)
  %22 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xsInt, i32 0, i32 0
  %23 = load { %Array* }*, { %Array* }** %22, align 8
  %24 = getelementptr inbounds { %Array* }, { %Array* }* %23, i32 0, i32 0
  %25 = load %Array*, %Array** %24, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %25, i32 1)
  %26 = bitcast { %Array* }* %23 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %26, i32 1)
  %27 = bitcast { { %Array* }* }* %xsInt to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 1)
  %28 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %ys)
  %ysInt = call { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %28)
  %29 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %ysInt, i32 0, i32 0
  %30 = load { %Array* }*, { %Array* }** %29, align 8
  %31 = getelementptr inbounds { %Array* }, { %Array* }* %30, i32 0, i32 0
  %32 = load %Array*, %Array** %31, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %32, i32 1)
  %33 = bitcast { %Array* }* %30 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %33, i32 1)
  %34 = bitcast { { %Array* }* }* %ysInt to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %34, i32 1)
  %35 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %tmpResult)
  %tmpResultInt = call { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %35)
  %36 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %tmpResultInt, i32 0, i32 0
  %37 = load { %Array* }*, { %Array* }** %36, align 8
  %38 = getelementptr inbounds { %Array* }, { %Array* }* %37, i32 0, i32 0
  %39 = load %Array*, %Array** %38, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %39, i32 1)
  %40 = bitcast { %Array* }* %37 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %40, i32 1)
  %41 = bitcast { { %Array* }* }* %tmpResultInt to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %41, i32 1)
  call void @Microsoft__Quantum__Arithmetic__MultiplySI__body({ { %Array* }* }* %xsInt, { { %Array* }* }* %ysInt, { { %Array* }* }* %tmpResultInt)
  %42 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %43 = bitcast %Tuple* %42 to { %Callable*, %Array* }*
  %44 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %43, i32 0, i32 0
  %45 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %43, i32 0, i32 1
  %46 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %47 = sub i64 %n, %px
  %48 = mul i64 2, %n
  %49 = sub i64 %48, %px
  %50 = sub i64 %49, 1
  %51 = load %Range, %Range* @EmptyRange, align 4
  %52 = insertvalue %Range %51, i64 %47, 0
  %53 = insertvalue %Range %52, i64 1, 1
  %54 = insertvalue %Range %53, i64 %50, 2
  %55 = call %Array* @__quantum__rt__array_slice_1d(%Array* %tmpResult, %Range %54, i1 true)
  %56 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %55, %Array* %zs)
  call void @__quantum__rt__array_update_reference_count(%Array* %55, i32 -1)
  store %Callable* %46, %Callable** %44, align 8
  store %Array* %56, %Array** %45, align 8
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__ctl(%Array* %controls, { %Callable*, %Array* }* %43)
  call void @Microsoft__Quantum__Arithmetic__MultiplySI__adj({ { %Array* }* }* %xsInt, { { %Array* }* }* %ysInt, { { %Array* }* }* %tmpResultInt)
  %57 = getelementptr inbounds { %Array* }, { %Array* }* %21, i32 0, i32 0
  %58 = load %Array*, %Array** %57, align 8
  %59 = getelementptr inbounds { %Array* }, { %Array* }* %28, i32 0, i32 0
  %60 = load %Array*, %Array** %59, align 8
  %61 = getelementptr inbounds { %Array* }, { %Array* }* %35, i32 0, i32 0
  %62 = load %Array*, %Array** %61, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %tmpResult, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %25, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %26, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %32, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %34, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %39, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %40, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %41, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %58, i32 -1)
  %63 = bitcast { %Array* }* %21 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %63, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %25, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %26, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %60, i32 -1)
  %64 = bitcast { %Array* }* %28 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %64, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %32, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %34, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %62, i32 -1)
  %65 = bitcast { %Array* }* %35 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %65, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %39, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %40, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %41, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %46, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %46, i32 -1)
  %66 = call i64 @__quantum__rt__array_get_size_1d(%Array* %56)
  %67 = sub i64 %66, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %68 = phi i64 [ 0, %entry ], [ %74, %exiting__1 ]
  %69 = icmp sle i64 %68, %67
  br i1 %69, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %70 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %56, i64 %68)
  %71 = bitcast i8* %70 to { %Qubit*, %Qubit* }**
  %72 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %71, align 8
  %73 = bitcast { %Qubit*, %Qubit* }* %72 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %73, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %74 = add i64 %68, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %56, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %42, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %tmpResult)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %zs, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %xs, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ys, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %zs, i32 -1)
  br label %header__2

header__2:                                        ; preds = %exiting__2, %exit__1
  %75 = phi i64 [ 0, %exit__1 ], [ %83, %exiting__2 ]
  %76 = icmp sle i64 %75, 2
  br i1 %76, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %77 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %10, i64 %75)
  %78 = bitcast i8* %77 to { i64, %Array* }**
  %79 = load { i64, %Array* }*, { i64, %Array* }** %78, align 8
  %80 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %79, i32 0, i32 1
  %81 = load %Array*, %Array** %80, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %81, i32 -1)
  %82 = bitcast { i64, %Array* }* %79 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %82, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %83 = add i64 %75, 1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_reference_count(%Array* %10, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyFxP__ctladj(%Array* %controls, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 0
  %fp1 = load { i64, %Array* }*, { i64, %Array* }** %1, align 8
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 1
  %__qsVar1__xs__ = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %3 = bitcast { i64, %Array* }* %fp1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 1)
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 1
  %fp2 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %5 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 1
  %__qsVar3__ys__ = load %Array*, %Array** %5, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 1)
  %6 = bitcast { i64, %Array* }* %fp2 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %0, i32 0, i32 2
  %result = load { i64, %Array* }*, { i64, %Array* }** %7, align 8
  %8 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 1
  %__qsVar5__zs__ = load %Array*, %Array** %8, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar5__zs__, i32 1)
  %9 = bitcast { i64, %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 1)
  %10 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 3)
  %11 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %10, i64 0)
  %12 = bitcast i8* %11 to { i64, %Array* }**
  %13 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %10, i64 1)
  %14 = bitcast i8* %13 to { i64, %Array* }**
  %15 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %10, i64 2)
  %16 = bitcast i8* %15 to { i64, %Array* }**
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar1__xs__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %3, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar3__ys__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__qsVar5__zs__, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %9, i32 1)
  store { i64, %Array* }* %fp1, { i64, %Array* }** %12, align 8
  store { i64, %Array* }* %fp2, { i64, %Array* }** %14, align 8
  store { i64, %Array* }* %result, { i64, %Array* }** %16, align 8
  call void @Microsoft__Quantum__Arithmetic__IdenticalFormatFactFxP__body(%Array* %10)
  %17 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp1, i32 0, i32 0
  %__qsVar0__px__ = load i64, i64* %17, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 1)
  %18 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %fp2, i32 0, i32 0
  %__qsVar2__py__ = load i64, i64* %18, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 1)
  %19 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %result, i32 0, i32 0
  %__qsVar4__pz__ = load i64, i64* %19, align 4
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar5__zs__, i32 1)
  %__qsVar6__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %__qsVar1__xs__)
  %20 = mul i64 2, %__qsVar6__n__
  %__qsVar7__tmpResult__ = call %Array* @__quantum__rt__qubit_allocate_array(i64 %20)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar7__tmpResult__, i32 1)
  %21 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__qsVar1__xs__)
  %__qsVar8__xsInt__ = call { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %21)
  %22 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %__qsVar8__xsInt__, i32 0, i32 0
  %23 = load { %Array* }*, { %Array* }** %22, align 8
  %24 = getelementptr inbounds { %Array* }, { %Array* }* %23, i32 0, i32 0
  %25 = load %Array*, %Array** %24, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %25, i32 1)
  %26 = bitcast { %Array* }* %23 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %26, i32 1)
  %27 = bitcast { { %Array* }* }* %__qsVar8__xsInt__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 1)
  %28 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__qsVar3__ys__)
  %__qsVar9__ysInt__ = call { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %28)
  %29 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %__qsVar9__ysInt__, i32 0, i32 0
  %30 = load { %Array* }*, { %Array* }** %29, align 8
  %31 = getelementptr inbounds { %Array* }, { %Array* }* %30, i32 0, i32 0
  %32 = load %Array*, %Array** %31, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %32, i32 1)
  %33 = bitcast { %Array* }* %30 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %33, i32 1)
  %34 = bitcast { { %Array* }* }* %__qsVar9__ysInt__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %34, i32 1)
  %35 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__qsVar7__tmpResult__)
  %__qsVar10__tmpResultInt__ = call { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %35)
  %36 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %__qsVar10__tmpResultInt__, i32 0, i32 0
  %37 = load { %Array* }*, { %Array* }** %36, align 8
  %38 = getelementptr inbounds { %Array* }, { %Array* }* %37, i32 0, i32 0
  %39 = load %Array*, %Array** %38, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %39, i32 1)
  %40 = bitcast { %Array* }* %37 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %40, i32 1)
  %41 = bitcast { { %Array* }* }* %__qsVar10__tmpResultInt__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %41, i32 1)
  call void @Microsoft__Quantum__Arithmetic__MultiplySI__body({ { %Array* }* }* %__qsVar8__xsInt__, { { %Array* }* }* %__qsVar9__ysInt__, { { %Array* }* }* %__qsVar10__tmpResultInt__)
  %42 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %43 = bitcast %Tuple* %42 to { %Callable*, %Array* }*
  %44 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %43, i32 0, i32 0
  %45 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %43, i32 0, i32 1
  %46 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__CNOT, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  %47 = sub i64 %__qsVar6__n__, %__qsVar0__px__
  %48 = mul i64 2, %__qsVar6__n__
  %49 = sub i64 %48, %__qsVar0__px__
  %50 = sub i64 %49, 1
  %51 = load %Range, %Range* @EmptyRange, align 4
  %52 = insertvalue %Range %51, i64 %47, 0
  %53 = insertvalue %Range %52, i64 1, 1
  %54 = insertvalue %Range %53, i64 %50, 2
  %55 = call %Array* @__quantum__rt__array_slice_1d(%Array* %__qsVar7__tmpResult__, %Range %54, i1 true)
  %56 = call %Array* @Microsoft__Quantum__Arrays___39040dcd17464d1aa3217d3c020d7ec0_Zipped__body(%Array* %55, %Array* %__qsVar5__zs__)
  call void @__quantum__rt__array_update_reference_count(%Array* %55, i32 -1)
  store %Callable* %46, %Callable** %44, align 8
  store %Array* %56, %Array** %45, align 8
  call void @Microsoft__Quantum__Canon___fa387bf1c9294c84a0dfc44b22a18e5f_ApplyToEachCA__ctladj(%Array* %controls, { %Callable*, %Array* }* %43)
  call void @Microsoft__Quantum__Arithmetic__MultiplySI__adj({ { %Array* }* }* %__qsVar8__xsInt__, { { %Array* }* }* %__qsVar9__ysInt__, { { %Array* }* }* %__qsVar10__tmpResultInt__)
  %57 = getelementptr inbounds { %Array* }, { %Array* }* %21, i32 0, i32 0
  %58 = load %Array*, %Array** %57, align 8
  %59 = getelementptr inbounds { %Array* }, { %Array* }* %28, i32 0, i32 0
  %60 = load %Array*, %Array** %59, align 8
  %61 = getelementptr inbounds { %Array* }, { %Array* }* %35, i32 0, i32 0
  %62 = load %Array*, %Array** %61, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar7__tmpResult__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %25, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %26, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %32, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %34, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %39, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %40, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %41, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %58, i32 -1)
  %63 = bitcast { %Array* }* %21 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %63, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %25, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %26, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %27, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %60, i32 -1)
  %64 = bitcast { %Array* }* %28 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %64, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %32, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %34, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %62, i32 -1)
  %65 = bitcast { %Array* }* %35 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %65, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %39, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %40, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %41, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %46, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %46, i32 -1)
  %66 = call i64 @__quantum__rt__array_get_size_1d(%Array* %56)
  %67 = sub i64 %66, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %68 = phi i64 [ 0, %entry ], [ %74, %exiting__1 ]
  %69 = icmp sle i64 %68, %67
  br i1 %69, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %70 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %56, i64 %68)
  %71 = bitcast i8* %70 to { %Qubit*, %Qubit* }**
  %72 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %71, align 8
  %73 = bitcast { %Qubit*, %Qubit* }* %72 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %73, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %74 = add i64 %68, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_reference_count(%Array* %56, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %42, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %__qsVar7__tmpResult__)
  call void @Microsoft__Quantum__Arithmetic__AssertAllZeroFxP__adj({ i64, %Array* }* %result)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %3, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar5__zs__, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar1__xs__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar3__ys__, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar5__zs__, i32 -1)
  br label %header__2

header__2:                                        ; preds = %exiting__2, %exit__1
  %75 = phi i64 [ 0, %exit__1 ], [ %83, %exiting__2 ]
  %76 = icmp sle i64 %75, 2
  br i1 %76, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %77 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %10, i64 %75)
  %78 = bitcast i8* %77 to { i64, %Array* }**
  %79 = load { i64, %Array* }*, { i64, %Array* }** %78, align 8
  %80 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %79, i32 0, i32 1
  %81 = load %Array*, %Array** %80, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %81, i32 -1)
  %82 = bitcast { i64, %Array* }* %79 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %82, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %83 = add i64 %75, 1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_reference_count(%Array* %10, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___6f7d9c2cdb674d83b075888f482779f5_ApplyWithCA__adj(%Callable* %outerOperation, %Callable* %innerOperation, { { i64, %Array* }*, { i64, %Array* }* }* %target) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %0 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %target, i32 0, i32 0
  %1 = load { i64, %Array* }*, { i64, %Array* }** %0, align 8
  %2 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %1, i32 0, i32 1
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { i64, %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %target, i32 0, i32 1
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %6, i32 0, i32 1
  %8 = load %Array*, %Array** %7, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 1)
  %9 = bitcast { i64, %Array* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 1)
  %10 = bitcast { { i64, %Array* }*, { i64, %Array* }* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 1)
  %11 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %11)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %11)
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %10, %Tuple* null)
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %innerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %10, %Tuple* null)
  %13 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %13, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %13)
  call void @__quantum__rt__callable_invoke(%Callable* %13, %Tuple* %10, %Tuple* null)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %13, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %13, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__15__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 0
  %5 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 2
  store %Array* %2, %Array** %10, align 8
  store { i64, %Array* }* %5, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %14, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__15__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 0
  %5 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %10 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %9, i32 0, i32 2
  store %Array* %2, %Array** %10, align 8
  store { i64, %Array* }* %5, { i64, %Array* }** %11, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  %15 = call %Callable* @__quantum__rt__callable_copy(%Callable* %14, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %15)
  call void @__quantum__rt__callable_invoke(%Callable* %15, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__15__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %14 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 2
  store %Array* %7, %Array** %14, align 8
  store { i64, %Array* }* %9, { i64, %Array* }** %15, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %19 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__15__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { %Array*, { i64, %Array* }*, { i64, %Array* }* }*
  %14 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { %Array*, { i64, %Array* }*, { i64, %Array* }* }, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, i32 0, i32 2
  store %Array* %7, %Array** %14, align 8
  store { i64, %Array* }* %9, { i64, %Array* }** %15, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %19 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { %Array*, { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { %Array*, { i64, %Array* }*, { i64, %Array* }* }* %13, { %Array*, { i64, %Array* }*, { i64, %Array* }* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %23)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__16__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 0
  %5 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %11 = bitcast %Tuple* %10 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %12 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 1
  %14 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 2
  store { i64, %Array* }* %5, { i64, %Array* }** %12, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %13, align 8
  store { i64, %Array* }* %9, { i64, %Array* }** %14, align 8
  %15 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %16 = bitcast %Tuple* %15 to { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %17 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %16, i32 0, i32 0
  %18 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %16, i32 0, i32 1
  store %Array* %2, %Array** %17, align 8
  store { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }** %18, align 8
  %19 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %20 = load %Callable*, %Callable** %19, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %20, %Tuple* %15, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %15, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__16__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, { i64, %Array* }* }*
  %1 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { { i64, %Array* }*, { i64, %Array* }* }*
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 0
  %5 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %6 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %3, i32 0, i32 1
  %7 = load { i64, %Array* }*, { i64, %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 2
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %11 = bitcast %Tuple* %10 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %12 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 1
  %14 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, i32 0, i32 2
  store { i64, %Array* }* %5, { i64, %Array* }** %12, align 8
  store { i64, %Array* }* %7, { i64, %Array* }** %13, align 8
  store { i64, %Array* }* %9, { i64, %Array* }** %14, align 8
  %15 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %16 = bitcast %Tuple* %15 to { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %17 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %16, i32 0, i32 0
  %18 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %16, i32 0, i32 1
  store %Array* %2, %Array** %17, align 8
  store { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %11, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }** %18, align 8
  %19 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %0, i32 0, i32 0
  %20 = load %Callable*, %Callable** %19, align 8
  %21 = call %Callable* @__quantum__rt__callable_copy(%Callable* %20, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %21, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %21)
  call void @__quantum__rt__callable_invoke(%Callable* %21, %Tuple* %15, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %15, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %21, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %21, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__16__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 2
  %13 = load { i64, %Array* }*, { i64, %Array* }** %12, align 8
  %14 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %15 = bitcast %Tuple* %14 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %16 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 0
  %17 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 1
  %18 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 2
  store { i64, %Array* }* %9, { i64, %Array* }** %16, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %17, align 8
  store { i64, %Array* }* %13, { i64, %Array* }** %18, align 8
  %19 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %20 = bitcast %Tuple* %19 to { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %21 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, i32 0, i32 0
  %22 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, i32 0, i32 1
  store %Array* %7, %Array** %21, align 8
  store { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }** %22, align 8
  %23 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %24 = bitcast %Tuple* %23 to { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }*
  %25 = getelementptr inbounds { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %24, i32 0, i32 0
  %26 = getelementptr inbounds { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %24, i32 0, i32 1
  store %Array* %3, %Array** %25, align 8
  store { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }** %26, align 8
  %27 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 0
  %28 = load %Callable*, %Callable** %27, align 8
  %29 = call %Callable* @__quantum__rt__callable_copy(%Callable* %28, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %29)
  call void @__quantum__rt__callable_invoke(%Callable* %29, %Tuple* %23, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %23, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %29, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__16__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array*, { i64, %Array* }* }*
  %6 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 0
  %9 = load { i64, %Array* }*, { i64, %Array* }** %8, align 8
  %10 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %4, i32 0, i32 1
  %11 = load { i64, %Array* }*, { i64, %Array* }** %10, align 8
  %12 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 2
  %13 = load { i64, %Array* }*, { i64, %Array* }** %12, align 8
  %14 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %15 = bitcast %Tuple* %14 to { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }*
  %16 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 0
  %17 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 1
  %18 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, i32 0, i32 2
  store { i64, %Array* }* %9, { i64, %Array* }** %16, align 8
  store { i64, %Array* }* %11, { i64, %Array* }** %17, align 8
  store { i64, %Array* }* %13, { i64, %Array* }** %18, align 8
  %19 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %20 = bitcast %Tuple* %19 to { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }*
  %21 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, i32 0, i32 0
  %22 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, i32 0, i32 1
  store %Array* %7, %Array** %21, align 8
  store { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* %15, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }** %22, align 8
  %23 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %24 = bitcast %Tuple* %23 to { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }*
  %25 = getelementptr inbounds { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %24, i32 0, i32 0
  %26 = getelementptr inbounds { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }, { %Array*, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* }* %24, i32 0, i32 1
  store %Array* %3, %Array** %25, align 8
  store { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }* %20, { %Array*, { { i64, %Array* }*, { i64, %Array* }*, { i64, %Array* }* }* }** %26, align 8
  %27 = getelementptr inbounds { %Callable*, %Array*, { i64, %Array* }* }, { %Callable*, %Array*, { i64, %Array* }* }* %5, i32 0, i32 0
  %28 = load %Callable*, %Callable** %27, align 8
  %29 = call %Callable* @__quantum__rt__callable_copy(%Callable* %28, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %29)
  call void @__quantum__rt__callable_make_controlled(%Callable* %29)
  call void @__quantum__rt__callable_invoke(%Callable* %29, %Tuple* %23, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %23, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %29, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %29, i32 -1)
  ret void
}

declare %Array* @__quantum__rt__array_slice_1d(%Array*, %Range, i1)

define %Array* @Microsoft__Quantum__Arrays___a5a25c88e98b4395a077e1efe49da681_Most__body(%Array* %array) {
entry:
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %array)
  %1 = sub i64 %0, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %2 = phi i64 [ 0, %entry ], [ %10, %exiting__1 ]
  %3 = icmp sle i64 %2, %1
  br i1 %3, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %array, i64 %2)
  %5 = bitcast i8* %4 to { i64, %Array* }**
  %6 = load { i64, %Array* }*, { i64, %Array* }** %5, align 8
  %7 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %6, i32 0, i32 1
  %8 = load %Array*, %Array** %7, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 1)
  %9 = bitcast { i64, %Array* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %10 = add i64 %2, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 1)
  %11 = sub i64 %0, 2
  %12 = load %Range, %Range* @EmptyRange, align 4
  %13 = insertvalue %Range %12, i64 0, 0
  %14 = insertvalue %Range %13, i64 1, 1
  %15 = insertvalue %Range %14, i64 %11, 2
  %16 = call %Array* @__quantum__rt__array_slice_1d(%Array* %array, %Range %15, i1 true)
  %17 = call i64 @__quantum__rt__array_get_size_1d(%Array* %16)
  %18 = sub i64 %17, 1
  br label %header__2

header__2:                                        ; preds = %exiting__2, %exit__1
  %19 = phi i64 [ 0, %exit__1 ], [ %27, %exiting__2 ]
  %20 = icmp sle i64 %19, %18
  br i1 %20, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %21 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %16, i64 %19)
  %22 = bitcast i8* %21 to { i64, %Array* }**
  %23 = load { i64, %Array* }*, { i64, %Array* }** %22, align 8
  %24 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %23, i32 0, i32 1
  %25 = load %Array*, %Array** %24, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %25, i32 1)
  %26 = bitcast { i64, %Array* }* %23 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %26, i32 1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %27 = add i64 %19, 1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_reference_count(%Array* %16, i32 1)
  %28 = sub i64 %0, 1
  br label %header__3

header__3:                                        ; preds = %exiting__3, %exit__2
  %29 = phi i64 [ 0, %exit__2 ], [ %37, %exiting__3 ]
  %30 = icmp sle i64 %29, %28
  br i1 %30, label %body__3, label %exit__3

body__3:                                          ; preds = %header__3
  %31 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %array, i64 %29)
  %32 = bitcast i8* %31 to { i64, %Array* }**
  %33 = load { i64, %Array* }*, { i64, %Array* }** %32, align 8
  %34 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %33, i32 0, i32 1
  %35 = load %Array*, %Array** %34, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %35, i32 -1)
  %36 = bitcast { i64, %Array* }* %33 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %36, i32 -1)
  br label %exiting__3

exiting__3:                                       ; preds = %body__3
  %37 = add i64 %29, 1
  br label %header__3

exit__3:                                          ; preds = %header__3
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %16, i32 -1)
  ret %Array* %16
}

define void @Microsoft__Quantum__Arithmetic__Invert2sSI__body({ { %Array* }* }* %xs) {
entry:
  %0 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %1 = load { %Array* }*, { %Array* }** %0, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctl(%Array* %6, { { %Array* }* }* %xs)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctl(%Array* %controls, { { %Array* }* }* %xs) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %0 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %1 = load { %Array* }*, { %Array* }** %0, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Callable*, %Array* }*
  %8 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %7, i32 0, i32 1
  %10 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__X, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__callable_make_controlled(%Callable* %10)
  call void @__quantum__rt__array_update_reference_count(%Array* %controls, i32 1)
  store %Callable* %10, %Callable** %8, align 8
  store %Array* %controls, %Array** %9, align 8
  %11 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__17, [2 x void (%Tuple*, i32)*]* @MemoryManagement__6, %Tuple* %6)
  call void @Microsoft__Quantum__Canon___0a03bb4151e34663b70ac90c15a85f8f_ApplyToEachCA__body(%Callable* %11, %Array* %3)
  %12 = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %ancillas = call %Array* @__quantum__rt__qubit_allocate_array(i64 %12)
  call void @__quantum__rt__array_update_alias_count(%Array* %ancillas, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %13 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %ancillas, i64 0)
  %14 = bitcast i8* %13 to %Qubit**
  %qubit = load %Qubit*, %Qubit** %14, align 8
  call void @__quantum__qis__x__ctl(%Array* %controls, %Qubit* %qubit)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %15 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %ancillas)
  call void @Microsoft__Quantum__Arithmetic__AddI__body({ %Array* }* %15, { %Array* }* %1)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %16 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %ancillas, i64 0)
  %17 = bitcast i8* %16 to %Qubit**
  %qubit__1 = load %Qubit*, %Qubit** %17, align 8
  call void @__quantum__qis__x__ctl(%Array* %controls, %Qubit* %qubit__1)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %18 = getelementptr inbounds { %Array* }, { %Array* }* %15, i32 0, i32 0
  %19 = load %Array*, %Array** %18, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %ancillas, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %19, i32 -1)
  %20 = bitcast { %Array* }* %15 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %ancillas)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %11, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__Invert2sSI__adj({ { %Array* }* }* %xs) {
entry:
  %0 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %1 = load { %Array* }*, { %Array* }** %0, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctladj(%Array* %6, { { %Array* }* }* %xs)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctladj(%Array* %controls, { { %Array* }* }* %xs) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %0 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %1 = load { %Array* }*, { %Array* }** %0, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %__qsVar0__ancillas__ = call %Array* @__quantum__rt__qubit_allocate_array(i64 %6)
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar0__ancillas__, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %7 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %__qsVar0__ancillas__, i64 0)
  %8 = bitcast i8* %7 to %Qubit**
  %qubit = load %Qubit*, %Qubit** %8, align 8
  call void @__quantum__qis__x__ctl(%Array* %controls, %Qubit* %qubit)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %9 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %__qsVar0__ancillas__)
  call void @Microsoft__Quantum__Arithmetic__AddI__adj({ %Array* }* %9, { %Array* }* %1)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %10 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %__qsVar0__ancillas__, i64 0)
  %11 = bitcast i8* %10 to %Qubit**
  %qubit__1 = load %Qubit*, %Qubit** %11, align 8
  call void @__quantum__qis__x__ctl(%Array* %controls, %Qubit* %qubit__1)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %12 = getelementptr inbounds { %Array* }, { %Array* }* %9, i32 0, i32 0
  %13 = load %Array*, %Array** %12, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %__qsVar0__ancillas__, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %13, i32 -1)
  %14 = bitcast { %Array* }* %9 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__qubit_release_array(%Array* %__qsVar0__ancillas__)
  %15 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %16 = bitcast %Tuple* %15 to { %Callable*, %Array* }*
  %17 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %16, i32 0, i32 0
  %18 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %16, i32 0, i32 1
  %19 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @Microsoft__Quantum__Intrinsic__X, [2 x void (%Tuple*, i32)*]* null, %Tuple* null)
  call void @__quantum__rt__callable_make_controlled(%Callable* %19)
  call void @__quantum__rt__array_update_reference_count(%Array* %controls, i32 1)
  store %Callable* %19, %Callable** %17, align 8
  store %Array* %controls, %Array** %18, align 8
  %20 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__18, [2 x void (%Tuple*, i32)*]* @MemoryManagement__6, %Tuple* %15)
  call void @Microsoft__Quantum__Canon___0a03bb4151e34663b70ac90c15a85f8f_ApplyToEachCA__adj(%Callable* %20, %Array* %3)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %20, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %20, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___0a03bb4151e34663b70ac90c15a85f8f_ApplyToEachCA__body(%Callable* %singleElementOperation, %Array* %register) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 1)
  %0 = call %Range @Microsoft__Quantum__Arrays___075b44eb0d22417ea03c8829df3aae78_IndexRange__body(%Array* %register)
  %1 = extractvalue %Range %0, 0
  %2 = extractvalue %Range %0, 1
  %3 = extractvalue %Range %0, 2
  br label %preheader__1

preheader__1:                                     ; preds = %entry
  %4 = icmp sgt i64 %2, 0
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %idxQubit = phi i64 [ %1, %preheader__1 ], [ %14, %exiting__1 ]
  %5 = icmp sle i64 %idxQubit, %3
  %6 = icmp sge i64 %idxQubit, %3
  %7 = select i1 %4, i1 %5, i1 %6
  br i1 %7, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %8 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %idxQubit)
  %9 = bitcast i8* %8 to %Qubit**
  %10 = load %Qubit*, %Qubit** %9, align 8
  %11 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64))
  %12 = bitcast %Tuple* %11 to { %Qubit* }*
  %13 = getelementptr inbounds { %Qubit* }, { %Qubit* }* %12, i32 0, i32 0
  store %Qubit* %10, %Qubit** %13, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %singleElementOperation, %Tuple* %11, %Tuple* null)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %14 = add i64 %idxQubit, %2
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__17__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Qubit* }*
  %4 = getelementptr inbounds { %Qubit* }, { %Qubit* }* %3, i32 0, i32 0
  %5 = load %Qubit*, %Qubit** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Qubit* }*
  %8 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Qubit* %5, %Qubit** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__17__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Qubit* }*
  %4 = getelementptr inbounds { %Qubit* }, { %Qubit* }* %3, i32 0, i32 0
  %5 = load %Qubit*, %Qubit** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Qubit* }*
  %8 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Qubit* %5, %Qubit** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %11, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__17__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Qubit* }*
  %1 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Qubit*, %Qubit** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Qubit* }*
  %10 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Qubit* %4, %Qubit** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Qubit* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Qubit* }* }, { %Array*, { %Array*, %Qubit* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Qubit* }* }, { %Array*, { %Array*, %Qubit* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Qubit* }* %9, { %Array*, %Qubit* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__17__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Qubit* }*
  %1 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Qubit*, %Qubit** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Qubit* }*
  %10 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Qubit* %4, %Qubit** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Qubit* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Qubit* }* }, { %Array*, { %Array*, %Qubit* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Qubit* }* }, { %Array*, { %Array*, %Qubit* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Qubit* }* %9, { %Array*, %Qubit* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__X__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Qubit* }*
  %1 = getelementptr inbounds { %Qubit* }, { %Qubit* }* %0, i32 0, i32 0
  %2 = load %Qubit*, %Qubit** %1, align 8
  call void @Microsoft__Quantum__Intrinsic__X__body(%Qubit* %2)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__X__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Qubit* }*
  %1 = getelementptr inbounds { %Qubit* }, { %Qubit* }* %0, i32 0, i32 0
  %2 = load %Qubit*, %Qubit** %1, align 8
  call void @Microsoft__Quantum__Intrinsic__X__adj(%Qubit* %2)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__X__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Qubit* }*
  %1 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Qubit*, %Qubit** %2, align 8
  call void @Microsoft__Quantum__Intrinsic__X__ctl(%Array* %3, %Qubit* %4)
  ret void
}

define void @Microsoft__Quantum__Intrinsic__X__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Qubit* }*
  %1 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Qubit*, %Qubit** %2, align 8
  call void @Microsoft__Quantum__Intrinsic__X__ctladj(%Array* %3, %Qubit* %4)
  ret void
}

define void @MemoryManagement__6__RefCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 %count-change)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @MemoryManagement__6__AliasCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 %count-change)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @Microsoft__Quantum__Canon___0a03bb4151e34663b70ac90c15a85f8f_ApplyToEachCA__adj(%Callable* %singleElementOperation, %Array* %register) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 1)
  %0 = call %Range @Microsoft__Quantum__Arrays___075b44eb0d22417ea03c8829df3aae78_IndexRange__body(%Array* %register)
  %1 = extractvalue %Range %0, 0
  %2 = extractvalue %Range %0, 1
  %3 = extractvalue %Range %0, 2
  %4 = sub i64 %3, %1
  %5 = udiv i64 %4, %2
  %6 = mul i64 %2, %5
  %7 = add i64 %1, %6
  %8 = sub i64 0, %2
  %9 = load %Range, %Range* @EmptyRange, align 4
  %10 = insertvalue %Range %9, i64 %7, 0
  %11 = insertvalue %Range %10, i64 %8, 1
  %12 = insertvalue %Range %11, i64 %1, 2
  %13 = extractvalue %Range %12, 0
  %14 = extractvalue %Range %12, 1
  %15 = extractvalue %Range %12, 2
  br label %preheader__1

preheader__1:                                     ; preds = %entry
  %16 = icmp sgt i64 %14, 0
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %__qsVar0__idxQubit__ = phi i64 [ %13, %preheader__1 ], [ %27, %exiting__1 ]
  %17 = icmp sle i64 %__qsVar0__idxQubit__, %15
  %18 = icmp sge i64 %__qsVar0__idxQubit__, %15
  %19 = select i1 %16, i1 %17, i1 %18
  br i1 %19, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %20 = call %Callable* @__quantum__rt__callable_copy(%Callable* %singleElementOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %20, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %20)
  %21 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %__qsVar0__idxQubit__)
  %22 = bitcast i8* %21 to %Qubit**
  %23 = load %Qubit*, %Qubit** %22, align 8
  %24 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64))
  %25 = bitcast %Tuple* %24 to { %Qubit* }*
  %26 = getelementptr inbounds { %Qubit* }, { %Qubit* }* %25, i32 0, i32 0
  store %Qubit* %23, %Qubit** %26, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %20, %Tuple* %24, %Tuple* null)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %20, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %20, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %24, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %27 = add i64 %__qsVar0__idxQubit__, %14
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__18__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Qubit* }*
  %4 = getelementptr inbounds { %Qubit* }, { %Qubit* }* %3, i32 0, i32 0
  %5 = load %Qubit*, %Qubit** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Qubit* }*
  %8 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Qubit* %5, %Qubit** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__18__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Qubit* }*
  %4 = getelementptr inbounds { %Qubit* }, { %Qubit* }* %3, i32 0, i32 0
  %5 = load %Qubit*, %Qubit** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Qubit* }*
  %8 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Qubit* %5, %Qubit** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %11, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__18__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Qubit* }*
  %1 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Qubit*, %Qubit** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Qubit* }*
  %10 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Qubit* %4, %Qubit** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Qubit* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Qubit* }* }, { %Array*, { %Array*, %Qubit* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Qubit* }* }, { %Array*, { %Array*, %Qubit* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Qubit* }* %9, { %Array*, %Qubit* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__18__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Qubit* }*
  %1 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Qubit*, %Qubit** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Qubit* }*
  %10 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Qubit* %4, %Qubit** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Qubit* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Qubit* }* }, { %Array*, { %Array*, %Qubit* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Qubit* }* }, { %Array*, { %Array*, %Qubit* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Qubit* }* %9, { %Array*, %Qubit* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define double @Microsoft__Quantum__Math__PowD__body(double %x, double %y) {
entry:
  %0 = call double @llvm.pow.f64(double %x, double %y)
  ret double %0
}

define { { %Array* }* }* @Microsoft__Quantum__Arithmetic__SignedLittleEndian__body({ %Array* }* %__Item1__) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %__Item1__, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %__Item1__ to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64))
  %4 = bitcast %Tuple* %3 to { { %Array* }* }*
  %5 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %4, i32 0, i32 0
  store { %Array* }* %__Item1__, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %__Item1__, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %__Item1__ to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  ret { { %Array* }* }* %4
}

define void @Microsoft__Quantum__Arithmetic__MultiplySI__body({ { %Array* }* }* %xs, { { %Array* }* }* %ys, { { %Array* }* }* %result) {
entry:
  %0 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %1 = load { %Array* }*, { %Array* }** %0, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %ys, i32 0, i32 0
  %7 = load { %Array* }*, { %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Array* }, { %Array* }* %7, i32 0, i32 0
  %9 = load %Array*, %Array** %8, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %9, i32 1)
  %10 = bitcast { %Array* }* %7 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 1)
  %11 = bitcast { { %Array* }* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %11, i32 1)
  %12 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %result, i32 0, i32 0
  %13 = load { %Array* }*, { %Array* }** %12, align 8
  %14 = getelementptr inbounds { %Array* }, { %Array* }* %13, i32 0, i32 0
  %15 = load %Array*, %Array** %14, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %15, i32 1)
  %16 = bitcast { %Array* }* %13 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %16, i32 1)
  %17 = bitcast { { %Array* }* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %17, i32 1)
  %18 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %19 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %20 = bitcast %Tuple* %19 to { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }*
  %21 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %20, i32 0, i32 0
  %22 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %20, i32 0, i32 1
  %23 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %20, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %15, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %16, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 1)
  store { { %Array* }* }* %xs, { { %Array* }* }** %21, align 8
  store { { %Array* }* }* %ys, { { %Array* }* }** %22, align 8
  store { { %Array* }* }* %result, { { %Array* }* }** %23, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplySI__ctl(%Array* %18, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %20)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %9, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %11, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %15, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %16, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %15, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %16, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplySI__adj({ { %Array* }* }* %xs, { { %Array* }* }* %ys, { { %Array* }* }* %result) {
entry:
  %0 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %1 = load { %Array* }*, { %Array* }** %0, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %ys, i32 0, i32 0
  %7 = load { %Array* }*, { %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Array* }, { %Array* }* %7, i32 0, i32 0
  %9 = load %Array*, %Array** %8, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %9, i32 1)
  %10 = bitcast { %Array* }* %7 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 1)
  %11 = bitcast { { %Array* }* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %11, i32 1)
  %12 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %result, i32 0, i32 0
  %13 = load { %Array* }*, { %Array* }** %12, align 8
  %14 = getelementptr inbounds { %Array* }, { %Array* }* %13, i32 0, i32 0
  %15 = load %Array*, %Array** %14, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %15, i32 1)
  %16 = bitcast { %Array* }* %13 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %16, i32 1)
  %17 = bitcast { { %Array* }* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %17, i32 1)
  %18 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %19 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %20 = bitcast %Tuple* %19 to { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }*
  %21 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %20, i32 0, i32 0
  %22 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %20, i32 0, i32 1
  %23 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %20, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %15, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %16, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 1)
  store { { %Array* }* }* %xs, { { %Array* }* }** %21, align 8
  store { { %Array* }* }* %ys, { { %Array* }* }** %22, align 8
  store { { %Array* }* }* %result, { { %Array* }* }** %23, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplySI__ctladj(%Array* %18, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %20)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %9, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %11, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %15, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %16, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %15, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %16, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyI__body({ %Array* }* %xs, { %Array* }* %ys, { %Array* }* %result) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %result, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %1)
  %9 = call i64 @__quantum__rt__array_get_size_1d(%Array* %4)
  %10 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([94 x i8], [94 x i8]* @33, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %n, i64 %9, %String* %10)
  %11 = mul i64 2, %n
  %12 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %13 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([87 x i8], [87 x i8]* @34, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %11, i64 %12, %String* %13)
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__body(%Array* %7)
  %14 = sub i64 %n, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %i = phi i64 [ 0, %entry ], [ %39, %exiting__1 ]
  %15 = icmp sle i64 %i, %14
  br i1 %15, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %16 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %17 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %16, i64 0)
  %18 = bitcast i8* %17 to %Qubit**
  %19 = load %Array*, %Array** %0, align 8
  %20 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %19, i64 %i)
  %21 = bitcast i8* %20 to %Qubit**
  %22 = load %Qubit*, %Qubit** %21, align 8
  store %Qubit* %22, %Qubit** %18, align 8
  %23 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %24 = bitcast %Tuple* %23 to { { %Array* }*, { %Array* }* }*
  %25 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %24, i32 0, i32 0
  %26 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %24, i32 0, i32 1
  %27 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %27, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  %28 = load %Array*, %Array** %6, align 8
  %29 = add i64 %i, %n
  %30 = load %Range, %Range* @EmptyRange, align 4
  %31 = insertvalue %Range %30, i64 %i, 0
  %32 = insertvalue %Range %31, i64 1, 1
  %33 = insertvalue %Range %32, i64 %29, 2
  %34 = call %Array* @__quantum__rt__array_slice_1d(%Array* %28, %Range %33, i1 true)
  %35 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %34)
  call void @__quantum__rt__array_update_reference_count(%Array* %34, i32 -1)
  store { %Array* }* %ys, { %Array* }** %25, align 8
  store { %Array* }* %35, { %Array* }** %26, align 8
  call void @Microsoft__Quantum__Arithmetic__AddI__ctl(%Array* %16, { { %Array* }*, { %Array* }* }* %24)
  %36 = getelementptr inbounds { %Array* }, { %Array* }* %35, i32 0, i32 0
  %37 = load %Array*, %Array** %36, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %16, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %27, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %37, i32 -1)
  %38 = bitcast { %Array* }* %35 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %38, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %23, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %39 = add i64 %i, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  %40 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %40, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  %41 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %41, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  %42 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %42, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %10, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %13, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyI__adj({ %Array* }* %xs, { %Array* }* %ys, { %Array* }* %result) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %result, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %__qsVar0__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %1)
  %9 = call i64 @__quantum__rt__array_get_size_1d(%Array* %4)
  %10 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([94 x i8], [94 x i8]* @35, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %__qsVar0__n__, i64 %9, %String* %10)
  %11 = mul i64 2, %__qsVar0__n__
  %12 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %13 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([87 x i8], [87 x i8]* @36, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %11, i64 %12, %String* %13)
  %14 = sub i64 %__qsVar0__n__, 1
  %15 = sub i64 %14, 0
  %16 = udiv i64 %15, 1
  %17 = mul i64 1, %16
  %18 = add i64 0, %17
  %19 = load %Range, %Range* @EmptyRange, align 4
  %20 = insertvalue %Range %19, i64 %18, 0
  %21 = insertvalue %Range %20, i64 -1, 1
  %22 = insertvalue %Range %21, i64 0, 2
  %23 = extractvalue %Range %22, 0
  %24 = extractvalue %Range %22, 1
  %25 = extractvalue %Range %22, 2
  br label %preheader__1

preheader__1:                                     ; preds = %entry
  %26 = icmp sgt i64 %24, 0
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %__qsVar1__i__ = phi i64 [ %23, %preheader__1 ], [ %53, %exiting__1 ]
  %27 = icmp sle i64 %__qsVar1__i__, %25
  %28 = icmp sge i64 %__qsVar1__i__, %25
  %29 = select i1 %26, i1 %27, i1 %28
  br i1 %29, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %30 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %31 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %30, i64 0)
  %32 = bitcast i8* %31 to %Qubit**
  %33 = load %Array*, %Array** %0, align 8
  %34 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %33, i64 %__qsVar1__i__)
  %35 = bitcast i8* %34 to %Qubit**
  %36 = load %Qubit*, %Qubit** %35, align 8
  store %Qubit* %36, %Qubit** %32, align 8
  %37 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %38 = bitcast %Tuple* %37 to { { %Array* }*, { %Array* }* }*
  %39 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %38, i32 0, i32 0
  %40 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %38, i32 0, i32 1
  %41 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %41, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  %42 = load %Array*, %Array** %6, align 8
  %43 = add i64 %__qsVar1__i__, %__qsVar0__n__
  %44 = load %Range, %Range* @EmptyRange, align 4
  %45 = insertvalue %Range %44, i64 %__qsVar1__i__, 0
  %46 = insertvalue %Range %45, i64 1, 1
  %47 = insertvalue %Range %46, i64 %43, 2
  %48 = call %Array* @__quantum__rt__array_slice_1d(%Array* %42, %Range %47, i1 true)
  %49 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %48)
  call void @__quantum__rt__array_update_reference_count(%Array* %48, i32 -1)
  store { %Array* }* %ys, { %Array* }** %39, align 8
  store { %Array* }* %49, { %Array* }** %40, align 8
  call void @Microsoft__Quantum__Arithmetic__AddI__ctladj(%Array* %30, { { %Array* }*, { %Array* }* }* %38)
  %50 = getelementptr inbounds { %Array* }, { %Array* }* %49, i32 0, i32 0
  %51 = load %Array*, %Array** %50, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %30, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %41, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %51, i32 -1)
  %52 = bitcast { %Array* }* %49 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %52, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %37, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %53 = add i64 %__qsVar1__i__, %24
  br label %header__1

exit__1:                                          ; preds = %header__1
  %54 = load %Array*, %Array** %6, align 8
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__adj(%Array* %54)
  %55 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %55, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  %56 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %56, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %54, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %10, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %13, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplyI__ctl(%Array* %controls, { { %Array* }*, { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %0, i32 0, i32 2
  %result = load { %Array* }*, { %Array* }** %9, align 8
  %10 = getelementptr inbounds { %Array* }, { %Array* }* %result, i32 0, i32 0
  %11 = load %Array*, %Array** %10, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %11, i32 1)
  %12 = bitcast { %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %12, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %13 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %14 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([94 x i8], [94 x i8]* @37, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %n, i64 %13, %String* %14)
  %15 = mul i64 2, %n
  %16 = call i64 @__quantum__rt__array_get_size_1d(%Array* %11)
  %17 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([87 x i8], [87 x i8]* @38, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %15, i64 %16, %String* %17)
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__body(%Array* %11)
  %anc = call %Qubit* @__quantum__rt__qubit_allocate()
  %18 = sub i64 %n, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %i = phi i64 [ 0, %entry ], [ %54, %exiting__1 ]
  %19 = icmp sle i64 %i, %18
  br i1 %19, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %20 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %21 = bitcast %Tuple* %20 to { %Qubit*, %Qubit* }*
  %22 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %21, i32 0, i32 0
  %23 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %21, i32 0, i32 1
  %24 = load %Array*, %Array** %2, align 8
  %25 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %24, i64 %i)
  %26 = bitcast i8* %25 to %Qubit**
  %27 = load %Qubit*, %Qubit** %26, align 8
  store %Qubit* %27, %Qubit** %22, align 8
  store %Qubit* %anc, %Qubit** %23, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %controls, { %Qubit*, %Qubit* }* %21)
  %28 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %29 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %28, i64 0)
  %30 = bitcast i8* %29 to %Qubit**
  store %Qubit* %anc, %Qubit** %30, align 8
  %31 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %32 = bitcast %Tuple* %31 to { { %Array* }*, { %Array* }* }*
  %33 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %32, i32 0, i32 0
  %34 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %32, i32 0, i32 1
  %35 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %35, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  %36 = load %Array*, %Array** %10, align 8
  %37 = add i64 %i, %n
  %38 = load %Range, %Range* @EmptyRange, align 4
  %39 = insertvalue %Range %38, i64 %i, 0
  %40 = insertvalue %Range %39, i64 1, 1
  %41 = insertvalue %Range %40, i64 %37, 2
  %42 = call %Array* @__quantum__rt__array_slice_1d(%Array* %36, %Range %41, i1 true)
  %43 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %42)
  call void @__quantum__rt__array_update_reference_count(%Array* %42, i32 -1)
  store { %Array* }* %ys, { %Array* }** %33, align 8
  store { %Array* }* %43, { %Array* }** %34, align 8
  call void @Microsoft__Quantum__Arithmetic__AddI__ctl(%Array* %28, { { %Array* }*, { %Array* }* }* %32)
  %44 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %45 = bitcast %Tuple* %44 to { %Qubit*, %Qubit* }*
  %46 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %45, i32 0, i32 0
  %47 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %45, i32 0, i32 1
  %48 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %24, i64 %i)
  %49 = bitcast i8* %48 to %Qubit**
  %50 = load %Qubit*, %Qubit** %49, align 8
  store %Qubit* %50, %Qubit** %46, align 8
  store %Qubit* %anc, %Qubit** %47, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %controls, { %Qubit*, %Qubit* }* %45)
  %51 = getelementptr inbounds { %Array* }, { %Array* }* %43, i32 0, i32 0
  %52 = load %Array*, %Array** %51, align 8
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %28, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %35, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %52, i32 -1)
  %53 = bitcast { %Array* }* %43 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %53, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %31, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %44, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %54 = add i64 %i, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__qubit_release(%Qubit* %anc)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %55 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %55, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  %56 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %56, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  %57 = load %Array*, %Array** %10, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %57, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %14, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %17, i32 -1)
  ret void
}

declare void @__quantum__rt__qubit_release(%Qubit*)

define void @Microsoft__Quantum__Arithmetic__MultiplyI__ctladj(%Array* %controls, { { %Array* }*, { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %ys = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %ys, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %0, i32 0, i32 2
  %result = load { %Array* }*, { %Array* }** %9, align 8
  %10 = getelementptr inbounds { %Array* }, { %Array* }* %result, i32 0, i32 0
  %11 = load %Array*, %Array** %10, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %11, i32 1)
  %12 = bitcast { %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %12, i32 1)
  %__qsVar0__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %13 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %14 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([94 x i8], [94 x i8]* @39, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %__qsVar0__n__, i64 %13, %String* %14)
  %15 = mul i64 2, %__qsVar0__n__
  %16 = call i64 @__quantum__rt__array_get_size_1d(%Array* %11)
  %17 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([87 x i8], [87 x i8]* @40, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %15, i64 %16, %String* %17)
  %__qsVar1__anc__ = call %Qubit* @__quantum__rt__qubit_allocate()
  %18 = sub i64 %__qsVar0__n__, 1
  %19 = sub i64 %18, 0
  %20 = udiv i64 %19, 1
  %21 = mul i64 1, %20
  %22 = add i64 0, %21
  %23 = load %Range, %Range* @EmptyRange, align 4
  %24 = insertvalue %Range %23, i64 %22, 0
  %25 = insertvalue %Range %24, i64 -1, 1
  %26 = insertvalue %Range %25, i64 0, 2
  %27 = extractvalue %Range %26, 0
  %28 = extractvalue %Range %26, 1
  %29 = extractvalue %Range %26, 2
  br label %preheader__1

preheader__1:                                     ; preds = %entry
  %30 = icmp sgt i64 %28, 0
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %__qsVar2__i__ = phi i64 [ %27, %preheader__1 ], [ %68, %exiting__1 ]
  %31 = icmp sle i64 %__qsVar2__i__, %29
  %32 = icmp sge i64 %__qsVar2__i__, %29
  %33 = select i1 %30, i1 %31, i1 %32
  br i1 %33, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %34 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %35 = bitcast %Tuple* %34 to { %Qubit*, %Qubit* }*
  %36 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %35, i32 0, i32 0
  %37 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %35, i32 0, i32 1
  %38 = load %Array*, %Array** %2, align 8
  %39 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %38, i64 %__qsVar2__i__)
  %40 = bitcast i8* %39 to %Qubit**
  %41 = load %Qubit*, %Qubit** %40, align 8
  store %Qubit* %41, %Qubit** %36, align 8
  store %Qubit* %__qsVar1__anc__, %Qubit** %37, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %controls, { %Qubit*, %Qubit* }* %35)
  %42 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %43 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %42, i64 0)
  %44 = bitcast i8* %43 to %Qubit**
  store %Qubit* %__qsVar1__anc__, %Qubit** %44, align 8
  %45 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %46 = bitcast %Tuple* %45 to { { %Array* }*, { %Array* }* }*
  %47 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %46, i32 0, i32 0
  %48 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %46, i32 0, i32 1
  %49 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %49, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  %50 = load %Array*, %Array** %10, align 8
  %51 = add i64 %__qsVar2__i__, %__qsVar0__n__
  %52 = load %Range, %Range* @EmptyRange, align 4
  %53 = insertvalue %Range %52, i64 %__qsVar2__i__, 0
  %54 = insertvalue %Range %53, i64 1, 1
  %55 = insertvalue %Range %54, i64 %51, 2
  %56 = call %Array* @__quantum__rt__array_slice_1d(%Array* %50, %Range %55, i1 true)
  %57 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %56)
  call void @__quantum__rt__array_update_reference_count(%Array* %56, i32 -1)
  store { %Array* }* %ys, { %Array* }** %47, align 8
  store { %Array* }* %57, { %Array* }** %48, align 8
  call void @Microsoft__Quantum__Arithmetic__AddI__ctladj(%Array* %42, { { %Array* }*, { %Array* }* }* %46)
  %58 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %59 = bitcast %Tuple* %58 to { %Qubit*, %Qubit* }*
  %60 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %59, i32 0, i32 0
  %61 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %59, i32 0, i32 1
  %62 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %38, i64 %__qsVar2__i__)
  %63 = bitcast i8* %62 to %Qubit**
  %64 = load %Qubit*, %Qubit** %63, align 8
  store %Qubit* %64, %Qubit** %60, align 8
  store %Qubit* %__qsVar1__anc__, %Qubit** %61, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %controls, { %Qubit*, %Qubit* }* %59)
  %65 = getelementptr inbounds { %Array* }, { %Array* }* %57, i32 0, i32 0
  %66 = load %Array*, %Array** %65, align 8
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %34, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %42, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %49, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %66, i32 -1)
  %67 = bitcast { %Array* }* %57 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %67, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %45, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %58, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %68 = add i64 %__qsVar2__i__, %28
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__qubit_release(%Qubit* %__qsVar1__anc__)
  %69 = load %Array*, %Array** %10, align 8
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__adj(%Array* %69)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %70 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %70, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  %71 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %71, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %69, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %14, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %17, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplySI__ctl(%Array* %controls, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %0, i32 0, i32 0
  %xs = load { { %Array* }* }*, { { %Array* }* }** %1, align 8
  %2 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %3 = load { %Array* }*, { %Array* }** %2, align 8
  %4 = getelementptr inbounds { %Array* }, { %Array* }* %3, i32 0, i32 0
  %5 = load %Array*, %Array** %4, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 1)
  %6 = bitcast { %Array* }* %3 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 1)
  %8 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %0, i32 0, i32 1
  %ys = load { { %Array* }* }*, { { %Array* }* }** %8, align 8
  %9 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %ys, i32 0, i32 0
  %10 = load { %Array* }*, { %Array* }** %9, align 8
  %11 = getelementptr inbounds { %Array* }, { %Array* }* %10, i32 0, i32 0
  %12 = load %Array*, %Array** %11, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 1)
  %13 = bitcast { %Array* }* %10 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 1)
  %14 = bitcast { { %Array* }* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 1)
  %15 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %0, i32 0, i32 2
  %result = load { { %Array* }* }*, { { %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %result, i32 0, i32 0
  %17 = load { %Array* }*, { %Array* }** %16, align 8
  %18 = getelementptr inbounds { %Array* }, { %Array* }* %17, i32 0, i32 0
  %19 = load %Array*, %Array** %18, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %19, i32 1)
  %20 = bitcast { %Array* }* %17 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 1)
  %21 = bitcast { { %Array* }* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %21, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %5)
  %signx = call %Qubit* @__quantum__rt__qubit_allocate()
  %signy = call %Qubit* @__quantum__rt__qubit_allocate()
  %22 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %5)
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %22, %Qubit* %signx)
  %23 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %12)
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %23, %Qubit* %signy)
  %24 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %25 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %24, i64 0)
  %26 = bitcast i8* %25 to %Qubit**
  store %Qubit* %signx, %Qubit** %26, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctl(%Array* %24, { { %Array* }* }* %xs)
  %27 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %28 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %27, i64 0)
  %29 = bitcast i8* %28 to %Qubit**
  store %Qubit* %signy, %Qubit** %29, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctl(%Array* %27, { { %Array* }* }* %ys)
  %30 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %31 = bitcast %Tuple* %30 to { { %Array* }*, { %Array* }*, { %Array* }* }*
  %32 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %31, i32 0, i32 0
  %33 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %31, i32 0, i32 1
  %34 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %31, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %19, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 1)
  store { %Array* }* %3, { %Array* }** %32, align 8
  store { %Array* }* %10, { %Array* }** %33, align 8
  store { %Array* }* %17, { %Array* }** %34, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplyI__ctl(%Array* %controls, { { %Array* }*, { %Array* }*, { %Array* }* }* %31)
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %signx, %Qubit* %signy)
  %35 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %36 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %35, i64 0)
  %37 = bitcast i8* %36 to %Qubit**
  store %Qubit* %signy, %Qubit** %37, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctl(%Array* %35, { { %Array* }* }* %result)
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %signx, %Qubit* %signy)
  %38 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %39 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %38, i64 0)
  %40 = bitcast i8* %39 to %Qubit**
  store %Qubit* %signx, %Qubit** %40, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctladj(%Array* %38, { { %Array* }* }* %xs)
  %41 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %42 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %41, i64 0)
  %43 = bitcast i8* %42 to %Qubit**
  store %Qubit* %signy, %Qubit** %43, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctladj(%Array* %41, { { %Array* }* }* %ys)
  %44 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %5)
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %44, %Qubit* %signx)
  %45 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %12)
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %45, %Qubit* %signy)
  call void @__quantum__rt__array_update_reference_count(%Array* %24, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %27, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %30, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %35, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %38, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %41, i32 -1)
  call void @__quantum__rt__qubit_release(%Qubit* %signx)
  call void @__quantum__rt__qubit_release(%Qubit* %signy)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %21, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__MultiplySI__ctladj(%Array* %controls, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %0, i32 0, i32 0
  %xs = load { { %Array* }* }*, { { %Array* }* }** %1, align 8
  %2 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %3 = load { %Array* }*, { %Array* }** %2, align 8
  %4 = getelementptr inbounds { %Array* }, { %Array* }* %3, i32 0, i32 0
  %5 = load %Array*, %Array** %4, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 1)
  %6 = bitcast { %Array* }* %3 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 1)
  %8 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %0, i32 0, i32 1
  %ys = load { { %Array* }* }*, { { %Array* }* }** %8, align 8
  %9 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %ys, i32 0, i32 0
  %10 = load { %Array* }*, { %Array* }** %9, align 8
  %11 = getelementptr inbounds { %Array* }, { %Array* }* %10, i32 0, i32 0
  %12 = load %Array*, %Array** %11, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 1)
  %13 = bitcast { %Array* }* %10 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 1)
  %14 = bitcast { { %Array* }* }* %ys to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 1)
  %15 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }*, { { %Array* }* }* }* %0, i32 0, i32 2
  %result = load { { %Array* }* }*, { { %Array* }* }** %15, align 8
  %16 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %result, i32 0, i32 0
  %17 = load { %Array* }*, { %Array* }** %16, align 8
  %18 = getelementptr inbounds { %Array* }, { %Array* }* %17, i32 0, i32 0
  %19 = load %Array*, %Array** %18, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %19, i32 1)
  %20 = bitcast { %Array* }* %17 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 1)
  %21 = bitcast { { %Array* }* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %21, i32 1)
  %__qsVar0__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %5)
  %__qsVar1__signx__ = call %Qubit* @__quantum__rt__qubit_allocate()
  %__qsVar2__signy__ = call %Qubit* @__quantum__rt__qubit_allocate()
  %22 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %12)
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %22, %Qubit* %__qsVar2__signy__)
  %23 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %5)
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %23, %Qubit* %__qsVar1__signx__)
  %24 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %25 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %24, i64 0)
  %26 = bitcast i8* %25 to %Qubit**
  store %Qubit* %__qsVar2__signy__, %Qubit** %26, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctl(%Array* %24, { { %Array* }* }* %ys)
  %27 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %28 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %27, i64 0)
  %29 = bitcast i8* %28 to %Qubit**
  store %Qubit* %__qsVar1__signx__, %Qubit** %29, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctl(%Array* %27, { { %Array* }* }* %xs)
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %__qsVar1__signx__, %Qubit* %__qsVar2__signy__)
  %30 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %31 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %30, i64 0)
  %32 = bitcast i8* %31 to %Qubit**
  store %Qubit* %__qsVar2__signy__, %Qubit** %32, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctladj(%Array* %30, { { %Array* }* }* %result)
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %__qsVar1__signx__, %Qubit* %__qsVar2__signy__)
  %33 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %34 = bitcast %Tuple* %33 to { { %Array* }*, { %Array* }*, { %Array* }* }*
  %35 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %34, i32 0, i32 0
  %36 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %34, i32 0, i32 1
  %37 = getelementptr inbounds { { %Array* }*, { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }*, { %Array* }* }* %34, i32 0, i32 2
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %19, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 1)
  store { %Array* }* %3, { %Array* }** %35, align 8
  store { %Array* }* %10, { %Array* }** %36, align 8
  store { %Array* }* %17, { %Array* }** %37, align 8
  call void @Microsoft__Quantum__Arithmetic__MultiplyI__ctladj(%Array* %controls, { { %Array* }*, { %Array* }*, { %Array* }* }* %34)
  %38 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %39 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %38, i64 0)
  %40 = bitcast i8* %39 to %Qubit**
  store %Qubit* %__qsVar2__signy__, %Qubit** %40, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctladj(%Array* %38, { { %Array* }* }* %ys)
  %41 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %42 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %41, i64 0)
  %43 = bitcast i8* %42 to %Qubit**
  store %Qubit* %__qsVar1__signx__, %Qubit** %43, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctladj(%Array* %41, { { %Array* }* }* %xs)
  %44 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %12)
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %44, %Qubit* %__qsVar2__signy__)
  %45 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %5)
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %45, %Qubit* %__qsVar1__signx__)
  call void @__quantum__rt__array_update_reference_count(%Array* %24, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %27, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %30, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %33, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %38, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %41, i32 -1)
  call void @__quantum__rt__qubit_release(%Qubit* %__qsVar1__signx__)
  call void @__quantum__rt__qubit_release(%Qubit* %__qsVar2__signy__)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %19, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %21, i32 -1)
  ret void
}

define double @Microsoft__Quantum__Math__AbsD__body(double %a) {
entry:
  %0 = fcmp olt double %a, 0.000000e+00
  br i1 %0, label %condTrue__1, label %condFalse__1

condTrue__1:                                      ; preds = %entry
  %1 = fneg double %a
  br label %condContinue__1

condFalse__1:                                     ; preds = %entry
  br label %condContinue__1

condContinue__1:                                  ; preds = %condFalse__1, %condTrue__1
  %2 = phi double [ %1, %condTrue__1 ], [ %a, %condFalse__1 ]
  ret double %2
}

define i64 @Microsoft__Quantum__Math__Floor__body(double %value) {
entry:
  %0 = call { i64, double, i1 }* @Microsoft__Quantum__Math____QsRef2__ExtendedTruncation____body(double %value)
  %1 = getelementptr inbounds { i64, double, i1 }, { i64, double, i1 }* %0, i32 0, i32 0
  %truncated = load i64, i64* %1, align 4
  %2 = getelementptr inbounds { i64, double, i1 }, { i64, double, i1 }* %0, i32 0, i32 1
  %remainder = load double, double* %2, align 8
  %3 = getelementptr inbounds { i64, double, i1 }, { i64, double, i1 }* %0, i32 0, i32 2
  %isPositive = load i1, i1* %3, align 1
  %4 = call double @Microsoft__Quantum__Math__AbsD__body(double %remainder)
  %5 = fcmp ole double %4, 1.000000e-15
  br i1 %5, label %then0__1, label %else__1

then0__1:                                         ; preds = %entry
  %6 = bitcast { i64, double, i1 }* %0 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret i64 %truncated

else__1:                                          ; preds = %entry
  br i1 %isPositive, label %condTrue__1, label %condFalse__1

condTrue__1:                                      ; preds = %else__1
  br label %condContinue__1

condFalse__1:                                     ; preds = %else__1
  %7 = sub i64 %truncated, 1
  br label %condContinue__1

condContinue__1:                                  ; preds = %condFalse__1, %condTrue__1
  %8 = phi i64 [ %truncated, %condTrue__1 ], [ %7, %condFalse__1 ]
  %9 = bitcast { i64, double, i1 }* %0 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %9, i32 -1)
  ret i64 %8

continue__1:                                      ; No predecessors!
  %10 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([28 x i8], [28 x i8]* @52, i32 0, i32 0))
  %11 = bitcast { i64, double, i1 }* %0 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 -1)
  call void @__quantum__rt__fail(%String* %10)
  unreachable
}

define void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__body(%Callable* %outerOperation, %Callable* %innerOperation, { { %Array* }*, { %Array* }* }* %target) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %0 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %target, i32 0, i32 0
  %1 = load { %Array* }*, { %Array* }** %0, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %target, i32 0, i32 1
  %6 = load { %Array* }*, { %Array* }** %5, align 8
  %7 = getelementptr inbounds { %Array* }, { %Array* }* %6, i32 0, i32 0
  %8 = load %Array*, %Array** %7, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 1)
  %9 = bitcast { %Array* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 1)
  %10 = bitcast { { %Array* }*, { %Array* }* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 1)
  call void @__quantum__rt__callable_invoke(%Callable* %outerOperation, %Tuple* %10, %Tuple* null)
  call void @__quantum__rt__callable_invoke(%Callable* %innerOperation, %Tuple* %10, %Tuple* null)
  %11 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %11)
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %10, %Tuple* null)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %11, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %3 = load { %Array* }*, { %Array* }** %1, align 8
  %4 = load { %Array* }*, { %Array* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____body({ %Array* }* %3, { %Array* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %3 = load { %Array* }*, { %Array* }** %1, align 8
  %4 = load { %Array* }*, { %Array* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____adj({ %Array* }* %3, { %Array* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____ctl(%Array* %3, { { %Array* }*, { %Array* }* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyOuterTTKAdder____ctladj(%Array* %3, { { %Array* }*, { %Array* }* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %3 = load { %Array* }*, { %Array* }** %1, align 8
  %4 = load { %Array* }*, { %Array* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____body({ %Array* }* %3, { %Array* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %3 = load { %Array* }*, { %Array* }** %1, align 8
  %4 = load { %Array* }*, { %Array* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____adj({ %Array* }* %3, { %Array* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____ctl(%Array* %3, { { %Array* }*, { %Array* }* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdderWithoutCarry____ctladj(%Array* %3, { { %Array* }*, { %Array* }* }* %4)
  ret void
}

define void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__adj(%Callable* %outerOperation, %Callable* %innerOperation, { { %Array* }*, { %Array* }* }* %target) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %0 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %target, i32 0, i32 0
  %1 = load { %Array* }*, { %Array* }** %0, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %target, i32 0, i32 1
  %6 = load { %Array* }*, { %Array* }** %5, align 8
  %7 = getelementptr inbounds { %Array* }, { %Array* }* %6, i32 0, i32 0
  %8 = load %Array*, %Array** %7, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 1)
  %9 = bitcast { %Array* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 1)
  %10 = bitcast { { %Array* }*, { %Array* }* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 1)
  %11 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %11)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %11)
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %10, %Tuple* null)
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %innerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %10, %Tuple* null)
  %13 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %13, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %13)
  call void @__quantum__rt__callable_invoke(%Callable* %13, %Tuple* %10, %Tuple* null)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %8, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %9, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %13, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %13, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__ctl(%Array* %controlRegister, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 1)
  %1 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %outerOperation = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  %2 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %innerOperation = load %Callable*, %Callable** %2, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %3 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 2
  %target = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %3, align 8
  %4 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %target, i32 0, i32 0
  %5 = load { %Array* }*, { %Array* }** %4, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %5, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %5 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %target, i32 0, i32 1
  %10 = load { %Array* }*, { %Array* }** %9, align 8
  %11 = getelementptr inbounds { %Array* }, { %Array* }* %10, i32 0, i32 0
  %12 = load %Array*, %Array** %11, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 1)
  %13 = bitcast { %Array* }* %10 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 1)
  %14 = bitcast { { %Array* }*, { %Array* }* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 1)
  call void @__quantum__rt__callable_invoke(%Callable* %outerOperation, %Tuple* %14, %Tuple* null)
  %15 = call %Callable* @__quantum__rt__callable_copy(%Callable* %innerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %15)
  %16 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %17 = bitcast %Tuple* %16 to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %18 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %17, i32 0, i32 0
  %19 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %17, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 1)
  store %Array* %controlRegister, %Array** %18, align 8
  store { { %Array* }*, { %Array* }* }* %target, { { %Array* }*, { %Array* }* }** %19, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %15, %Tuple* %16, %Tuple* null)
  %20 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %20, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %20)
  call void @__quantum__rt__callable_invoke(%Callable* %20, %Tuple* %14, %Tuple* null)
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %16, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %20, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %20, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___bfa31039d0be4a608254cc24e08c4c06_ApplyWithCA__ctladj(%Array* %controlRegister, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 1)
  %1 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %outerOperation = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  %2 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %innerOperation = load %Callable*, %Callable** %2, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %3 = getelementptr inbounds { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }, { %Callable*, %Callable*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 2
  %target = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %3, align 8
  %4 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %target, i32 0, i32 0
  %5 = load { %Array* }*, { %Array* }** %4, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %5, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %5 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %target, i32 0, i32 1
  %10 = load { %Array* }*, { %Array* }** %9, align 8
  %11 = getelementptr inbounds { %Array* }, { %Array* }* %10, i32 0, i32 0
  %12 = load %Array*, %Array** %11, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 1)
  %13 = bitcast { %Array* }* %10 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 1)
  %14 = bitcast { { %Array* }*, { %Array* }* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 1)
  %15 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %15)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %15)
  call void @__quantum__rt__callable_invoke(%Callable* %15, %Tuple* %14, %Tuple* null)
  %16 = call %Callable* @__quantum__rt__callable_copy(%Callable* %innerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %16, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %16)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %16)
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %19 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %18, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 1)
  store %Array* %controlRegister, %Array** %19, align 8
  store { { %Array* }*, { %Array* }* }* %target, { { %Array* }*, { %Array* }* }** %20, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %16, %Tuple* %17, %Tuple* null)
  %21 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %21, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %21)
  call void @__quantum__rt__callable_invoke(%Callable* %21, %Tuple* %14, %Tuple* null)
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %16, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %16, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %21, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %21, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__19__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = load { %Array* }*, { %Array* }** %1, align 8
  %3 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %4 = load { %Array* }*, { %Array* }** %3, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %6 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 1
  %7 = load %Qubit*, %Qubit** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 2
  store { %Array* }* %2, { %Array* }** %10, align 8
  store { %Array* }* %4, { %Array* }** %11, align 8
  store %Qubit* %7, %Qubit** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %14, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__19__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = load { %Array* }*, { %Array* }** %1, align 8
  %3 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %4 = load { %Array* }*, { %Array* }** %3, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %6 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 1
  %7 = load %Qubit*, %Qubit** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 2
  store { %Array* }* %2, { %Array* }** %10, align 8
  store { %Array* }* %4, { %Array* }** %11, align 8
  store %Qubit* %7, %Qubit** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  %15 = call %Callable* @__quantum__rt__callable_copy(%Callable* %14, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %15)
  call void @__quantum__rt__callable_invoke(%Callable* %15, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__19__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 0
  %6 = load { %Array* }*, { %Array* }** %5, align 8
  %7 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 1
  %8 = load { %Array* }*, { %Array* }** %7, align 8
  %9 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %10 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 1
  %11 = load %Qubit*, %Qubit** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 2
  store { %Array* }* %6, { %Array* }** %14, align 8
  store { %Array* }* %8, { %Array* }** %15, align 8
  store %Qubit* %11, %Qubit** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }*
  %19 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { { %Array* }*, { %Array* }*, %Qubit* }* %13, { { %Array* }*, { %Array* }*, %Qubit* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__19__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 0
  %6 = load { %Array* }*, { %Array* }** %5, align 8
  %7 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 1
  %8 = load { %Array* }*, { %Array* }** %7, align 8
  %9 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %10 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 1
  %11 = load %Qubit*, %Qubit** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 2
  store { %Array* }* %6, { %Array* }** %14, align 8
  store { %Array* }* %8, { %Array* }** %15, align 8
  store %Qubit* %11, %Qubit** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }*
  %19 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { { %Array* }*, { %Array* }*, %Qubit* }* %13, { { %Array* }*, { %Array* }*, %Qubit* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %23)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }*, %Qubit* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 1
  %3 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 2
  %4 = load { %Array* }*, { %Array* }** %1, align 8
  %5 = load { %Array* }*, { %Array* }** %2, align 8
  %6 = load %Qubit*, %Qubit** %3, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____body({ %Array* }* %4, { %Array* }* %5, %Qubit* %6)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }*, %Qubit* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 1
  %3 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %0, i32 0, i32 2
  %4 = load { %Array* }*, { %Array* }** %1, align 8
  %5 = load { %Array* }*, { %Array* }** %2, align 8
  %6 = load %Qubit*, %Qubit** %3, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____adj({ %Array* }* %4, { %Array* }* %5, %Qubit* %6)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }*, %Qubit* }*, { { %Array* }*, { %Array* }*, %Qubit* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____ctl(%Array* %3, { { %Array* }*, { %Array* }*, %Qubit* }* %4)
  ret void
}

define void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }*, %Qubit* }*, { { %Array* }*, { %Array* }*, %Qubit* }** %2, align 8
  call void @Microsoft__Quantum__Arithmetic____QsRef3__ApplyInnerTTKAdder____ctladj(%Array* %3, { { %Array* }*, { %Array* }*, %Qubit* }* %4)
  ret void
}

define void @MemoryManagement__7__RefCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %1 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @MemoryManagement__7__AliasCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %1 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @Lifted__PartialApplication__20__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = load { %Array* }*, { %Array* }** %1, align 8
  %3 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %4 = load { %Array* }*, { %Array* }** %3, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %6 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 1
  %7 = load %Qubit*, %Qubit** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 2
  store { %Array* }* %2, { %Array* }** %10, align 8
  store { %Array* }* %4, { %Array* }** %11, align 8
  store %Qubit* %7, %Qubit** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %14, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__20__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = load { %Array* }*, { %Array* }** %1, align 8
  %3 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %4 = load { %Array* }*, { %Array* }** %3, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %6 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 1
  %7 = load %Qubit*, %Qubit** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 2
  store { %Array* }* %2, { %Array* }** %10, align 8
  store { %Array* }* %4, { %Array* }** %11, align 8
  store %Qubit* %7, %Qubit** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  %15 = call %Callable* @__quantum__rt__callable_copy(%Callable* %14, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %15)
  call void @__quantum__rt__callable_invoke(%Callable* %15, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__20__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 0
  %6 = load { %Array* }*, { %Array* }** %5, align 8
  %7 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 1
  %8 = load { %Array* }*, { %Array* }** %7, align 8
  %9 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %10 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 1
  %11 = load %Qubit*, %Qubit** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 2
  store { %Array* }* %6, { %Array* }** %14, align 8
  store { %Array* }* %8, { %Array* }** %15, align 8
  store %Qubit* %11, %Qubit** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }*
  %19 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { { %Array* }*, { %Array* }*, %Qubit* }* %13, { { %Array* }*, { %Array* }*, %Qubit* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__20__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 0
  %6 = load { %Array* }*, { %Array* }** %5, align 8
  %7 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 1
  %8 = load { %Array* }*, { %Array* }** %7, align 8
  %9 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %10 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 1
  %11 = load %Qubit*, %Qubit** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 2
  store { %Array* }* %6, { %Array* }** %14, align 8
  store { %Array* }* %8, { %Array* }** %15, align 8
  store %Qubit* %11, %Qubit** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }*
  %19 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { { %Array* }*, { %Array* }*, %Qubit* }* %13, { { %Array* }*, { %Array* }*, %Qubit* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %23)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__21__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = load { %Array* }*, { %Array* }** %1, align 8
  %3 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %4 = load { %Array* }*, { %Array* }** %3, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %6 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 1
  %7 = load %Qubit*, %Qubit** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 2
  store { %Array* }* %2, { %Array* }** %10, align 8
  store { %Array* }* %4, { %Array* }** %11, align 8
  store %Qubit* %7, %Qubit** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %14, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__21__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = load { %Array* }*, { %Array* }** %1, align 8
  %3 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %4 = load { %Array* }*, { %Array* }** %3, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %6 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 1
  %7 = load %Qubit*, %Qubit** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 2
  store { %Array* }* %2, { %Array* }** %10, align 8
  store { %Array* }* %4, { %Array* }** %11, align 8
  store %Qubit* %7, %Qubit** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  %15 = call %Callable* @__quantum__rt__callable_copy(%Callable* %14, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %15)
  call void @__quantum__rt__callable_invoke(%Callable* %15, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__21__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 0
  %6 = load { %Array* }*, { %Array* }** %5, align 8
  %7 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 1
  %8 = load { %Array* }*, { %Array* }** %7, align 8
  %9 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %10 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 1
  %11 = load %Qubit*, %Qubit** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 2
  store { %Array* }* %6, { %Array* }** %14, align 8
  store { %Array* }* %8, { %Array* }** %15, align 8
  store %Qubit* %11, %Qubit** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }*
  %19 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { { %Array* }*, { %Array* }*, %Qubit* }* %13, { { %Array* }*, { %Array* }*, %Qubit* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__21__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 0
  %6 = load { %Array* }*, { %Array* }** %5, align 8
  %7 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 1
  %8 = load { %Array* }*, { %Array* }** %7, align 8
  %9 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %10 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 1
  %11 = load %Qubit*, %Qubit** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 2
  store { %Array* }* %6, { %Array* }** %14, align 8
  store { %Array* }* %8, { %Array* }** %15, align 8
  store %Qubit* %11, %Qubit** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }*
  %19 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { { %Array* }*, { %Array* }*, %Qubit* }* %13, { { %Array* }*, { %Array* }*, %Qubit* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %23)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__22__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = load { %Array* }*, { %Array* }** %1, align 8
  %3 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %4 = load { %Array* }*, { %Array* }** %3, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %6 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 1
  %7 = load %Qubit*, %Qubit** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 2
  store { %Array* }* %2, { %Array* }** %10, align 8
  store { %Array* }* %4, { %Array* }** %11, align 8
  store %Qubit* %7, %Qubit** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %14, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__22__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { { %Array* }*, { %Array* }* }*
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %2 = load { %Array* }*, { %Array* }** %1, align 8
  %3 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %4 = load { %Array* }*, { %Array* }** %3, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %6 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 1
  %7 = load %Qubit*, %Qubit** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %9 = bitcast %Tuple* %8 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 1
  %12 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %9, i32 0, i32 2
  store { %Array* }* %2, { %Array* }** %10, align 8
  store { %Array* }* %4, { %Array* }** %11, align 8
  store %Qubit* %7, %Qubit** %12, align 8
  %13 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %5, i32 0, i32 0
  %14 = load %Callable*, %Callable** %13, align 8
  %15 = call %Callable* @__quantum__rt__callable_copy(%Callable* %14, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %15)
  call void @__quantum__rt__callable_invoke(%Callable* %15, %Tuple* %8, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__22__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 0
  %6 = load { %Array* }*, { %Array* }** %5, align 8
  %7 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 1
  %8 = load { %Array* }*, { %Array* }** %7, align 8
  %9 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %10 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 1
  %11 = load %Qubit*, %Qubit** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 2
  store { %Array* }* %6, { %Array* }** %14, align 8
  store { %Array* }* %8, { %Array* }** %15, align 8
  store %Qubit* %11, %Qubit** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }*
  %19 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { { %Array* }*, { %Array* }*, %Qubit* }* %13, { { %Array* }*, { %Array* }*, %Qubit* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__22__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, { { %Array* }*, { %Array* }* }* }*
  %1 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }* }* }, { %Array*, { { %Array* }*, { %Array* }* }* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load { { %Array* }*, { %Array* }* }*, { { %Array* }*, { %Array* }* }** %2, align 8
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 0
  %6 = load { %Array* }*, { %Array* }** %5, align 8
  %7 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %4, i32 0, i32 1
  %8 = load { %Array* }*, { %Array* }** %7, align 8
  %9 = bitcast %Tuple* %capture-tuple to { %Callable*, %Qubit* }*
  %10 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 1
  %11 = load %Qubit*, %Qubit** %10, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 3))
  %13 = bitcast %Tuple* %12 to { { %Array* }*, { %Array* }*, %Qubit* }*
  %14 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 1
  %16 = getelementptr inbounds { { %Array* }*, { %Array* }*, %Qubit* }, { { %Array* }*, { %Array* }*, %Qubit* }* %13, i32 0, i32 2
  store { %Array* }* %6, { %Array* }** %14, align 8
  store { %Array* }* %8, { %Array* }** %15, align 8
  store %Qubit* %11, %Qubit** %16, align 8
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }*
  %19 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }, { %Array*, { { %Array* }*, { %Array* }*, %Qubit* }* }* %18, i32 0, i32 1
  store %Array* %3, %Array** %19, align 8
  store { { %Array* }*, { %Array* }*, %Qubit* }* %13, { { %Array* }*, { %Array* }*, %Qubit* }** %20, align 8
  %21 = getelementptr inbounds { %Callable*, %Qubit* }, { %Callable*, %Qubit* }* %9, i32 0, i32 0
  %22 = load %Callable*, %Callable** %21, align 8
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %22, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %23)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %17, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareSI__body({ { %Array* }* }* %xs, { { %Array* }* }* %result) {
entry:
  %0 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %1 = load { %Array* }*, { %Array* }** %0, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %result, i32 0, i32 0
  %7 = load { %Array* }*, { %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Array* }, { %Array* }* %7, i32 0, i32 0
  %9 = load %Array*, %Array** %8, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %9, i32 1)
  %10 = bitcast { %Array* }* %7 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 1)
  %11 = bitcast { { %Array* }* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %11, i32 1)
  %12 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %13 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %14 = bitcast %Tuple* %13 to { { { %Array* }* }*, { { %Array* }* }* }*
  %15 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }* }* %14, i32 0, i32 0
  %16 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }* }* %14, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 1)
  store { { %Array* }* }* %xs, { { %Array* }* }** %15, align 8
  store { { %Array* }* }* %result, { { %Array* }* }** %16, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareSI__ctl(%Array* %12, { { { %Array* }* }*, { { %Array* }* }* }* %14)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %9, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %11, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareSI__adj({ { %Array* }* }* %xs, { { %Array* }* }* %result) {
entry:
  %0 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %1 = load { %Array* }*, { %Array* }** %0, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %1, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %1 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %result, i32 0, i32 0
  %7 = load { %Array* }*, { %Array* }** %6, align 8
  %8 = getelementptr inbounds { %Array* }, { %Array* }* %7, i32 0, i32 0
  %9 = load %Array*, %Array** %8, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %9, i32 1)
  %10 = bitcast { %Array* }* %7 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 1)
  %11 = bitcast { { %Array* }* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %11, i32 1)
  %12 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %13 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %14 = bitcast %Tuple* %13 to { { { %Array* }* }*, { { %Array* }* }* }*
  %15 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }* }* %14, i32 0, i32 0
  %16 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }* }* %14, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 1)
  store { { %Array* }* }* %xs, { { %Array* }* }** %15, align 8
  store { { %Array* }* }* %result, { { %Array* }* }** %16, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareSI__ctladj(%Array* %12, { { { %Array* }* }*, { { %Array* }* }* }* %14)
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %9, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %11, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %3, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %9, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %10, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %11, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareI__body({ %Array* }* %xs, { %Array* }* %result) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %result, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %8 = bitcast %Tuple* %7 to { { %Array* }*, { %Array* }* }*
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %8, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { %Array* }* %xs, { %Array* }** %9, align 8
  store { %Array* }* %result, { %Array* }** %10, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareI__ctl(%Array* %6, { { %Array* }*, { %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareI__ctl(%Array* %controls, { { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %result = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %result, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %9 = mul i64 2, %n
  %10 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %11 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([87 x i8], [87 x i8]* @49, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %9, i64 %10, %String* %11)
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__body(%Array* %7)
  %anc = call %Qubit* @__quantum__rt__qubit_allocate()
  %12 = sub i64 %n, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %i = phi i64 [ 0, %entry ], [ %47, %exiting__1 ]
  %13 = icmp sle i64 %i, %12
  br i1 %13, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %14 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %15 = bitcast %Tuple* %14 to { %Qubit*, %Qubit* }*
  %16 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %15, i32 0, i32 0
  %17 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %15, i32 0, i32 1
  %18 = load %Array*, %Array** %2, align 8
  %19 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %18, i64 %i)
  %20 = bitcast i8* %19 to %Qubit**
  %21 = load %Qubit*, %Qubit** %20, align 8
  store %Qubit* %21, %Qubit** %16, align 8
  store %Qubit* %anc, %Qubit** %17, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %controls, { %Qubit*, %Qubit* }* %15)
  %22 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %23 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %22, i64 0)
  %24 = bitcast i8* %23 to %Qubit**
  store %Qubit* %anc, %Qubit** %24, align 8
  %25 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %26 = bitcast %Tuple* %25 to { { %Array* }*, { %Array* }* }*
  %27 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %26, i32 0, i32 0
  %28 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %26, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  %29 = load %Array*, %Array** %6, align 8
  %30 = add i64 %i, %n
  %31 = load %Range, %Range* @EmptyRange, align 4
  %32 = insertvalue %Range %31, i64 %i, 0
  %33 = insertvalue %Range %32, i64 1, 1
  %34 = insertvalue %Range %33, i64 %30, 2
  %35 = call %Array* @__quantum__rt__array_slice_1d(%Array* %29, %Range %34, i1 true)
  %36 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %35)
  call void @__quantum__rt__array_update_reference_count(%Array* %35, i32 -1)
  store { %Array* }* %xs, { %Array* }** %27, align 8
  store { %Array* }* %36, { %Array* }** %28, align 8
  call void @Microsoft__Quantum__Arithmetic__AddI__ctl(%Array* %22, { { %Array* }*, { %Array* }* }* %26)
  %37 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %38 = bitcast %Tuple* %37 to { %Qubit*, %Qubit* }*
  %39 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %38, i32 0, i32 0
  %40 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %38, i32 0, i32 1
  %41 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %18, i64 %i)
  %42 = bitcast i8* %41 to %Qubit**
  %43 = load %Qubit*, %Qubit** %42, align 8
  store %Qubit* %43, %Qubit** %39, align 8
  store %Qubit* %anc, %Qubit** %40, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctl(%Array* %controls, { %Qubit*, %Qubit* }* %38)
  %44 = getelementptr inbounds { %Array* }, { %Array* }* %36, i32 0, i32 0
  %45 = load %Array*, %Array** %44, align 8
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %22, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %18, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %45, i32 -1)
  %46 = bitcast { %Array* }* %36 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %46, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %25, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %37, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %47 = add i64 %i, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__qubit_release(%Qubit* %anc)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %48 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %48, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  %49 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %49, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %11, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareI__adj({ %Array* }* %xs, { %Array* }* %result) {
entry:
  %0 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %1 = load %Array*, %Array** %0, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 1)
  %2 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 1)
  %3 = getelementptr inbounds { %Array* }, { %Array* }* %result, i32 0, i32 0
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 1)
  %5 = bitcast { %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 1)
  %6 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 0)
  %7 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %8 = bitcast %Tuple* %7 to { { %Array* }*, { %Array* }* }*
  %9 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %8, i32 0, i32 0
  %10 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %8, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 1)
  store { %Array* }* %xs, { %Array* }** %9, align 8
  store { %Array* }* %result, { %Array* }** %10, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareI__ctladj(%Array* %6, { { %Array* }*, { %Array* }* }* %8)
  call void @__quantum__rt__array_update_alias_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %1, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %2, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %7, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareI__ctladj(%Array* %controls, { { %Array* }*, { %Array* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 0
  %xs = load { %Array* }*, { %Array* }** %1, align 8
  %2 = getelementptr inbounds { %Array* }, { %Array* }* %xs, i32 0, i32 0
  %3 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %3, i32 1)
  %4 = bitcast { %Array* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 1)
  %5 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %0, i32 0, i32 1
  %result = load { %Array* }*, { %Array* }** %5, align 8
  %6 = getelementptr inbounds { %Array* }, { %Array* }* %result, i32 0, i32 0
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { %Array* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %__qsVar0__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %3)
  %9 = mul i64 2, %__qsVar0__n__
  %10 = call i64 @__quantum__rt__array_get_size_1d(%Array* %7)
  %11 = call %String* @__quantum__rt__string_create(i8* getelementptr inbounds ([87 x i8], [87 x i8]* @50, i32 0, i32 0))
  call void @Microsoft__Quantum__Diagnostics__EqualityFactI__body(i64 %9, i64 %10, %String* %11)
  %__qsVar1__anc__ = call %Qubit* @__quantum__rt__qubit_allocate()
  %12 = sub i64 %__qsVar0__n__, 1
  %13 = sub i64 %12, 0
  %14 = udiv i64 %13, 1
  %15 = mul i64 1, %14
  %16 = add i64 0, %15
  %17 = load %Range, %Range* @EmptyRange, align 4
  %18 = insertvalue %Range %17, i64 %16, 0
  %19 = insertvalue %Range %18, i64 -1, 1
  %20 = insertvalue %Range %19, i64 0, 2
  %21 = extractvalue %Range %20, 0
  %22 = extractvalue %Range %20, 1
  %23 = extractvalue %Range %20, 2
  br label %preheader__1

preheader__1:                                     ; preds = %entry
  %24 = icmp sgt i64 %22, 0
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %__qsVar2__i__ = phi i64 [ %21, %preheader__1 ], [ %61, %exiting__1 ]
  %25 = icmp sle i64 %__qsVar2__i__, %23
  %26 = icmp sge i64 %__qsVar2__i__, %23
  %27 = select i1 %24, i1 %25, i1 %26
  br i1 %27, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %28 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %29 = bitcast %Tuple* %28 to { %Qubit*, %Qubit* }*
  %30 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %29, i32 0, i32 0
  %31 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %29, i32 0, i32 1
  %32 = load %Array*, %Array** %2, align 8
  %33 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %32, i64 %__qsVar2__i__)
  %34 = bitcast i8* %33 to %Qubit**
  %35 = load %Qubit*, %Qubit** %34, align 8
  store %Qubit* %35, %Qubit** %30, align 8
  store %Qubit* %__qsVar1__anc__, %Qubit** %31, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %controls, { %Qubit*, %Qubit* }* %29)
  %36 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %37 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %36, i64 0)
  %38 = bitcast i8* %37 to %Qubit**
  store %Qubit* %__qsVar1__anc__, %Qubit** %38, align 8
  %39 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %40 = bitcast %Tuple* %39 to { { %Array* }*, { %Array* }* }*
  %41 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %40, i32 0, i32 0
  %42 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %40, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %32, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 1)
  %43 = load %Array*, %Array** %6, align 8
  %44 = add i64 %__qsVar2__i__, %__qsVar0__n__
  %45 = load %Range, %Range* @EmptyRange, align 4
  %46 = insertvalue %Range %45, i64 %__qsVar2__i__, 0
  %47 = insertvalue %Range %46, i64 1, 1
  %48 = insertvalue %Range %47, i64 %44, 2
  %49 = call %Array* @__quantum__rt__array_slice_1d(%Array* %43, %Range %48, i1 true)
  %50 = call { %Array* }* @Microsoft__Quantum__Arithmetic__LittleEndian__body(%Array* %49)
  call void @__quantum__rt__array_update_reference_count(%Array* %49, i32 -1)
  store { %Array* }* %xs, { %Array* }** %41, align 8
  store { %Array* }* %50, { %Array* }** %42, align 8
  call void @Microsoft__Quantum__Arithmetic__AddI__ctladj(%Array* %36, { { %Array* }*, { %Array* }* }* %40)
  %51 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %52 = bitcast %Tuple* %51 to { %Qubit*, %Qubit* }*
  %53 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %52, i32 0, i32 0
  %54 = getelementptr inbounds { %Qubit*, %Qubit* }, { %Qubit*, %Qubit* }* %52, i32 0, i32 1
  %55 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %32, i64 %__qsVar2__i__)
  %56 = bitcast i8* %55 to %Qubit**
  %57 = load %Qubit*, %Qubit** %56, align 8
  store %Qubit* %57, %Qubit** %53, align 8
  store %Qubit* %__qsVar1__anc__, %Qubit** %54, align 8
  call void @Microsoft__Quantum__Intrinsic__CNOT__ctladj(%Array* %controls, { %Qubit*, %Qubit* }* %52)
  %58 = getelementptr inbounds { %Array* }, { %Array* }* %50, i32 0, i32 0
  %59 = load %Array*, %Array** %58, align 8
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %28, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %36, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %32, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %59, i32 -1)
  %60 = bitcast { %Array* }* %50 to %Tuple*
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %60, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %39, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %51, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %61 = add i64 %__qsVar2__i__, %22
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__qubit_release(%Qubit* %__qsVar1__anc__)
  %62 = load %Array*, %Array** %6, align 8
  call void @Microsoft__Quantum__Diagnostics__AssertAllZero__adj(%Array* %62)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  %63 = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %63, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %4, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %62, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__string_update_reference_count(%String* %11, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareSI__ctl(%Array* %controls, { { { %Array* }* }*, { { %Array* }* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }* }* %0, i32 0, i32 0
  %xs = load { { %Array* }* }*, { { %Array* }* }** %1, align 8
  %2 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %3 = load { %Array* }*, { %Array* }** %2, align 8
  %4 = getelementptr inbounds { %Array* }, { %Array* }* %3, i32 0, i32 0
  %5 = load %Array*, %Array** %4, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 1)
  %6 = bitcast { %Array* }* %3 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 1)
  %8 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }* }* %0, i32 0, i32 1
  %result = load { { %Array* }* }*, { { %Array* }* }** %8, align 8
  %9 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %result, i32 0, i32 0
  %10 = load { %Array* }*, { %Array* }** %9, align 8
  %11 = getelementptr inbounds { %Array* }, { %Array* }* %10, i32 0, i32 0
  %12 = load %Array*, %Array** %11, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 1)
  %13 = bitcast { %Array* }* %10 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 1)
  %14 = bitcast { { %Array* }* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 1)
  %n = call i64 @__quantum__rt__array_get_size_1d(%Array* %5)
  %signx = call %Qubit* @__quantum__rt__qubit_allocate()
  %signy = call %Qubit* @__quantum__rt__qubit_allocate()
  %15 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %5)
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %15, %Qubit* %signx)
  %16 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %17 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %16, i64 0)
  %18 = bitcast i8* %17 to %Qubit**
  store %Qubit* %signx, %Qubit** %18, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctl(%Array* %16, { { %Array* }* }* %xs)
  %19 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %20 = bitcast %Tuple* %19 to { { %Array* }*, { %Array* }* }*
  %21 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %20, i32 0, i32 0
  %22 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %20, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 1)
  store { %Array* }* %3, { %Array* }** %21, align 8
  store { %Array* }* %10, { %Array* }** %22, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareI__ctl(%Array* %controls, { { %Array* }*, { %Array* }* }* %20)
  %23 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %24 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %23, i64 0)
  %25 = bitcast i8* %24 to %Qubit**
  store %Qubit* %signx, %Qubit** %25, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctladj(%Array* %23, { { %Array* }* }* %xs)
  %26 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %5)
  call void @Microsoft__Quantum__Intrinsic__CNOT__body(%Qubit* %26, %Qubit* %signx)
  call void @__quantum__rt__array_update_reference_count(%Array* %16, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %23, i32 -1)
  call void @__quantum__rt__qubit_release(%Qubit* %signx)
  call void @__quantum__rt__qubit_release(%Qubit* %signy)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Arithmetic__SquareSI__ctladj(%Array* %controls, { { { %Array* }* }*, { { %Array* }* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 1)
  %1 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }* }* %0, i32 0, i32 0
  %xs = load { { %Array* }* }*, { { %Array* }* }** %1, align 8
  %2 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %xs, i32 0, i32 0
  %3 = load { %Array* }*, { %Array* }** %2, align 8
  %4 = getelementptr inbounds { %Array* }, { %Array* }* %3, i32 0, i32 0
  %5 = load %Array*, %Array** %4, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 1)
  %6 = bitcast { %Array* }* %3 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 1)
  %7 = bitcast { { %Array* }* }* %xs to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 1)
  %8 = getelementptr inbounds { { { %Array* }* }*, { { %Array* }* }* }, { { { %Array* }* }*, { { %Array* }* }* }* %0, i32 0, i32 1
  %result = load { { %Array* }* }*, { { %Array* }* }** %8, align 8
  %9 = getelementptr inbounds { { %Array* }* }, { { %Array* }* }* %result, i32 0, i32 0
  %10 = load { %Array* }*, { %Array* }** %9, align 8
  %11 = getelementptr inbounds { %Array* }, { %Array* }* %10, i32 0, i32 0
  %12 = load %Array*, %Array** %11, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 1)
  %13 = bitcast { %Array* }* %10 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 1)
  %14 = bitcast { { %Array* }* }* %result to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 1)
  %__qsVar0__n__ = call i64 @__quantum__rt__array_get_size_1d(%Array* %5)
  %__qsVar1__signx__ = call %Qubit* @__quantum__rt__qubit_allocate()
  %__qsVar2__signy__ = call %Qubit* @__quantum__rt__qubit_allocate()
  %15 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %5)
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %15, %Qubit* %__qsVar1__signx__)
  %16 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %17 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %16, i64 0)
  %18 = bitcast i8* %17 to %Qubit**
  store %Qubit* %__qsVar1__signx__, %Qubit** %18, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctl(%Array* %16, { { %Array* }* }* %xs)
  %19 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %20 = bitcast %Tuple* %19 to { { %Array* }*, { %Array* }* }*
  %21 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %20, i32 0, i32 0
  %22 = getelementptr inbounds { { %Array* }*, { %Array* }* }, { { %Array* }*, { %Array* }* }* %20, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 1)
  store { %Array* }* %3, { %Array* }** %21, align 8
  store { %Array* }* %10, { %Array* }** %22, align 8
  call void @Microsoft__Quantum__Arithmetic__SquareI__ctladj(%Array* %controls, { { %Array* }*, { %Array* }* }* %20)
  %23 = call %Array* @__quantum__rt__array_create_1d(i32 8, i64 1)
  %24 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %23, i64 0)
  %25 = bitcast i8* %24 to %Qubit**
  store %Qubit* %__qsVar1__signx__, %Qubit** %25, align 8
  call void @Microsoft__Quantum__Arithmetic__Invert2sSI__ctladj(%Array* %23, { { %Array* }* }* %xs)
  %26 = call %Qubit* @Microsoft__Quantum__Arrays___135717def3dd46f98cf8a62f6e6fd0b3_Tail__body(%Array* %5)
  call void @Microsoft__Quantum__Intrinsic__CNOT__adj(%Qubit* %26, %Qubit* %__qsVar1__signx__)
  call void @__quantum__rt__array_update_reference_count(%Array* %16, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %19, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %23, i32 -1)
  call void @__quantum__rt__qubit_release(%Qubit* %__qsVar1__signx__)
  call void @__quantum__rt__qubit_release(%Qubit* %__qsVar2__signy__)
  call void @__quantum__rt__array_update_alias_count(%Array* %controls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %5, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 -1)
  ret void
}

define %Range @Microsoft__Quantum__Arrays___fa96fdec02544eef8fc1589d871c3b90_IndexRange__body(%Array* %array) {
entry:
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %array)
  %1 = sub i64 %0, 1
  br label %header__1

header__1:                                        ; preds = %exiting__1, %entry
  %2 = phi i64 [ 0, %entry ], [ %8, %exiting__1 ]
  %3 = icmp sle i64 %2, %1
  br i1 %3, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %4 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %array, i64 %2)
  %5 = bitcast i8* %4 to { %Qubit*, %Qubit* }**
  %6 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %5, align 8
  %7 = bitcast { %Qubit*, %Qubit* }* %6 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %7, i32 1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %8 = add i64 %2, 1
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 1)
  %9 = sub i64 %0, 1
  %10 = load %Range, %Range* @EmptyRange, align 4
  %11 = insertvalue %Range %10, i64 0, 0
  %12 = insertvalue %Range %11, i64 1, 1
  %13 = insertvalue %Range %12, i64 %9, 2
  %14 = sub i64 %0, 1
  br label %header__2

header__2:                                        ; preds = %exiting__2, %exit__1
  %15 = phi i64 [ 0, %exit__1 ], [ %21, %exiting__2 ]
  %16 = icmp sle i64 %15, %14
  br i1 %16, label %body__2, label %exit__2

body__2:                                          ; preds = %header__2
  %17 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %array, i64 %15)
  %18 = bitcast i8* %17 to { %Qubit*, %Qubit* }**
  %19 = load { %Qubit*, %Qubit* }*, { %Qubit*, %Qubit* }** %18, align 8
  %20 = bitcast { %Qubit*, %Qubit* }* %19 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %20, i32 -1)
  br label %exiting__2

exiting__2:                                       ; preds = %body__2
  %21 = add i64 %15, 1
  br label %header__2

exit__2:                                          ; preds = %header__2
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 -1)
  ret %Range %13
}

define %Range @Microsoft__Quantum__Arrays___075b44eb0d22417ea03c8829df3aae78_IndexRange__body(%Array* %array) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 1)
  %0 = call i64 @__quantum__rt__array_get_size_1d(%Array* %array)
  %1 = sub i64 %0, 1
  %2 = load %Range, %Range* @EmptyRange, align 4
  %3 = insertvalue %Range %2, i64 0, 0
  %4 = insertvalue %Range %3, i64 1, 1
  %5 = insertvalue %Range %4, i64 %1, 2
  call void @__quantum__rt__array_update_alias_count(%Array* %array, i32 -1)
  ret %Range %5
}

define void @Microsoft__Quantum__Canon___0a03bb4151e34663b70ac90c15a85f8f_ApplyToEachCA__ctl(%Array* %__controlQubits__, { %Callable*, %Array* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %singleElementOperation = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 1)
  %2 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %register = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 1)
  %3 = call %Range @Microsoft__Quantum__Arrays___075b44eb0d22417ea03c8829df3aae78_IndexRange__body(%Array* %register)
  %4 = extractvalue %Range %3, 0
  %5 = extractvalue %Range %3, 1
  %6 = extractvalue %Range %3, 2
  br label %preheader__1

preheader__1:                                     ; preds = %entry
  %7 = icmp sgt i64 %5, 0
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %idxQubit = phi i64 [ %4, %preheader__1 ], [ %19, %exiting__1 ]
  %8 = icmp sle i64 %idxQubit, %6
  %9 = icmp sge i64 %idxQubit, %6
  %10 = select i1 %7, i1 %8, i1 %9
  br i1 %10, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %11 = call %Callable* @__quantum__rt__callable_copy(%Callable* %singleElementOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %11)
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, %Qubit* }*
  %14 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %13, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__, i32 1)
  %16 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %idxQubit)
  %17 = bitcast i8* %16 to %Qubit**
  %18 = load %Qubit*, %Qubit** %17, align 8
  store %Array* %__controlQubits__, %Array** %14, align 8
  store %Qubit* %18, %Qubit** %15, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %12, %Tuple* null)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %11, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %19 = add i64 %idxQubit, %5
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___0a03bb4151e34663b70ac90c15a85f8f_ApplyToEachCA__ctladj(%Array* %__controlQubits__, { %Callable*, %Array* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 1)
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %singleElementOperation = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 1)
  %2 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %register = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 1)
  %3 = call %Range @Microsoft__Quantum__Arrays___075b44eb0d22417ea03c8829df3aae78_IndexRange__body(%Array* %register)
  %4 = extractvalue %Range %3, 0
  %5 = extractvalue %Range %3, 1
  %6 = extractvalue %Range %3, 2
  %7 = sub i64 %6, %4
  %8 = udiv i64 %7, %5
  %9 = mul i64 %5, %8
  %10 = add i64 %4, %9
  %11 = sub i64 0, %5
  %12 = load %Range, %Range* @EmptyRange, align 4
  %13 = insertvalue %Range %12, i64 %10, 0
  %14 = insertvalue %Range %13, i64 %11, 1
  %15 = insertvalue %Range %14, i64 %4, 2
  %16 = extractvalue %Range %15, 0
  %17 = extractvalue %Range %15, 1
  %18 = extractvalue %Range %15, 2
  br label %preheader__1

preheader__1:                                     ; preds = %entry
  %19 = icmp sgt i64 %17, 0
  br label %header__1

header__1:                                        ; preds = %exiting__1, %preheader__1
  %__qsVar0__idxQubit__ = phi i64 [ %16, %preheader__1 ], [ %31, %exiting__1 ]
  %20 = icmp sle i64 %__qsVar0__idxQubit__, %18
  %21 = icmp sge i64 %__qsVar0__idxQubit__, %18
  %22 = select i1 %19, i1 %20, i1 %21
  br i1 %22, label %body__1, label %exit__1

body__1:                                          ; preds = %header__1
  %23 = call %Callable* @__quantum__rt__callable_copy(%Callable* %singleElementOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %23)
  call void @__quantum__rt__callable_make_controlled(%Callable* %23)
  %24 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %25 = bitcast %Tuple* %24 to { %Array*, %Qubit* }*
  %26 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %25, i32 0, i32 0
  %27 = getelementptr inbounds { %Array*, %Qubit* }, { %Array*, %Qubit* }* %25, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__, i32 1)
  %28 = call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %register, i64 %__qsVar0__idxQubit__)
  %29 = bitcast i8* %28 to %Qubit**
  %30 = load %Qubit*, %Qubit** %29, align 8
  store %Array* %__controlQubits__, %Array** %26, align 8
  store %Qubit* %30, %Qubit** %27, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %23, %Tuple* %24, %Tuple* null)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %23, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %24, i32 -1)
  br label %exiting__1

exiting__1:                                       ; preds = %body__1
  %31 = add i64 %__qsVar0__idxQubit__, %17
  br label %header__1

exit__1:                                          ; preds = %header__1
  call void @__quantum__rt__array_update_alias_count(%Array* %__controlQubits__, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %singleElementOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %register, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___6f7d9c2cdb674d83b075888f482779f5_ApplyWithCA__ctl(%Array* %controlRegister, { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 1)
  %1 = getelementptr inbounds { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %outerOperation = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  %2 = getelementptr inbounds { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %innerOperation = load %Callable*, %Callable** %2, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %3 = getelementptr inbounds { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 2
  %target = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %3, align 8
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %target, i32 0, i32 0
  %5 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %5 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %target, i32 0, i32 1
  %10 = load { i64, %Array* }*, { i64, %Array* }** %9, align 8
  %11 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %10, i32 0, i32 1
  %12 = load %Array*, %Array** %11, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 1)
  %13 = bitcast { i64, %Array* }* %10 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 1)
  %14 = bitcast { { i64, %Array* }*, { i64, %Array* }* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 1)
  call void @__quantum__rt__callable_invoke(%Callable* %outerOperation, %Tuple* %14, %Tuple* null)
  %15 = call %Callable* @__quantum__rt__callable_copy(%Callable* %innerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %15)
  %16 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %17 = bitcast %Tuple* %16 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %18 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %17, i32 0, i32 0
  %19 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %17, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 1)
  store %Array* %controlRegister, %Array** %18, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %target, { { i64, %Array* }*, { i64, %Array* }* }** %19, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %15, %Tuple* %16, %Tuple* null)
  %20 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %20, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %20)
  call void @__quantum__rt__callable_invoke(%Callable* %20, %Tuple* %14, %Tuple* null)
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %16, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %20, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %20, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Canon___6f7d9c2cdb674d83b075888f482779f5_ApplyWithCA__ctladj(%Array* %controlRegister, { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 1)
  %1 = getelementptr inbounds { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 0
  %outerOperation = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 1)
  %2 = getelementptr inbounds { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 1
  %innerOperation = load %Callable*, %Callable** %2, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 1)
  %3 = getelementptr inbounds { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Callable*, %Callable*, { { i64, %Array* }*, { i64, %Array* }* }* }* %0, i32 0, i32 2
  %target = load { { i64, %Array* }*, { i64, %Array* }* }*, { { i64, %Array* }*, { i64, %Array* }* }** %3, align 8
  %4 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %target, i32 0, i32 0
  %5 = load { i64, %Array* }*, { i64, %Array* }** %4, align 8
  %6 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 1)
  %8 = bitcast { i64, %Array* }* %5 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 1)
  %9 = getelementptr inbounds { { i64, %Array* }*, { i64, %Array* }* }, { { i64, %Array* }*, { i64, %Array* }* }* %target, i32 0, i32 1
  %10 = load { i64, %Array* }*, { i64, %Array* }** %9, align 8
  %11 = getelementptr inbounds { i64, %Array* }, { i64, %Array* }* %10, i32 0, i32 1
  %12 = load %Array*, %Array** %11, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 1)
  %13 = bitcast { i64, %Array* }* %10 to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 1)
  %14 = bitcast { { i64, %Array* }*, { i64, %Array* }* }* %target to %Tuple*
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 1)
  %15 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %15)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %15)
  call void @__quantum__rt__callable_invoke(%Callable* %15, %Tuple* %14, %Tuple* null)
  %16 = call %Callable* @__quantum__rt__callable_copy(%Callable* %innerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %16, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %16)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %16)
  %17 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %18 = bitcast %Tuple* %17 to { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }*
  %19 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 0
  %20 = getelementptr inbounds { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }, { %Array*, { { i64, %Array* }*, { i64, %Array* }* }* }* %18, i32 0, i32 1
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 1)
  store %Array* %controlRegister, %Array** %19, align 8
  store { { i64, %Array* }*, { i64, %Array* }* }* %target, { { i64, %Array* }*, { i64, %Array* }* }** %20, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %16, %Tuple* %17, %Tuple* null)
  %21 = call %Callable* @__quantum__rt__callable_copy(%Callable* %outerOperation, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %21, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %21)
  call void @__quantum__rt__callable_invoke(%Callable* %21, %Tuple* %14, %Tuple* null)
  call void @__quantum__rt__array_update_alias_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %outerOperation, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %innerOperation, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %15, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %16, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %16, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %controlRegister, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %7, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__array_update_reference_count(%Array* %12, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %13, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %14, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %17, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %21, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %21, i32 -1)
  ret void
}

define { i64, double, i1 }* @Microsoft__Quantum__Math____QsRef2__ExtendedTruncation____body(double %value) {
entry:
  %truncated = fptosi double %value to i64
  %0 = call %Tuple* @__quantum__rt__tuple_create(i64 ptrtoint ({ i64, double, i1 }* getelementptr ({ i64, double, i1 }, { i64, double, i1 }* null, i32 1) to i64))
  %1 = bitcast %Tuple* %0 to { i64, double, i1 }*
  %2 = getelementptr inbounds { i64, double, i1 }, { i64, double, i1 }* %1, i32 0, i32 0
  %3 = getelementptr inbounds { i64, double, i1 }, { i64, double, i1 }* %1, i32 0, i32 1
  %4 = getelementptr inbounds { i64, double, i1 }, { i64, double, i1 }* %1, i32 0, i32 2
  %5 = sitofp i64 %truncated to double
  %6 = fsub double %5, %value
  %7 = fcmp oge double %value, 0.000000e+00
  store i64 %truncated, i64* %2, align 4
  store double %6, double* %3, align 8
  store i1 %7, i1* %4, align 1
  ret { i64, double, i1 }* %1
}

; Function Attrs: nounwind readnone speculatable willreturn
declare double @llvm.pow.f64(double, double) #1

define double @Microsoft__Quantum__Math__Sin__body(double %theta) {
entry:
  %0 = call double @__quantum__qis__sin__body(double %theta)
  ret double %0
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyConditionallyIntrinsic__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp, %Callable* %onNonEqualOp) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__qis__applyconditionallyintrinsic__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp, %Callable* %onNonEqualOp)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  ret void
}

declare void @__quantum__qis__applyconditionallyintrinsic__body(%Array*, %Array*, %Callable*, %Callable*)

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyConditionallyIntrinsicA__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp, %Callable* %onNonEqualOp) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__qis__applyconditionallyintrinsic__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp, %Callable* %onNonEqualOp)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyConditionallyIntrinsicA__adj(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp, %Callable* %onNonEqualOp) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  %onEqualOp__1 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onEqualOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onEqualOp__1, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %onEqualOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp__1, i32 1)
  %onNonEqualOp__1 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onNonEqualOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %onNonEqualOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__qis__applyconditionallyintrinsic__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp__1, %Callable* %onNonEqualOp__1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyConditionallyIntrinsicC__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp, %Callable* %onNonEqualOp) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__qis__applyconditionallyintrinsic__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp, %Callable* %onNonEqualOp)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyConditionallyIntrinsicC__ctl(%Array* %ctls, { %Array*, %Array*, %Callable*, %Callable* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 1)
  %1 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 0
  %measurementResults = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  %2 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 1
  %resultsValues = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  %3 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 2
  %onEqualOp = load %Callable*, %Callable** %3, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  %4 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 3
  %onNonEqualOp = load %Callable*, %Callable** %4, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  %5 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %6 = bitcast %Tuple* %5 to { %Callable*, %Array* }*
  %7 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %6, i32 0, i32 0
  %8 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %6, i32 0, i32 1
  %9 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onEqualOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %9, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %9)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %9, %Callable** %7, align 8
  store %Array* %ctls, %Array** %8, align 8
  %onEqualOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__23, [2 x void (%Tuple*, i32)*]* @MemoryManagement__8, %Tuple* %5)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp__1, i32 1)
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %11 = bitcast %Tuple* %10 to { %Callable*, %Array* }*
  %12 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %11, i32 0, i32 1
  %14 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onNonEqualOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %14, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %14)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %14, %Callable** %12, align 8
  store %Array* %ctls, %Array** %13, align 8
  %onNonEqualOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__24, [2 x void (%Tuple*, i32)*]* @MemoryManagement__8, %Tuple* %10)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__qis__applyconditionallyintrinsic__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp__1, %Callable* %onNonEqualOp__1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__23__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__23__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @MemoryManagement__8__RefCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 %count-change)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @MemoryManagement__8__AliasCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 %count-change)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @Lifted__PartialApplication__24__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__24__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyConditionallyIntrinsicCA__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp, %Callable* %onNonEqualOp) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__qis__applyconditionallyintrinsic__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp, %Callable* %onNonEqualOp)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyConditionallyIntrinsicCA__adj(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp, %Callable* %onNonEqualOp) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  %onEqualOp__1 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onEqualOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onEqualOp__1, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %onEqualOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp__1, i32 1)
  %onNonEqualOp__1 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onNonEqualOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %onNonEqualOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__qis__applyconditionallyintrinsic__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp__1, %Callable* %onNonEqualOp__1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyConditionallyIntrinsicCA__ctl(%Array* %ctls, { %Array*, %Array*, %Callable*, %Callable* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 1)
  %1 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 0
  %measurementResults = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  %2 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 1
  %resultsValues = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  %3 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 2
  %onEqualOp = load %Callable*, %Callable** %3, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  %4 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 3
  %onNonEqualOp = load %Callable*, %Callable** %4, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  %5 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %6 = bitcast %Tuple* %5 to { %Callable*, %Array* }*
  %7 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %6, i32 0, i32 0
  %8 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %6, i32 0, i32 1
  %9 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onEqualOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %9, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %9)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %9, %Callable** %7, align 8
  store %Array* %ctls, %Array** %8, align 8
  %onEqualOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__25, [2 x void (%Tuple*, i32)*]* @MemoryManagement__9, %Tuple* %5)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp__1, i32 1)
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %11 = bitcast %Tuple* %10 to { %Callable*, %Array* }*
  %12 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %11, i32 0, i32 1
  %14 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onNonEqualOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %14, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %14)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %14, %Callable** %12, align 8
  store %Array* %ctls, %Array** %13, align 8
  %onNonEqualOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__26, [2 x void (%Tuple*, i32)*]* @MemoryManagement__9, %Tuple* %10)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__qis__applyconditionallyintrinsic__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp__1, %Callable* %onNonEqualOp__1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__25__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__25__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %11, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__25__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__25__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @MemoryManagement__9__RefCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_reference_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_reference_count(%Array* %4, i32 %count-change)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @MemoryManagement__9__AliasCount(%Tuple* %capture-tuple, i32 %count-change) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %2 = load %Callable*, %Callable** %1, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %2, i32 %count-change)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %2, i32 %count-change)
  %3 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %4 = load %Array*, %Array** %3, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %4, i32 %count-change)
  call void @__quantum__rt__tuple_update_alias_count(%Tuple* %capture-tuple, i32 %count-change)
  ret void
}

define void @Lifted__PartialApplication__26__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__26__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %11, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__26__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__26__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyConditionallyIntrinsicCA__ctladj(%Array* %ctls, { %Array*, %Array*, %Callable*, %Callable* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 1)
  %1 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 0
  %measurementResults = load %Array*, %Array** %1, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  %2 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 1
  %resultsValues = load %Array*, %Array** %2, align 8
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  %3 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 2
  %onEqualOp = load %Callable*, %Callable** %3, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 1)
  %4 = getelementptr inbounds { %Array*, %Array*, %Callable*, %Callable* }, { %Array*, %Array*, %Callable*, %Callable* }* %0, i32 0, i32 3
  %onNonEqualOp = load %Callable*, %Callable** %4, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 1)
  %5 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %6 = bitcast %Tuple* %5 to { %Callable*, %Array* }*
  %7 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %6, i32 0, i32 0
  %8 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %6, i32 0, i32 1
  %9 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onEqualOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %9, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %9)
  call void @__quantum__rt__callable_make_controlled(%Callable* %9)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %9, %Callable** %7, align 8
  store %Array* %ctls, %Array** %8, align 8
  %onEqualOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__27, [2 x void (%Tuple*, i32)*]* @MemoryManagement__9, %Tuple* %5)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp__1, i32 1)
  %10 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %11 = bitcast %Tuple* %10 to { %Callable*, %Array* }*
  %12 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %11, i32 0, i32 0
  %13 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %11, i32 0, i32 1
  %14 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onNonEqualOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %14, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %14)
  call void @__quantum__rt__callable_make_controlled(%Callable* %14)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %14, %Callable** %12, align 8
  store %Array* %ctls, %Array** %13, align 8
  %onNonEqualOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__28, [2 x void (%Tuple*, i32)*]* @MemoryManagement__9, %Tuple* %10)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp__1, i32 1)
  call void @__quantum__qis__applyconditionallyintrinsic__body(%Array* %measurementResults, %Array* %resultsValues, %Callable* %onEqualOp__1, %Callable* %onNonEqualOp__1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onEqualOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onNonEqualOp__1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %measurementResults, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %resultsValues, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onEqualOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onNonEqualOp, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__27__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__27__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %11, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__27__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__27__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__28__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__28__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %11, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__28__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__28__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyIfElseIntrinsic__body(%Result* %measurementResult, %Callable* %onResultZeroOp, %Callable* %onResultOneOp) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__qis__applyifelseintrinsic__body(%Result* %measurementResult, %Callable* %onResultZeroOp, %Callable* %onResultOneOp)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  ret void
}

declare void @__quantum__qis__applyifelseintrinsic__body(%Result*, %Callable*, %Callable*)

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyIfElseIntrinsicA__body(%Result* %measurementResult, %Callable* %onResultZeroOp, %Callable* %onResultOneOp) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__qis__applyifelseintrinsic__body(%Result* %measurementResult, %Callable* %onResultZeroOp, %Callable* %onResultOneOp)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyIfElseIntrinsicA__adj(%Result* %measurementResult, %Callable* %onResultZeroOp, %Callable* %onResultOneOp) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  %onResultZeroOp__1 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onResultZeroOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultZeroOp__1, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %onResultZeroOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp__1, i32 1)
  %onResultOneOp__1 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onResultOneOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %onResultOneOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__qis__applyifelseintrinsic__body(%Result* %measurementResult, %Callable* %onResultZeroOp__1, %Callable* %onResultOneOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyIfElseIntrinsicC__body(%Result* %measurementResult, %Callable* %onResultZeroOp, %Callable* %onResultOneOp) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__qis__applyifelseintrinsic__body(%Result* %measurementResult, %Callable* %onResultZeroOp, %Callable* %onResultOneOp)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyIfElseIntrinsicC__ctl(%Array* %ctls, { %Result*, %Callable*, %Callable* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 1)
  %1 = getelementptr inbounds { %Result*, %Callable*, %Callable* }, { %Result*, %Callable*, %Callable* }* %0, i32 0, i32 0
  %measurementResult = load %Result*, %Result** %1, align 8
  %2 = getelementptr inbounds { %Result*, %Callable*, %Callable* }, { %Result*, %Callable*, %Callable* }* %0, i32 0, i32 1
  %onResultZeroOp = load %Callable*, %Callable** %2, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  %3 = getelementptr inbounds { %Result*, %Callable*, %Callable* }, { %Result*, %Callable*, %Callable* }* %0, i32 0, i32 2
  %onResultOneOp = load %Callable*, %Callable** %3, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  %4 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %5 = bitcast %Tuple* %4 to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %7 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %8 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onResultZeroOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %8, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %8)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %8, %Callable** %6, align 8
  store %Array* %ctls, %Array** %7, align 8
  %onResultZeroOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__29, [2 x void (%Tuple*, i32)*]* @MemoryManagement__8, %Tuple* %4)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp__1, i32 1)
  %9 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %10 = bitcast %Tuple* %9 to { %Callable*, %Array* }*
  %11 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %10, i32 0, i32 0
  %12 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %10, i32 0, i32 1
  %13 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onResultOneOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %13, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %13)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %13, %Callable** %11, align 8
  store %Array* %ctls, %Array** %12, align 8
  %onResultOneOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__30, [2 x void (%Tuple*, i32)*]* @MemoryManagement__8, %Tuple* %9)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__qis__applyifelseintrinsic__body(%Result* %measurementResult, %Callable* %onResultZeroOp__1, %Callable* %onResultOneOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__29__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__29__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__30__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__30__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyIfElseIntrinsicCA__body(%Result* %measurementResult, %Callable* %onResultZeroOp, %Callable* %onResultOneOp) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__qis__applyifelseintrinsic__body(%Result* %measurementResult, %Callable* %onResultZeroOp, %Callable* %onResultOneOp)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyIfElseIntrinsicCA__adj(%Result* %measurementResult, %Callable* %onResultZeroOp, %Callable* %onResultOneOp) {
entry:
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  %onResultZeroOp__1 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onResultZeroOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultZeroOp__1, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %onResultZeroOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp__1, i32 1)
  %onResultOneOp__1 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onResultOneOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %onResultOneOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__qis__applyifelseintrinsic__body(%Result* %measurementResult, %Callable* %onResultZeroOp__1, %Callable* %onResultOneOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyIfElseIntrinsicCA__ctl(%Array* %ctls, { %Result*, %Callable*, %Callable* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 1)
  %1 = getelementptr inbounds { %Result*, %Callable*, %Callable* }, { %Result*, %Callable*, %Callable* }* %0, i32 0, i32 0
  %measurementResult = load %Result*, %Result** %1, align 8
  %2 = getelementptr inbounds { %Result*, %Callable*, %Callable* }, { %Result*, %Callable*, %Callable* }* %0, i32 0, i32 1
  %onResultZeroOp = load %Callable*, %Callable** %2, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  %3 = getelementptr inbounds { %Result*, %Callable*, %Callable* }, { %Result*, %Callable*, %Callable* }* %0, i32 0, i32 2
  %onResultOneOp = load %Callable*, %Callable** %3, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  %4 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %5 = bitcast %Tuple* %4 to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %7 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %8 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onResultZeroOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %8, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %8)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %8, %Callable** %6, align 8
  store %Array* %ctls, %Array** %7, align 8
  %onResultZeroOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__31, [2 x void (%Tuple*, i32)*]* @MemoryManagement__9, %Tuple* %4)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp__1, i32 1)
  %9 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %10 = bitcast %Tuple* %9 to { %Callable*, %Array* }*
  %11 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %10, i32 0, i32 0
  %12 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %10, i32 0, i32 1
  %13 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onResultOneOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %13, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %13)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %13, %Callable** %11, align 8
  store %Array* %ctls, %Array** %12, align 8
  %onResultOneOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__32, [2 x void (%Tuple*, i32)*]* @MemoryManagement__9, %Tuple* %9)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__qis__applyifelseintrinsic__body(%Result* %measurementResult, %Callable* %onResultZeroOp__1, %Callable* %onResultOneOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__31__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__31__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %11, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__31__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__31__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__32__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__32__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %11, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__32__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__32__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Simulation__QuantumProcessor__Extensions__ApplyIfElseIntrinsicCA__ctladj(%Array* %ctls, { %Result*, %Callable*, %Callable* }* %0) {
entry:
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 1)
  %1 = getelementptr inbounds { %Result*, %Callable*, %Callable* }, { %Result*, %Callable*, %Callable* }* %0, i32 0, i32 0
  %measurementResult = load %Result*, %Result** %1, align 8
  %2 = getelementptr inbounds { %Result*, %Callable*, %Callable* }, { %Result*, %Callable*, %Callable* }* %0, i32 0, i32 1
  %onResultZeroOp = load %Callable*, %Callable** %2, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 1)
  %3 = getelementptr inbounds { %Result*, %Callable*, %Callable* }, { %Result*, %Callable*, %Callable* }* %0, i32 0, i32 2
  %onResultOneOp = load %Callable*, %Callable** %3, align 8
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 1)
  %4 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %5 = bitcast %Tuple* %4 to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %7 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %8 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onResultZeroOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %8, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %8)
  call void @__quantum__rt__callable_make_controlled(%Callable* %8)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %8, %Callable** %6, align 8
  store %Array* %ctls, %Array** %7, align 8
  %onResultZeroOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__33, [2 x void (%Tuple*, i32)*]* @MemoryManagement__9, %Tuple* %4)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp__1, i32 1)
  %9 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %10 = bitcast %Tuple* %9 to { %Callable*, %Array* }*
  %11 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %10, i32 0, i32 0
  %12 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %10, i32 0, i32 1
  %13 = call %Callable* @__quantum__rt__callable_copy(%Callable* %onResultOneOp, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %13, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %13)
  call void @__quantum__rt__callable_make_controlled(%Callable* %13)
  call void @__quantum__rt__array_update_reference_count(%Array* %ctls, i32 1)
  store %Callable* %13, %Callable** %11, align 8
  store %Array* %ctls, %Array** %12, align 8
  %onResultOneOp__1 = call %Callable* @__quantum__rt__callable_create([4 x void (%Tuple*, %Tuple*, %Tuple*)*]* @PartialApplication__34, [2 x void (%Tuple*, i32)*]* @MemoryManagement__9, %Tuple* %9)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp__1, i32 1)
  call void @__quantum__qis__applyifelseintrinsic__body(%Result* %measurementResult, %Callable* %onResultZeroOp__1, %Callable* %onResultOneOp__1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onResultZeroOp__1, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %onResultOneOp__1, i32 -1)
  call void @__quantum__rt__array_update_alias_count(%Array* %ctls, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultZeroOp, i32 -1)
  call void @__quantum__rt__capture_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  call void @__quantum__rt__callable_update_alias_count(%Callable* %onResultOneOp, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__33__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__33__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %11, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__33__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__33__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__34__body__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  call void @__quantum__rt__callable_invoke(%Callable* %11, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__34__adj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %1 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 1
  %2 = load %Array*, %Array** %1, align 8
  %3 = bitcast %Tuple* %arg-tuple to { %Tuple* }*
  %4 = getelementptr inbounds { %Tuple* }, { %Tuple* }* %3, i32 0, i32 0
  %5 = load %Tuple*, %Tuple** %4, align 8
  %6 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %7 = bitcast %Tuple* %6 to { %Array*, %Tuple* }*
  %8 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 0
  %9 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %7, i32 0, i32 1
  store %Array* %2, %Array** %8, align 8
  store %Tuple* %5, %Tuple** %9, align 8
  %10 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %0, i32 0, i32 0
  %11 = load %Callable*, %Callable** %10, align 8
  %12 = call %Callable* @__quantum__rt__callable_copy(%Callable* %11, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %12)
  call void @__quantum__rt__callable_invoke(%Callable* %12, %Tuple* %6, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %6, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %12, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %12, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__34__ctl__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Lifted__PartialApplication__34__ctladj__wrapper(%Tuple* %capture-tuple, %Tuple* %arg-tuple, %Tuple* %result-tuple) {
entry:
  %0 = bitcast %Tuple* %arg-tuple to { %Array*, %Tuple* }*
  %1 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 0
  %2 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %0, i32 0, i32 1
  %3 = load %Array*, %Array** %1, align 8
  %4 = load %Tuple*, %Tuple** %2, align 8
  %5 = bitcast %Tuple* %capture-tuple to { %Callable*, %Array* }*
  %6 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 1
  %7 = load %Array*, %Array** %6, align 8
  %8 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %9 = bitcast %Tuple* %8 to { %Array*, %Tuple* }*
  %10 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 0
  %11 = getelementptr inbounds { %Array*, %Tuple* }, { %Array*, %Tuple* }* %9, i32 0, i32 1
  store %Array* %7, %Array** %10, align 8
  store %Tuple* %4, %Tuple** %11, align 8
  %12 = call %Tuple* @__quantum__rt__tuple_create(i64 mul nuw (i64 ptrtoint (i1** getelementptr (i1*, i1** null, i32 1) to i64), i64 2))
  %13 = bitcast %Tuple* %12 to { %Array*, { %Array*, %Tuple* }* }*
  %14 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 0
  %15 = getelementptr inbounds { %Array*, { %Array*, %Tuple* }* }, { %Array*, { %Array*, %Tuple* }* }* %13, i32 0, i32 1
  store %Array* %3, %Array** %14, align 8
  store { %Array*, %Tuple* }* %9, { %Array*, %Tuple* }** %15, align 8
  %16 = getelementptr inbounds { %Callable*, %Array* }, { %Callable*, %Array* }* %5, i32 0, i32 0
  %17 = load %Callable*, %Callable** %16, align 8
  %18 = call %Callable* @__quantum__rt__callable_copy(%Callable* %17, i1 false)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 1)
  call void @__quantum__rt__callable_make_adjoint(%Callable* %18)
  call void @__quantum__rt__callable_make_controlled(%Callable* %18)
  call void @__quantum__rt__callable_invoke(%Callable* %18, %Tuple* %12, %Tuple* %result-tuple)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %8, i32 -1)
  call void @__quantum__rt__tuple_update_reference_count(%Tuple* %12, i32 -1)
  call void @__quantum__rt__capture_update_reference_count(%Callable* %18, i32 -1)
  call void @__quantum__rt__callable_update_reference_count(%Callable* %18, i32 -1)
  ret void
}

define void @Microsoft__Quantum__Numerics__Samples__RunProgram() #2 {
entry:
  call void @Microsoft__Quantum__Numerics__Samples__RunProgram__body()
  ret void
}

attributes #0 = { "InteropFriendly" }
attributes #1 = { nounwind readnone speculatable willreturn }
attributes #2 = { "EntryPoint" }
